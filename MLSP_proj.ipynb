{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T6QAmWHF3sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fq6u6Vcv3YZ",
        "outputId": "25f031d7-6518-4246-bd7c-5981d2a034f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_difference(gold_path, pred_path):\n",
        "  running_avg=0\n",
        "  count=0\n",
        "  pred_files = sorted(os.listdir(pred_path))\n",
        "  for i,img_name in enumerate(sorted(os.listdir(gold_path))):\n",
        "    try:\n",
        "      gold = Image.open(os.path.join(gold_path,img_name))\n",
        "      if i==0:\n",
        "        print(gold.size)\n",
        "      pred = Image.open(os.path.join(pred_path,img_name))\n",
        "      pred_rsz = pred.resize(gold.size)\n",
        "      gold_np = np.array(gold)\n",
        "      pred_np = np.array(pred_rsz)\n",
        "      error = np.linalg.norm(pred_np - gold_np)\n",
        "      if count==0:\n",
        "        running_avg = error\n",
        "      else:\n",
        "        running_avg = running_avg*(count/(count+1)) + (error/(count+1))\n",
        "      count+=1\n",
        "      if count%100==0:\n",
        "        print(count,running_avg)\n",
        "    except:\n",
        "      try:\n",
        "        gold = Image.open(os.path.join(gold_path,img_name))\n",
        "        pred = Image.open(os.path.join(pred_path,pred_files[i]))\n",
        "        pred_rsz = pred.resize(gold.size)\n",
        "        gold_np = np.array(gold)\n",
        "        pred_np = np.array(pred_rsz)\n",
        "        error = np.linalg.norm(pred_np - gold_np)\n",
        "        if count==0:\n",
        "          running_avg = error\n",
        "        else:\n",
        "          running_avg = running_avg*(count/(count+1)) + (error/(count+1))\n",
        "        count+=1\n",
        "        if count%100==0:\n",
        "          print(count,running_avg)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "\n",
        "  return running_avg\n",
        "      \n"
      ],
      "metadata": {
        "id": "EtGjBK3v8HbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_path = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test/original\""
      ],
      "metadata": {
        "id": "laBjmbryHs7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_faces_model_N100 = \"/content/gdrive/MyDrive/faces_model/faces_N100\""
      ],
      "metadata": {
        "id": "Qbw2MzJltePL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_difference(gold_path, faces_pred_path_faces_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCe2zO-ateLv",
        "outputId": "5d17c762-bb36-489a-eba0-4e8dd49d43d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 172800.66850872498\n",
            "200 170792.64995581083\n",
            "300 171665.08624267564\n",
            "400 172987.81791645856\n",
            "500 169737.16549013194\n",
            "600 171679.0257619606\n",
            "700 169993.23763691334\n",
            "800 170096.3962843683\n",
            "900 169601.27994081573\n",
            "1000 170120.1067372303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172853.36015669338"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_faces_model_N20 = \"/content/gdrive/MyDrive/faces_model/faces_N20\""
      ],
      "metadata": {
        "id": "NfJ27FTEteHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_difference(gold_path, faces_pred_path_faces_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP4cIRP02nfK",
        "outputId": "ae620fd6-6ce5-4bba-9a03-9d0909513a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 172800.5646217541\n",
            "200 170792.5568020947\n",
            "300 171665.0047486899\n",
            "400 172987.71160168966\n",
            "500 169737.0984720396\n",
            "600 171679.01336869618\n",
            "700 169993.1974816654\n",
            "800 170096.37287820672\n",
            "900 169601.2089471269\n",
            "1000 170120.0503693949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172853.32020066152"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_faces_model_N20 = \"/content/gdrive/MyDrive/faces_model/endo_over_N20\"\n",
        "get_difference(gold_path, endo_over_pred_path_faces_model_N20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgxAyP882p2m",
        "outputId": "c9c8229f-c72b-4519-820a-e23f4dd5f870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174086.6263773879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165924.1393012151"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_faces_model_N100 = \"/content/gdrive/MyDrive/faces_model/endo_over_N100\"\n",
        "get_difference(gold_path, endo_over_pred_path_faces_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEWWH8OL3B8N",
        "outputId": "d8fb777e-4e2b-4964-8d21-07e963917baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174086.73607474248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165924.14578108778"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_faces_model_N20 = \"/content/gdrive/MyDrive/faces_model/endo_under_N20\"\n",
        "get_difference(gold_path, endo_under_pred_path_faces_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy3YMgM63HoV",
        "outputId": "9c12c049-cb71-4588-91bf-fd3b17f64017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173731.02980461903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168951.40716246443"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_faces_model_N100 = \"/content/gdrive/MyDrive/faces_model/endo_under_N100\"\n",
        "get_difference(gold_path, endo_under_pred_path_faces_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rneqY4k73RTG",
        "outputId": "87ebbc27-1165-46e9-d98d-6e21ff01fd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173730.9606476342\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168951.27764853253"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Endoscopy model"
      ],
      "metadata": {
        "id": "oL5v9dPT3xCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_endo_model_N20 = \"/content/gdrive/MyDrive/Endo_Model/faces_N20\"\n",
        "get_difference(gold_path, faces_pred_path_endo_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMtIVI263U1m",
        "outputId": "88a65341-71f1-4ecb-d4b9-92a4f621aaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 172756.6455278678\n",
            "200 170744.0955864524\n",
            "300 171654.25771122437\n",
            "400 172962.1497980926\n",
            "500 169705.68766617833\n",
            "600 171651.74177376195\n",
            "700 169965.9556077237\n",
            "800 170062.43340805685\n",
            "900 169570.59557865045\n",
            "1000 170086.20774177538\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172813.4769546897"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_endo_model_N100 = \"/content/gdrive/MyDrive/Endo_Model/faces_N100\"\n",
        "get_difference(gold_path, faces_pred_path_endo_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3stkuXrAbC2",
        "outputId": "6f5be56d-6f1e-4982-f8c6-4bc81dadd4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 172756.58589202227\n",
            "200 170744.00967054916\n",
            "300 171654.30041515394\n",
            "400 172962.19019006143\n",
            "500 169705.71088513947\n",
            "600 171651.6895071009\n",
            "700 169965.92549390887\n",
            "800 170062.3900298115\n",
            "900 169570.564376176\n",
            "1000 170086.17463077232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172813.42411686663"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_endo_model_N100 = \"/content/gdrive/MyDrive/Endo_Model/endo_under_N100\"\n",
        "get_difference(gold_path, endo_under_pred_path_endo_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA-OsbdXAr4c",
        "outputId": "0050cf93-4714-4e40-e7f5-7b9786548583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173731.22026218363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168952.21440733317"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_endo_model_N20 = \"/content/gdrive/MyDrive/Endo_Model/endo_under_N20\"\n",
        "get_difference(gold_path, endo_under_pred_path_endo_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ghgya9vA3ic",
        "outputId": "9a0a68f4-3b32-44e5-913a-9670686f74c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173731.36244943866\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168952.34222032796"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_endo_model_N20 = \"/content/gdrive/MyDrive/Endo_Model/endo_over_N20\"\n",
        "get_difference(gold_path, endo_over_pred_path_endo_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbs9DdodBrPd",
        "outputId": "b65fa3b0-6f44-4b6d-feaf-e82dcab9e06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174089.61909538327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165695.4511310785"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_endo_model_N100 = \"/content/gdrive/MyDrive/Endo_Model/endo_over_N100\"\n",
        "get_difference(gold_path, endo_over_pred_path_endo_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHctHZFbByAU",
        "outputId": "cbd1d124-07e8-489b-bf41-03cc551eefe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174089.5566935731\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165923.8597468046"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_all_model_N100 = \"/content/gdrive/MyDrive/all_model/faces_N100\"\n",
        "get_difference(gold_path, faces_pred_path_all_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9NVjP2jCO_H",
        "outputId": "d35680b6-7a16-4c6c-9893-fc2334b7c52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 172807.3111759795\n",
            "200 170796.9937442677\n",
            "300 171672.63641334977\n",
            "400 172992.82996231585\n",
            "500 169740.97832860978\n",
            "600 171682.19545477635\n",
            "700 169995.98878088963\n",
            "800 170099.43983039825\n",
            "900 169603.8821761419\n",
            "1000 170122.27179465856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172855.44118215184"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_pred_path_all_model_N20 = \"/content/gdrive/MyDrive/all_model/faces_N20\"\n",
        "get_difference(gold_path, faces_pred_path_all_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlkKXqY_CVxz",
        "outputId": "bd0ce07a-fc3b-4740-8ca1-7c159807494f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 172807.42865806952\n",
            "200 170797.18328255578\n",
            "300 171672.69082974922\n",
            "400 172992.8053360645\n",
            "500 169740.93366702358\n",
            "600 171682.08145975703\n",
            "700 169995.85489258703\n",
            "800 170099.31404934457\n",
            "900 169603.78030844443\n",
            "1000 170122.17545594304\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172855.34513574158"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_all_model_N100 = \"/content/gdrive/MyDrive/all_model/endo_over_N100\"\n",
        "get_difference(gold_path, endo_over_pred_path_all_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmKwmmZCO8i",
        "outputId": "3fca8431-c647-4f22-bd6e-390752a81630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174083.87608754428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165919.6304454131"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_over_pred_path_all_model_N20 = \"/content/gdrive/MyDrive/all_model/endo_over_N20\"\n",
        "get_difference(gold_path, endo_over_pred_path_all_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GbDpgS_CO6G",
        "outputId": "7dc21bef-348b-4d4e-c750-42667014763e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 174084.0189679413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165919.6831099963"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_all_model_N100 = \"/content/gdrive/MyDrive/all_model/endo_under_N100\"\n",
        "get_difference(gold_path, endo_under_pred_path_all_model_N100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REh2JecwC22k",
        "outputId": "8353bf54-4cc9-4799-dfb5-ddb59643a5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173729.734396115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168949.20698903588"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endo_under_pred_path_all_model_N20 = \"/content/gdrive/MyDrive/all_model/endo_under_N20\"\n",
        "get_difference(gold_path, endo_under_pred_path_all_model_N20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdpO1eOhC92T",
        "outputId": "12560ac1-8442-4156-dba7-8ff88907e800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(600, 600)\n",
            "100 173729.52286947312\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168949.01482543626"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQHPSRhqteET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faces_preds_path = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_RDN\"\n",
        "rdn_faces_faces = get_difference(gold_path=gold_path, pred_path = faces_preds_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx-xH8e-HnMv",
        "outputId": "55692f93-35e0-4444-f883-68f7909b04d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 189389.6350804599\n",
            "200 190725.5388785373\n",
            "300 189869.48029295125\n",
            "400 189443.1928376499\n",
            "500 188769.94298950981\n",
            "600 187372.28235818536\n",
            "700 187022.5138690125\n",
            "800 186740.1616471109\n",
            "900 186612.92658772867\n",
            "1000 186130.33839908853\n",
            "1100 188029.50603449554\n",
            "1200 191294.88267749263\n",
            "1300 192500.00241794626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_preds_path = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_RDN_endo\"\n",
        "rdn_endo_faces = get_difference(gold_path=gold_path, pred_path = faces_preds_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io-QMZlgIVZR",
        "outputId": "384a36ce-d36d-410b-d0ff-51245bbbd1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 217412.2634759594\n",
            "200 217873.15519854845\n",
            "300 217781.08643131587\n",
            "400 216421.91707598444\n",
            "500 215661.24633577402\n",
            "600 214606.95543019028\n",
            "700 213841.26460979268\n",
            "800 213898.92544044156\n",
            "900 213876.32514075845\n",
            "1000 213747.77882413552\n",
            "1100 216477.4895248735\n",
            "1200 220376.61364483472\n",
            "1300 222956.02364483743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_preds_path = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_Upconv\"\n",
        "upconv_faces_faces = get_difference(gold_path=gold_path, pred_path = faces_preds_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ovnaCT5IciD",
        "outputId": "c18fa9cf-ea4b-4da4-f4ea-1fdc2e3f176b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 237499.72913635397\n",
            "200 240208.70704571088\n",
            "300 239246.54017508373\n",
            "400 238601.02561058637\n",
            "500 238099.08419570295\n",
            "600 236829.0852610895\n",
            "700 236326.22684013785\n",
            "800 236200.5224965986\n",
            "900 236165.26535699656\n",
            "1000 235845.05302334653\n",
            "1100 238690.55763139002\n",
            "1200 243084.19656396788\n",
            "1300 245550.8174799271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faces_preds_path = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_Upconv_endo\"\n",
        "upconv_endo_faces = get_difference(gold_path=gold_path, pred_path = faces_preds_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DddMEuNmIdha",
        "outputId": "9162465a-dd99-4299-db60-9ff70cb0ad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 192981.25652994055\n",
            "200 195959.979859997\n",
            "300 194829.07049883794\n",
            "400 194531.7366904509\n",
            "500 194260.35038469217\n",
            "600 193098.01539288842\n",
            "700 192620.88117850435\n",
            "800 192626.02060620824\n",
            "900 192707.97513945933\n",
            "1000 192436.34681727792\n",
            "1100 194434.25213899053\n",
            "1200 197609.13405818644\n",
            "1300 199101.8829473631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdn_faces_faces, rdn_endo_faces, upconv_faces_faces, upconv_endo_faces)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gVrUjWKQANn",
        "outputId": "0918c59f-3688-43f7-baed-786ac7a34cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193022.69906229366 223413.34929973498 245971.72583670588 199270.41522234242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdn_faces_overexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/results_rdn_faces\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g7Rc5bvAIN3",
        "outputId": "39cc3745-c90b-46d3-8694-abb0288dba1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 150514.37758984056\n",
            "200 158954.1245234621\n",
            "300 161236.6813374789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdn_endo_overexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/results_rdn_overexposed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0w1yNRi8Gjx",
        "outputId": "c2db0c78-136b-4a8f-c3b6-b65807ccbaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 163293.2032909277\n",
            "200 168802.78453797137\n",
            "300 170165.37066846318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upconv_faces_overexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/results_upconv_faces\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKTMR6yaCBbK",
        "outputId": "65e6bb70-8033-4164-f2ef-aca9fd40f015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 192244.49855673616\n",
            "200 190984.02286783193\n",
            "300 190523.24256717938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upconv_endo_overexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Overexp/results_upconv_overexposed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhbkHjABCOM7",
        "outputId": "48221f66-3c45-40b5-9109-463398c29e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 152283.36192981765\n",
            "200 159361.80230564473\n",
            "300 161158.48638395508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdn_faces_overexposed, rdn_endo_overexposed, upconv_faces_overexposed, upconv_endo_overexposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ZDpWMkCchp",
        "outputId": "99d9ad05-28f4-43bc-af22-d4fa3e1ce3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162904.875914659 171323.87365259381 190230.43103552467 162815.3043111373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdn_faces_underexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/results_rdn_faces\")\n",
        "rdn_endo_underexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/results_rdn_underexposed\")\n",
        "upconv_faces_underexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/results_upconv_faces\")\n",
        "upconv_endo_underexposed = get_difference(\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/test/Normal_frames\",\"/content/gdrive/MyDrive/MLSP_project_data/Endoscopic real-synthetic over- and underexposed frames for image enhancement/Endo4IE/Real-Underexp/results_upconv_underexposed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDnuLufRCnTQ",
        "outputId": "12c9e905-6b3a-4553-8e39-c9725ddb709a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 191457.87868513202\n",
            "200 185139.15492870487\n",
            "100 198783.32978563773\n",
            "200 193896.04098035165\n",
            "100 192742.64690191374\n",
            "200 194006.53644505062\n",
            "100 193022.5563116493\n",
            "200 185802.6686385177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdn_faces_underexposed,rdn_endo_underexposed,upconv_faces_underexposed, upconv_endo_underexposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9KZnjVOElTK",
        "outputId": "e454d4e1-fa62-47c6-e371-28a1cf0dde61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183175.88586529528 191755.89010299864 194169.04309859368 183727.04005364553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/puffnjackie/pytorch-super-resolution-implementations.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1QtjWGy3sD7",
        "outputId": "e2c17212-8dea-4ce3-bc3c-8546f760e65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-super-resolution-implementations'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Total 29 (delta 0), reused 0 (delta 0), pack-reused 29\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch-super-resolution-implementations/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu-hi-da3r-W",
        "outputId": "253e9183-085e-4cde-f58c-37a62d16354d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-super-resolution-implementations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train.py --upscale_factor 2 --model \"Upconv\" --datapath \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Train/original\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhKx-nj63r7V",
        "outputId": "0ef0ca88-3ee0-4b94-c368-b4a531225c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(datapath='/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Train/original', model='Upconv', threads=4, upscale_factor=2)\n",
            "===> Loading datasets\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "===> Datasets Loading Complete\n",
            "===> Model Initialize\n",
            "===> Model Initialize Complete\n",
            "===> Training Initialize\n",
            "===> Training Initialize Complete\n",
            "=====>  Training 1 epochs\n",
            "===> Training # 1 epoch\n",
            "===> Epoch[1](1/720): Loss: 0.379448\n",
            "===> Epoch[1](2/720): Loss: 0.099085\n",
            "===> Epoch[1](3/720): Loss: 0.967072\n",
            "===> Epoch[1](4/720): Loss: 0.129902\n",
            "===> Epoch[1](5/720): Loss: 0.106431\n",
            "===> Epoch[1](6/720): Loss: 0.036017\n",
            "===> Epoch[1](7/720): Loss: 0.033875\n",
            "===> Epoch[1](8/720): Loss: 0.016719\n",
            "===> Epoch[1](9/720): Loss: 0.031313\n",
            "===> Epoch[1](10/720): Loss: 0.017202\n",
            "===> Epoch[1](11/720): Loss: 0.025594\n",
            "===> Epoch[1](12/720): Loss: 0.015899\n",
            "===> Epoch[1](13/720): Loss: 0.021929\n",
            "===> Epoch[1](14/720): Loss: 0.006770\n",
            "===> Epoch[1](15/720): Loss: 0.018644\n",
            "===> Epoch[1](16/720): Loss: 0.007109\n",
            "===> Epoch[1](17/720): Loss: 0.012505\n",
            "===> Epoch[1](18/720): Loss: 0.013511\n",
            "===> Epoch[1](19/720): Loss: 0.009141\n",
            "===> Epoch[1](20/720): Loss: 0.007083\n",
            "===> Epoch[1](21/720): Loss: 0.006891\n",
            "===> Epoch[1](22/720): Loss: 0.008830\n",
            "===> Epoch[1](23/720): Loss: 0.004867\n",
            "===> Epoch[1](24/720): Loss: 0.005395\n",
            "===> Epoch[1](25/720): Loss: 0.007778\n",
            "===> Epoch[1](26/720): Loss: 0.005686\n",
            "===> Epoch[1](27/720): Loss: 0.005290\n",
            "===> Epoch[1](28/720): Loss: 0.004398\n",
            "===> Epoch[1](29/720): Loss: 0.004691\n",
            "===> Epoch[1](30/720): Loss: 0.004099\n",
            "===> Epoch[1](31/720): Loss: 0.005157\n",
            "===> Epoch[1](32/720): Loss: 0.005361\n",
            "===> Epoch[1](33/720): Loss: 0.005019\n",
            "===> Epoch[1](34/720): Loss: 0.004309\n",
            "===> Epoch[1](35/720): Loss: 0.002774\n",
            "===> Epoch[1](36/720): Loss: 0.003823\n",
            "===> Epoch[1](37/720): Loss: 0.005090\n",
            "===> Epoch[1](38/720): Loss: 0.003062\n",
            "===> Epoch[1](39/720): Loss: 0.002886\n",
            "===> Epoch[1](40/720): Loss: 0.004875\n",
            "===> Epoch[1](41/720): Loss: 0.003086\n",
            "===> Epoch[1](42/720): Loss: 0.004403\n",
            "===> Epoch[1](43/720): Loss: 0.003251\n",
            "===> Epoch[1](44/720): Loss: 0.002967\n",
            "===> Epoch[1](45/720): Loss: 0.003506\n",
            "===> Epoch[1](46/720): Loss: 0.003858\n",
            "===> Epoch[1](47/720): Loss: 0.002803\n",
            "===> Epoch[1](48/720): Loss: 0.002521\n",
            "===> Epoch[1](49/720): Loss: 0.006080\n",
            "===> Epoch[1](50/720): Loss: 0.002771\n",
            "===> Epoch[1](51/720): Loss: 0.004072\n",
            "===> Epoch[1](52/720): Loss: 0.003240\n",
            "===> Epoch[1](53/720): Loss: 0.003990\n",
            "===> Epoch[1](54/720): Loss: 0.002460\n",
            "===> Epoch[1](55/720): Loss: 0.006036\n",
            "===> Epoch[1](56/720): Loss: 0.002609\n",
            "===> Epoch[1](57/720): Loss: 0.003558\n",
            "===> Epoch[1](58/720): Loss: 0.002311\n",
            "===> Epoch[1](59/720): Loss: 0.004076\n",
            "===> Epoch[1](60/720): Loss: 0.003124\n",
            "===> Epoch[1](61/720): Loss: 0.002727\n",
            "===> Epoch[1](62/720): Loss: 0.003021\n",
            "===> Epoch[1](63/720): Loss: 0.002654\n",
            "===> Epoch[1](64/720): Loss: 0.002394\n",
            "===> Epoch[1](65/720): Loss: 0.002551\n",
            "===> Epoch[1](66/720): Loss: 0.002667\n",
            "===> Epoch[1](67/720): Loss: 0.002493\n",
            "===> Epoch[1](68/720): Loss: 0.005090\n",
            "===> Epoch[1](69/720): Loss: 0.003067\n",
            "===> Epoch[1](70/720): Loss: 0.002722\n",
            "===> Epoch[1](71/720): Loss: 0.002199\n",
            "===> Epoch[1](72/720): Loss: 0.002962\n",
            "===> Epoch[1](73/720): Loss: 0.002260\n",
            "===> Epoch[1](74/720): Loss: 0.003765\n",
            "===> Epoch[1](75/720): Loss: 0.002914\n",
            "===> Epoch[1](76/720): Loss: 0.005395\n",
            "===> Epoch[1](77/720): Loss: 0.002756\n",
            "===> Epoch[1](78/720): Loss: 0.002938\n",
            "===> Epoch[1](79/720): Loss: 0.003858\n",
            "===> Epoch[1](80/720): Loss: 0.003849\n",
            "===> Epoch[1](81/720): Loss: 0.002418\n",
            "===> Epoch[1](82/720): Loss: 0.001982\n",
            "===> Epoch[1](83/720): Loss: 0.003118\n",
            "===> Epoch[1](84/720): Loss: 0.001664\n",
            "===> Epoch[1](85/720): Loss: 0.002724\n",
            "===> Epoch[1](86/720): Loss: 0.003248\n",
            "===> Epoch[1](87/720): Loss: 0.002276\n",
            "===> Epoch[1](88/720): Loss: 0.002438\n",
            "===> Epoch[1](89/720): Loss: 0.001678\n",
            "===> Epoch[1](90/720): Loss: 0.002771\n",
            "===> Epoch[1](91/720): Loss: 0.002510\n",
            "===> Epoch[1](92/720): Loss: 0.002964\n",
            "===> Epoch[1](93/720): Loss: 0.002993\n",
            "===> Epoch[1](94/720): Loss: 0.002090\n",
            "===> Epoch[1](95/720): Loss: 0.001607\n",
            "===> Epoch[1](96/720): Loss: 0.003207\n",
            "===> Epoch[1](97/720): Loss: 0.004412\n",
            "===> Epoch[1](98/720): Loss: 0.001822\n",
            "===> Epoch[1](99/720): Loss: 0.002921\n",
            "===> Epoch[1](100/720): Loss: 0.001458\n",
            "===> Epoch[1](101/720): Loss: 0.001446\n",
            "===> Epoch[1](102/720): Loss: 0.003410\n",
            "===> Epoch[1](103/720): Loss: 0.002021\n",
            "===> Epoch[1](104/720): Loss: 0.002155\n",
            "===> Epoch[1](105/720): Loss: 0.001379\n",
            "===> Epoch[1](106/720): Loss: 0.001446\n",
            "===> Epoch[1](107/720): Loss: 0.002952\n",
            "===> Epoch[1](108/720): Loss: 0.002397\n",
            "===> Epoch[1](109/720): Loss: 0.001454\n",
            "===> Epoch[1](110/720): Loss: 0.002143\n",
            "===> Epoch[1](111/720): Loss: 0.001679\n",
            "===> Epoch[1](112/720): Loss: 0.003585\n",
            "===> Epoch[1](113/720): Loss: 0.001284\n",
            "===> Epoch[1](114/720): Loss: 0.001508\n",
            "===> Epoch[1](115/720): Loss: 0.001875\n",
            "===> Epoch[1](116/720): Loss: 0.001199\n",
            "===> Epoch[1](117/720): Loss: 0.001138\n",
            "===> Epoch[1](118/720): Loss: 0.000977\n",
            "===> Epoch[1](119/720): Loss: 0.002911\n",
            "===> Epoch[1](120/720): Loss: 0.001288\n",
            "===> Epoch[1](121/720): Loss: 0.001492\n",
            "===> Epoch[1](122/720): Loss: 0.001284\n",
            "===> Epoch[1](123/720): Loss: 0.001548\n",
            "===> Epoch[1](124/720): Loss: 0.002120\n",
            "===> Epoch[1](125/720): Loss: 0.001162\n",
            "===> Epoch[1](126/720): Loss: 0.001333\n",
            "===> Epoch[1](127/720): Loss: 0.001303\n",
            "===> Epoch[1](128/720): Loss: 0.003343\n",
            "===> Epoch[1](129/720): Loss: 0.002180\n",
            "===> Epoch[1](130/720): Loss: 0.001167\n",
            "===> Epoch[1](131/720): Loss: 0.004744\n",
            "===> Epoch[1](132/720): Loss: 0.002043\n",
            "===> Epoch[1](133/720): Loss: 0.001479\n",
            "===> Epoch[1](134/720): Loss: 0.002424\n",
            "===> Epoch[1](135/720): Loss: 0.002966\n",
            "===> Epoch[1](136/720): Loss: 0.002620\n",
            "===> Epoch[1](137/720): Loss: 0.002111\n",
            "===> Epoch[1](138/720): Loss: 0.001757\n",
            "===> Epoch[1](139/720): Loss: 0.002091\n",
            "===> Epoch[1](140/720): Loss: 0.002528\n",
            "===> Epoch[1](141/720): Loss: 0.004188\n",
            "===> Epoch[1](142/720): Loss: 0.001922\n",
            "===> Epoch[1](143/720): Loss: 0.001096\n",
            "===> Epoch[1](144/720): Loss: 0.001702\n",
            "===> Epoch[1](145/720): Loss: 0.001944\n",
            "===> Epoch[1](146/720): Loss: 0.001188\n",
            "===> Epoch[1](147/720): Loss: 0.001863\n",
            "===> Epoch[1](148/720): Loss: 0.002459\n",
            "===> Epoch[1](149/720): Loss: 0.002557\n",
            "===> Epoch[1](150/720): Loss: 0.001509\n",
            "===> Epoch[1](151/720): Loss: 0.000850\n",
            "===> Epoch[1](152/720): Loss: 0.002617\n",
            "===> Epoch[1](153/720): Loss: 0.001613\n",
            "===> Epoch[1](154/720): Loss: 0.000752\n",
            "===> Epoch[1](155/720): Loss: 0.000710\n",
            "===> Epoch[1](156/720): Loss: 0.001019\n",
            "===> Epoch[1](157/720): Loss: 0.000443\n",
            "===> Epoch[1](158/720): Loss: 0.001314\n",
            "===> Epoch[1](159/720): Loss: 0.000810\n",
            "===> Epoch[1](160/720): Loss: 0.004072\n",
            "===> Epoch[1](161/720): Loss: 0.002177\n",
            "===> Epoch[1](162/720): Loss: 0.003628\n",
            "===> Epoch[1](163/720): Loss: 0.001751\n",
            "===> Epoch[1](164/720): Loss: 0.000860\n",
            "===> Epoch[1](165/720): Loss: 0.001427\n",
            "===> Epoch[1](166/720): Loss: 0.001921\n",
            "===> Epoch[1](167/720): Loss: 0.002194\n",
            "===> Epoch[1](168/720): Loss: 0.001920\n",
            "===> Epoch[1](169/720): Loss: 0.000574\n",
            "===> Epoch[1](170/720): Loss: 0.000571\n",
            "===> Epoch[1](171/720): Loss: 0.000851\n",
            "===> Epoch[1](172/720): Loss: 0.000644\n",
            "===> Epoch[1](173/720): Loss: 0.001216\n",
            "===> Epoch[1](174/720): Loss: 0.001075\n",
            "===> Epoch[1](175/720): Loss: 0.000942\n",
            "===> Epoch[1](176/720): Loss: 0.001352\n",
            "===> Epoch[1](177/720): Loss: 0.001788\n",
            "===> Epoch[1](178/720): Loss: 0.000892\n",
            "===> Epoch[1](179/720): Loss: 0.001168\n",
            "===> Epoch[1](180/720): Loss: 0.001726\n",
            "===> Epoch[1](181/720): Loss: 0.003824\n",
            "===> Epoch[1](182/720): Loss: 0.001259\n",
            "===> Epoch[1](183/720): Loss: 0.001905\n",
            "===> Epoch[1](184/720): Loss: 0.000893\n",
            "===> Epoch[1](185/720): Loss: 0.000886\n",
            "===> Epoch[1](186/720): Loss: 0.001484\n",
            "===> Epoch[1](187/720): Loss: 0.001063\n",
            "===> Epoch[1](188/720): Loss: 0.001142\n",
            "===> Epoch[1](189/720): Loss: 0.001645\n",
            "===> Epoch[1](190/720): Loss: 0.001168\n",
            "===> Epoch[1](191/720): Loss: 0.001143\n",
            "===> Epoch[1](192/720): Loss: 0.002558\n",
            "===> Epoch[1](193/720): Loss: 0.001318\n",
            "===> Epoch[1](194/720): Loss: 0.000464\n",
            "===> Epoch[1](195/720): Loss: 0.001601\n",
            "===> Epoch[1](196/720): Loss: 0.000930\n",
            "===> Epoch[1](197/720): Loss: 0.001380\n",
            "===> Epoch[1](198/720): Loss: 0.000956\n",
            "===> Epoch[1](199/720): Loss: 0.000685\n",
            "===> Epoch[1](200/720): Loss: 0.001277\n",
            "===> Epoch[1](201/720): Loss: 0.002086\n",
            "===> Epoch[1](202/720): Loss: 0.003148\n",
            "===> Epoch[1](203/720): Loss: 0.001343\n",
            "===> Epoch[1](204/720): Loss: 0.004905\n",
            "===> Epoch[1](205/720): Loss: 0.001651\n",
            "===> Epoch[1](206/720): Loss: 0.001148\n",
            "===> Epoch[1](207/720): Loss: 0.005049\n",
            "===> Epoch[1](208/720): Loss: 0.001200\n",
            "===> Epoch[1](209/720): Loss: 0.002183\n",
            "===> Epoch[1](210/720): Loss: 0.002423\n",
            "===> Epoch[1](211/720): Loss: 0.003635\n",
            "===> Epoch[1](212/720): Loss: 0.001887\n",
            "===> Epoch[1](213/720): Loss: 0.001962\n",
            "===> Epoch[1](214/720): Loss: 0.000876\n",
            "===> Epoch[1](215/720): Loss: 0.001650\n",
            "===> Epoch[1](216/720): Loss: 0.001646\n",
            "===> Epoch[1](217/720): Loss: 0.001303\n",
            "===> Epoch[1](218/720): Loss: 0.000786\n",
            "===> Epoch[1](219/720): Loss: 0.003153\n",
            "===> Epoch[1](220/720): Loss: 0.002136\n",
            "===> Epoch[1](221/720): Loss: 0.001215\n",
            "===> Epoch[1](222/720): Loss: 0.001130\n",
            "===> Epoch[1](223/720): Loss: 0.002262\n",
            "===> Epoch[1](224/720): Loss: 0.001799\n",
            "===> Epoch[1](225/720): Loss: 0.000919\n",
            "===> Epoch[1](226/720): Loss: 0.001178\n",
            "===> Epoch[1](227/720): Loss: 0.000751\n",
            "===> Epoch[1](228/720): Loss: 0.001054\n",
            "===> Epoch[1](229/720): Loss: 0.001242\n",
            "===> Epoch[1](230/720): Loss: 0.000696\n",
            "===> Epoch[1](231/720): Loss: 0.000392\n",
            "===> Epoch[1](232/720): Loss: 0.000617\n",
            "===> Epoch[1](233/720): Loss: 0.002266\n",
            "===> Epoch[1](234/720): Loss: 0.001743\n",
            "===> Epoch[1](235/720): Loss: 0.000814\n",
            "===> Epoch[1](236/720): Loss: 0.001168\n",
            "===> Epoch[1](237/720): Loss: 0.000965\n",
            "===> Epoch[1](238/720): Loss: 0.000839\n",
            "===> Epoch[1](239/720): Loss: 0.000795\n",
            "===> Epoch[1](240/720): Loss: 0.000632\n",
            "===> Epoch[1](241/720): Loss: 0.001890\n",
            "===> Epoch[1](242/720): Loss: 0.001547\n",
            "===> Epoch[1](243/720): Loss: 0.000721\n",
            "===> Epoch[1](244/720): Loss: 0.002170\n",
            "===> Epoch[1](245/720): Loss: 0.000780\n",
            "===> Epoch[1](246/720): Loss: 0.000664\n",
            "===> Epoch[1](247/720): Loss: 0.003995\n",
            "===> Epoch[1](248/720): Loss: 0.000478\n",
            "===> Epoch[1](249/720): Loss: 0.002337\n",
            "===> Epoch[1](250/720): Loss: 0.001273\n",
            "===> Epoch[1](251/720): Loss: 0.001235\n",
            "===> Epoch[1](252/720): Loss: 0.001244\n",
            "===> Epoch[1](253/720): Loss: 0.001172\n",
            "===> Epoch[1](254/720): Loss: 0.000433\n",
            "===> Epoch[1](255/720): Loss: 0.000705\n",
            "===> Epoch[1](256/720): Loss: 0.000534\n",
            "===> Epoch[1](257/720): Loss: 0.000918\n",
            "===> Epoch[1](258/720): Loss: 0.000736\n",
            "===> Epoch[1](259/720): Loss: 0.001051\n",
            "===> Epoch[1](260/720): Loss: 0.000408\n",
            "===> Epoch[1](261/720): Loss: 0.000575\n",
            "===> Epoch[1](262/720): Loss: 0.000628\n",
            "===> Epoch[1](263/720): Loss: 0.000570\n",
            "===> Epoch[1](264/720): Loss: 0.001457\n",
            "===> Epoch[1](265/720): Loss: 0.002505\n",
            "===> Epoch[1](266/720): Loss: 0.001496\n",
            "===> Epoch[1](267/720): Loss: 0.002684\n",
            "===> Epoch[1](268/720): Loss: 0.001054\n",
            "===> Epoch[1](269/720): Loss: 0.000842\n",
            "===> Epoch[1](270/720): Loss: 0.001087\n",
            "===> Epoch[1](271/720): Loss: 0.002159\n",
            "===> Epoch[1](272/720): Loss: 0.000513\n",
            "===> Epoch[1](273/720): Loss: 0.001582\n",
            "===> Epoch[1](274/720): Loss: 0.000685\n",
            "===> Epoch[1](275/720): Loss: 0.000777\n",
            "===> Epoch[1](276/720): Loss: 0.000713\n",
            "===> Epoch[1](277/720): Loss: 0.001299\n",
            "===> Epoch[1](278/720): Loss: 0.000559\n",
            "===> Epoch[1](279/720): Loss: 0.000586\n",
            "===> Epoch[1](280/720): Loss: 0.001590\n",
            "===> Epoch[1](281/720): Loss: 0.000737\n",
            "===> Epoch[1](282/720): Loss: 0.002148\n",
            "===> Epoch[1](283/720): Loss: 0.001022\n",
            "===> Epoch[1](284/720): Loss: 0.000914\n",
            "===> Epoch[1](285/720): Loss: 0.002303\n",
            "===> Epoch[1](286/720): Loss: 0.001881\n",
            "===> Epoch[1](287/720): Loss: 0.001007\n",
            "===> Epoch[1](288/720): Loss: 0.000587\n",
            "===> Epoch[1](289/720): Loss: 0.001151\n",
            "===> Epoch[1](290/720): Loss: 0.000852\n",
            "===> Epoch[1](291/720): Loss: 0.001133\n",
            "===> Epoch[1](292/720): Loss: 0.000605\n",
            "===> Epoch[1](293/720): Loss: 0.000945\n",
            "===> Epoch[1](294/720): Loss: 0.000630\n",
            "===> Epoch[1](295/720): Loss: 0.000430\n",
            "===> Epoch[1](296/720): Loss: 0.001640\n",
            "===> Epoch[1](297/720): Loss: 0.001368\n",
            "===> Epoch[1](298/720): Loss: 0.000389\n",
            "===> Epoch[1](299/720): Loss: 0.000239\n",
            "===> Epoch[1](300/720): Loss: 0.001472\n",
            "===> Epoch[1](301/720): Loss: 0.000391\n",
            "===> Epoch[1](302/720): Loss: 0.000760\n",
            "===> Epoch[1](303/720): Loss: 0.000324\n",
            "===> Epoch[1](304/720): Loss: 0.000753\n",
            "===> Epoch[1](305/720): Loss: 0.001779\n",
            "===> Epoch[1](306/720): Loss: 0.000881\n",
            "===> Epoch[1](307/720): Loss: 0.000467\n",
            "===> Epoch[1](308/720): Loss: 0.000496\n",
            "===> Epoch[1](309/720): Loss: 0.000453\n",
            "===> Epoch[1](310/720): Loss: 0.002001\n",
            "===> Epoch[1](311/720): Loss: 0.000936\n",
            "===> Epoch[1](312/720): Loss: 0.000553\n",
            "===> Epoch[1](313/720): Loss: 0.000996\n",
            "===> Epoch[1](314/720): Loss: 0.000601\n",
            "===> Epoch[1](315/720): Loss: 0.001363\n",
            "===> Epoch[1](316/720): Loss: 0.000409\n",
            "===> Epoch[1](317/720): Loss: 0.001012\n",
            "===> Epoch[1](318/720): Loss: 0.000579\n",
            "===> Epoch[1](319/720): Loss: 0.001004\n",
            "===> Epoch[1](320/720): Loss: 0.000460\n",
            "===> Epoch[1](321/720): Loss: 0.000563\n",
            "===> Epoch[1](322/720): Loss: 0.000442\n",
            "===> Epoch[1](323/720): Loss: 0.001763\n",
            "===> Epoch[1](324/720): Loss: 0.000965\n",
            "===> Epoch[1](325/720): Loss: 0.000729\n",
            "===> Epoch[1](326/720): Loss: 0.000369\n",
            "===> Epoch[1](327/720): Loss: 0.001631\n",
            "===> Epoch[1](328/720): Loss: 0.004098\n",
            "===> Epoch[1](329/720): Loss: 0.000914\n",
            "===> Epoch[1](330/720): Loss: 0.000808\n",
            "===> Epoch[1](331/720): Loss: 0.000453\n",
            "===> Epoch[1](332/720): Loss: 0.000750\n",
            "===> Epoch[1](333/720): Loss: 0.000378\n",
            "===> Epoch[1](334/720): Loss: 0.000630\n",
            "===> Epoch[1](335/720): Loss: 0.000623\n",
            "===> Epoch[1](336/720): Loss: 0.000504\n",
            "===> Epoch[1](337/720): Loss: 0.000444\n",
            "===> Epoch[1](338/720): Loss: 0.000946\n",
            "===> Epoch[1](339/720): Loss: 0.000743\n",
            "===> Epoch[1](340/720): Loss: 0.000829\n",
            "===> Epoch[1](341/720): Loss: 0.001166\n",
            "===> Epoch[1](342/720): Loss: 0.000344\n",
            "===> Epoch[1](343/720): Loss: 0.000920\n",
            "===> Epoch[1](344/720): Loss: 0.000658\n",
            "===> Epoch[1](345/720): Loss: 0.000818\n",
            "===> Epoch[1](346/720): Loss: 0.000773\n",
            "===> Epoch[1](347/720): Loss: 0.001164\n",
            "===> Epoch[1](348/720): Loss: 0.000933\n",
            "===> Epoch[1](349/720): Loss: 0.002167\n",
            "===> Epoch[1](350/720): Loss: 0.000944\n",
            "===> Epoch[1](351/720): Loss: 0.000422\n",
            "===> Epoch[1](352/720): Loss: 0.000947\n",
            "===> Epoch[1](353/720): Loss: 0.002125\n",
            "===> Epoch[1](354/720): Loss: 0.000269\n",
            "===> Epoch[1](355/720): Loss: 0.001915\n",
            "===> Epoch[1](356/720): Loss: 0.001627\n",
            "===> Epoch[1](357/720): Loss: 0.000365\n",
            "===> Epoch[1](358/720): Loss: 0.000716\n",
            "===> Epoch[1](359/720): Loss: 0.000428\n",
            "===> Epoch[1](360/720): Loss: 0.000654\n",
            "===> Epoch[1](361/720): Loss: 0.002109\n",
            "===> Epoch[1](362/720): Loss: 0.001456\n",
            "===> Epoch[1](363/720): Loss: 0.001515\n",
            "===> Epoch[1](364/720): Loss: 0.001465\n",
            "===> Epoch[1](365/720): Loss: 0.001109\n",
            "===> Epoch[1](366/720): Loss: 0.000466\n",
            "===> Epoch[1](367/720): Loss: 0.001593\n",
            "===> Epoch[1](368/720): Loss: 0.001053\n",
            "===> Epoch[1](369/720): Loss: 0.000890\n",
            "===> Epoch[1](370/720): Loss: 0.002178\n",
            "===> Epoch[1](371/720): Loss: 0.001369\n",
            "===> Epoch[1](372/720): Loss: 0.000667\n",
            "===> Epoch[1](373/720): Loss: 0.000629\n",
            "===> Epoch[1](374/720): Loss: 0.000721\n",
            "===> Epoch[1](375/720): Loss: 0.000592\n",
            "===> Epoch[1](376/720): Loss: 0.001138\n",
            "===> Epoch[1](377/720): Loss: 0.000867\n",
            "===> Epoch[1](378/720): Loss: 0.000547\n",
            "===> Epoch[1](379/720): Loss: 0.000942\n",
            "===> Epoch[1](380/720): Loss: 0.000728\n",
            "===> Epoch[1](381/720): Loss: 0.000864\n",
            "===> Epoch[1](382/720): Loss: 0.001463\n",
            "===> Epoch[1](383/720): Loss: 0.000720\n",
            "===> Epoch[1](384/720): Loss: 0.000574\n",
            "===> Epoch[1](385/720): Loss: 0.000584\n",
            "===> Epoch[1](386/720): Loss: 0.000828\n",
            "===> Epoch[1](387/720): Loss: 0.000731\n",
            "===> Epoch[1](388/720): Loss: 0.000437\n",
            "===> Epoch[1](389/720): Loss: 0.001029\n",
            "===> Epoch[1](390/720): Loss: 0.001398\n",
            "===> Epoch[1](391/720): Loss: 0.002323\n",
            "===> Epoch[1](392/720): Loss: 0.000856\n",
            "===> Epoch[1](393/720): Loss: 0.000398\n",
            "===> Epoch[1](394/720): Loss: 0.001745\n",
            "===> Epoch[1](395/720): Loss: 0.000291\n",
            "===> Epoch[1](396/720): Loss: 0.000791\n",
            "===> Epoch[1](397/720): Loss: 0.000932\n",
            "===> Epoch[1](398/720): Loss: 0.000481\n",
            "===> Epoch[1](399/720): Loss: 0.000472\n",
            "===> Epoch[1](400/720): Loss: 0.002362\n",
            "===> Epoch[1](401/720): Loss: 0.001952\n",
            "===> Epoch[1](402/720): Loss: 0.000414\n",
            "===> Epoch[1](403/720): Loss: 0.000910\n",
            "===> Epoch[1](404/720): Loss: 0.002944\n",
            "===> Epoch[1](405/720): Loss: 0.000804\n",
            "===> Epoch[1](406/720): Loss: 0.000900\n",
            "===> Epoch[1](407/720): Loss: 0.001307\n",
            "===> Epoch[1](408/720): Loss: 0.000913\n",
            "===> Epoch[1](409/720): Loss: 0.000872\n",
            "===> Epoch[1](410/720): Loss: 0.000541\n",
            "===> Epoch[1](411/720): Loss: 0.000951\n",
            "===> Epoch[1](412/720): Loss: 0.001702\n",
            "===> Epoch[1](413/720): Loss: 0.000388\n",
            "===> Epoch[1](414/720): Loss: 0.001137\n",
            "===> Epoch[1](415/720): Loss: 0.000560\n",
            "===> Epoch[1](416/720): Loss: 0.001108\n",
            "===> Epoch[1](417/720): Loss: 0.001554\n",
            "===> Epoch[1](418/720): Loss: 0.002687\n",
            "===> Epoch[1](419/720): Loss: 0.002228\n",
            "===> Epoch[1](420/720): Loss: 0.000326\n",
            "===> Epoch[1](421/720): Loss: 0.000384\n",
            "===> Epoch[1](422/720): Loss: 0.000668\n",
            "===> Epoch[1](423/720): Loss: 0.000985\n",
            "===> Epoch[1](424/720): Loss: 0.001024\n",
            "===> Epoch[1](425/720): Loss: 0.000513\n",
            "===> Epoch[1](426/720): Loss: 0.001792\n",
            "===> Epoch[1](427/720): Loss: 0.002609\n",
            "===> Epoch[1](428/720): Loss: 0.000889\n",
            "===> Epoch[1](429/720): Loss: 0.000781\n",
            "===> Epoch[1](430/720): Loss: 0.000553\n",
            "===> Epoch[1](431/720): Loss: 0.000668\n",
            "===> Epoch[1](432/720): Loss: 0.000370\n",
            "===> Epoch[1](433/720): Loss: 0.000788\n",
            "===> Epoch[1](434/720): Loss: 0.001078\n",
            "===> Epoch[1](435/720): Loss: 0.000809\n",
            "===> Epoch[1](436/720): Loss: 0.001595\n",
            "===> Epoch[1](437/720): Loss: 0.002012\n",
            "===> Epoch[1](438/720): Loss: 0.001067\n",
            "===> Epoch[1](439/720): Loss: 0.000591\n",
            "===> Epoch[1](440/720): Loss: 0.000924\n",
            "===> Epoch[1](441/720): Loss: 0.000525\n",
            "===> Epoch[1](442/720): Loss: 0.001272\n",
            "===> Epoch[1](443/720): Loss: 0.000387\n",
            "===> Epoch[1](444/720): Loss: 0.000785\n",
            "===> Epoch[1](445/720): Loss: 0.000689\n",
            "===> Epoch[1](446/720): Loss: 0.000915\n",
            "===> Epoch[1](447/720): Loss: 0.000605\n",
            "===> Epoch[1](448/720): Loss: 0.000669\n",
            "===> Epoch[1](449/720): Loss: 0.001247\n",
            "===> Epoch[1](450/720): Loss: 0.001502\n",
            "===> Epoch[1](451/720): Loss: 0.000411\n",
            "===> Epoch[1](452/720): Loss: 0.000363\n",
            "===> Epoch[1](453/720): Loss: 0.000812\n",
            "===> Epoch[1](454/720): Loss: 0.000250\n",
            "===> Epoch[1](455/720): Loss: 0.000732\n",
            "===> Epoch[1](456/720): Loss: 0.000479\n",
            "===> Epoch[1](457/720): Loss: 0.000290\n",
            "===> Epoch[1](458/720): Loss: 0.001196\n",
            "===> Epoch[1](459/720): Loss: 0.001009\n",
            "===> Epoch[1](460/720): Loss: 0.000440\n",
            "===> Epoch[1](461/720): Loss: 0.000335\n",
            "===> Epoch[1](462/720): Loss: 0.001043\n",
            "===> Epoch[1](463/720): Loss: 0.000489\n",
            "===> Epoch[1](464/720): Loss: 0.000371\n",
            "===> Epoch[1](465/720): Loss: 0.000945\n",
            "===> Epoch[1](466/720): Loss: 0.000403\n",
            "===> Epoch[1](467/720): Loss: 0.000702\n",
            "===> Epoch[1](468/720): Loss: 0.000341\n",
            "===> Epoch[1](469/720): Loss: 0.000742\n",
            "===> Epoch[1](470/720): Loss: 0.000371\n",
            "===> Epoch[1](471/720): Loss: 0.000872\n",
            "===> Epoch[1](472/720): Loss: 0.000529\n",
            "===> Epoch[1](473/720): Loss: 0.000310\n",
            "===> Epoch[1](474/720): Loss: 0.001770\n",
            "===> Epoch[1](475/720): Loss: 0.000447\n",
            "===> Epoch[1](476/720): Loss: 0.000455\n",
            "===> Epoch[1](477/720): Loss: 0.000339\n",
            "===> Epoch[1](478/720): Loss: 0.000806\n",
            "===> Epoch[1](479/720): Loss: 0.001749\n",
            "===> Epoch[1](480/720): Loss: 0.001484\n",
            "===> Epoch[1](481/720): Loss: 0.000809\n",
            "===> Epoch[1](482/720): Loss: 0.000985\n",
            "===> Epoch[1](483/720): Loss: 0.001028\n",
            "===> Epoch[1](484/720): Loss: 0.001239\n",
            "===> Epoch[1](485/720): Loss: 0.000583\n",
            "===> Epoch[1](486/720): Loss: 0.001066\n",
            "===> Epoch[1](487/720): Loss: 0.001832\n",
            "===> Epoch[1](488/720): Loss: 0.002505\n",
            "===> Epoch[1](489/720): Loss: 0.000590\n",
            "===> Epoch[1](490/720): Loss: 0.000670\n",
            "===> Epoch[1](491/720): Loss: 0.000454\n",
            "===> Epoch[1](492/720): Loss: 0.000401\n",
            "===> Epoch[1](493/720): Loss: 0.000470\n",
            "===> Epoch[1](494/720): Loss: 0.001209\n",
            "===> Epoch[1](495/720): Loss: 0.000492\n",
            "===> Epoch[1](496/720): Loss: 0.000769\n",
            "===> Epoch[1](497/720): Loss: 0.000567\n",
            "===> Epoch[1](498/720): Loss: 0.002466\n",
            "===> Epoch[1](499/720): Loss: 0.000426\n",
            "===> Epoch[1](500/720): Loss: 0.000701\n",
            "===> Epoch[1](501/720): Loss: 0.000426\n",
            "===> Epoch[1](502/720): Loss: 0.000413\n",
            "===> Epoch[1](503/720): Loss: 0.000368\n",
            "===> Epoch[1](504/720): Loss: 0.001121\n",
            "===> Epoch[1](505/720): Loss: 0.000970\n",
            "===> Epoch[1](506/720): Loss: 0.000217\n",
            "===> Epoch[1](507/720): Loss: 0.000221\n",
            "===> Epoch[1](508/720): Loss: 0.001188\n",
            "===> Epoch[1](509/720): Loss: 0.001673\n",
            "===> Epoch[1](510/720): Loss: 0.000567\n",
            "===> Epoch[1](511/720): Loss: 0.000452\n",
            "===> Epoch[1](512/720): Loss: 0.000684\n",
            "===> Epoch[1](513/720): Loss: 0.000488\n",
            "===> Epoch[1](514/720): Loss: 0.000412\n",
            "===> Epoch[1](515/720): Loss: 0.000469\n",
            "===> Epoch[1](516/720): Loss: 0.000538\n",
            "===> Epoch[1](517/720): Loss: 0.000473\n",
            "===> Epoch[1](518/720): Loss: 0.000401\n",
            "===> Epoch[1](519/720): Loss: 0.000281\n",
            "===> Epoch[1](520/720): Loss: 0.000244\n",
            "===> Epoch[1](521/720): Loss: 0.000899\n",
            "===> Epoch[1](522/720): Loss: 0.000413\n",
            "===> Epoch[1](523/720): Loss: 0.000335\n",
            "===> Epoch[1](524/720): Loss: 0.000496\n",
            "===> Epoch[1](525/720): Loss: 0.001804\n",
            "===> Epoch[1](526/720): Loss: 0.000168\n",
            "===> Epoch[1](527/720): Loss: 0.000360\n",
            "===> Epoch[1](528/720): Loss: 0.000926\n",
            "===> Epoch[1](529/720): Loss: 0.000860\n",
            "===> Epoch[1](530/720): Loss: 0.000436\n",
            "===> Epoch[1](531/720): Loss: 0.001018\n",
            "===> Epoch[1](532/720): Loss: 0.001197\n",
            "===> Epoch[1](533/720): Loss: 0.000253\n",
            "===> Epoch[1](534/720): Loss: 0.001544\n",
            "===> Epoch[1](535/720): Loss: 0.000146\n",
            "===> Epoch[1](536/720): Loss: 0.000334\n",
            "===> Epoch[1](537/720): Loss: 0.000238\n",
            "===> Epoch[1](538/720): Loss: 0.001261\n",
            "===> Epoch[1](539/720): Loss: 0.000486\n",
            "===> Epoch[1](540/720): Loss: 0.000561\n",
            "===> Epoch[1](541/720): Loss: 0.001443\n",
            "===> Epoch[1](542/720): Loss: 0.000861\n",
            "===> Epoch[1](543/720): Loss: 0.000221\n",
            "===> Epoch[1](544/720): Loss: 0.000643\n",
            "===> Epoch[1](545/720): Loss: 0.000949\n",
            "===> Epoch[1](546/720): Loss: 0.000306\n",
            "===> Epoch[1](547/720): Loss: 0.001709\n",
            "===> Epoch[1](548/720): Loss: 0.000333\n",
            "===> Epoch[1](549/720): Loss: 0.000313\n",
            "===> Epoch[1](550/720): Loss: 0.000389\n",
            "===> Epoch[1](551/720): Loss: 0.000508\n",
            "===> Epoch[1](552/720): Loss: 0.001385\n",
            "===> Epoch[1](553/720): Loss: 0.000363\n",
            "===> Epoch[1](554/720): Loss: 0.000222\n",
            "===> Epoch[1](555/720): Loss: 0.000945\n",
            "===> Epoch[1](556/720): Loss: 0.000165\n",
            "===> Epoch[1](557/720): Loss: 0.000686\n",
            "===> Epoch[1](558/720): Loss: 0.000635\n",
            "===> Epoch[1](559/720): Loss: 0.000462\n",
            "===> Epoch[1](560/720): Loss: 0.000715\n",
            "===> Epoch[1](561/720): Loss: 0.000747\n",
            "===> Epoch[1](562/720): Loss: 0.001524\n",
            "===> Epoch[1](563/720): Loss: 0.000320\n",
            "===> Epoch[1](564/720): Loss: 0.000392\n",
            "===> Epoch[1](565/720): Loss: 0.000522\n",
            "===> Epoch[1](566/720): Loss: 0.000248\n",
            "===> Epoch[1](567/720): Loss: 0.000403\n",
            "===> Epoch[1](568/720): Loss: 0.001417\n",
            "===> Epoch[1](569/720): Loss: 0.000673\n",
            "===> Epoch[1](570/720): Loss: 0.000838\n",
            "===> Epoch[1](571/720): Loss: 0.000268\n",
            "===> Epoch[1](572/720): Loss: 0.000500\n",
            "===> Epoch[1](573/720): Loss: 0.000186\n",
            "===> Epoch[1](574/720): Loss: 0.002914\n",
            "===> Epoch[1](575/720): Loss: 0.000347\n",
            "===> Epoch[1](576/720): Loss: 0.000359\n",
            "===> Epoch[1](577/720): Loss: 0.000331\n",
            "===> Epoch[1](578/720): Loss: 0.000380\n",
            "===> Epoch[1](579/720): Loss: 0.000494\n",
            "===> Epoch[1](580/720): Loss: 0.000379\n",
            "===> Epoch[1](581/720): Loss: 0.000378\n",
            "===> Epoch[1](582/720): Loss: 0.000436\n",
            "===> Epoch[1](583/720): Loss: 0.000446\n",
            "===> Epoch[1](584/720): Loss: 0.001120\n",
            "===> Epoch[1](585/720): Loss: 0.000702\n",
            "===> Epoch[1](586/720): Loss: 0.001729\n",
            "===> Epoch[1](587/720): Loss: 0.000384\n",
            "===> Epoch[1](588/720): Loss: 0.000896\n",
            "===> Epoch[1](589/720): Loss: 0.000559\n",
            "===> Epoch[1](590/720): Loss: 0.000423\n",
            "===> Epoch[1](591/720): Loss: 0.001721\n",
            "===> Epoch[1](592/720): Loss: 0.000922\n",
            "===> Epoch[1](593/720): Loss: 0.001232\n",
            "===> Epoch[1](594/720): Loss: 0.002370\n",
            "===> Epoch[1](595/720): Loss: 0.001189\n",
            "===> Epoch[1](596/720): Loss: 0.001292\n",
            "===> Epoch[1](597/720): Loss: 0.001160\n",
            "===> Epoch[1](598/720): Loss: 0.000321\n",
            "===> Epoch[1](599/720): Loss: 0.001720\n",
            "===> Epoch[1](600/720): Loss: 0.000917\n",
            "===> Epoch[1](601/720): Loss: 0.000737\n",
            "===> Epoch[1](602/720): Loss: 0.001461\n",
            "===> Epoch[1](603/720): Loss: 0.000898\n",
            "===> Epoch[1](604/720): Loss: 0.000854\n",
            "===> Epoch[1](605/720): Loss: 0.003108\n",
            "===> Epoch[1](606/720): Loss: 0.001082\n",
            "===> Epoch[1](607/720): Loss: 0.000364\n",
            "===> Epoch[1](608/720): Loss: 0.000725\n",
            "===> Epoch[1](609/720): Loss: 0.003468\n",
            "===> Epoch[1](610/720): Loss: 0.000498\n",
            "===> Epoch[1](611/720): Loss: 0.000532\n",
            "===> Epoch[1](612/720): Loss: 0.000664\n",
            "===> Epoch[1](613/720): Loss: 0.001170\n",
            "===> Epoch[1](614/720): Loss: 0.000901\n",
            "===> Epoch[1](615/720): Loss: 0.000600\n",
            "===> Epoch[1](616/720): Loss: 0.002124\n",
            "===> Epoch[1](617/720): Loss: 0.000522\n",
            "===> Epoch[1](618/720): Loss: 0.001554\n",
            "===> Epoch[1](619/720): Loss: 0.001258\n",
            "===> Epoch[1](620/720): Loss: 0.000279\n",
            "===> Epoch[1](621/720): Loss: 0.000451\n",
            "===> Epoch[1](622/720): Loss: 0.001322\n",
            "===> Epoch[1](623/720): Loss: 0.001036\n",
            "===> Epoch[1](624/720): Loss: 0.000639\n",
            "===> Epoch[1](625/720): Loss: 0.000406\n",
            "===> Epoch[1](626/720): Loss: 0.000519\n",
            "===> Epoch[1](627/720): Loss: 0.000254\n",
            "===> Epoch[1](628/720): Loss: 0.000305\n",
            "===> Epoch[1](629/720): Loss: 0.001130\n",
            "===> Epoch[1](630/720): Loss: 0.000720\n",
            "===> Epoch[1](631/720): Loss: 0.000362\n",
            "===> Epoch[1](632/720): Loss: 0.000493\n",
            "===> Epoch[1](633/720): Loss: 0.000795\n",
            "===> Epoch[1](634/720): Loss: 0.000674\n",
            "===> Epoch[1](635/720): Loss: 0.000333\n",
            "===> Epoch[1](636/720): Loss: 0.000520\n",
            "===> Epoch[1](637/720): Loss: 0.000724\n",
            "===> Epoch[1](638/720): Loss: 0.000862\n",
            "===> Epoch[1](639/720): Loss: 0.000165\n",
            "===> Epoch[1](640/720): Loss: 0.001515\n",
            "===> Epoch[1](641/720): Loss: 0.001238\n",
            "===> Epoch[1](642/720): Loss: 0.000347\n",
            "===> Epoch[1](643/720): Loss: 0.000663\n",
            "===> Epoch[1](644/720): Loss: 0.000315\n",
            "===> Epoch[1](645/720): Loss: 0.000414\n",
            "===> Epoch[1](646/720): Loss: 0.000325\n",
            "===> Epoch[1](647/720): Loss: 0.000268\n",
            "===> Epoch[1](648/720): Loss: 0.000193\n",
            "===> Epoch[1](649/720): Loss: 0.000317\n",
            "===> Epoch[1](650/720): Loss: 0.000389\n",
            "===> Epoch[1](651/720): Loss: 0.000297\n",
            "===> Epoch[1](652/720): Loss: 0.001357\n",
            "===> Epoch[1](653/720): Loss: 0.000520\n",
            "===> Epoch[1](654/720): Loss: 0.000454\n",
            "===> Epoch[1](655/720): Loss: 0.000372\n",
            "===> Epoch[1](656/720): Loss: 0.000224\n",
            "===> Epoch[1](657/720): Loss: 0.000989\n",
            "===> Epoch[1](658/720): Loss: 0.000609\n",
            "===> Epoch[1](659/720): Loss: 0.000499\n",
            "===> Epoch[1](660/720): Loss: 0.000332\n",
            "===> Epoch[1](661/720): Loss: 0.000711\n",
            "===> Epoch[1](662/720): Loss: 0.000192\n",
            "===> Epoch[1](663/720): Loss: 0.000290\n",
            "===> Epoch[1](664/720): Loss: 0.001928\n",
            "===> Epoch[1](665/720): Loss: 0.000268\n",
            "===> Epoch[1](666/720): Loss: 0.000177\n",
            "===> Epoch[1](667/720): Loss: 0.000481\n",
            "===> Epoch[1](668/720): Loss: 0.000747\n",
            "===> Epoch[1](669/720): Loss: 0.000383\n",
            "===> Epoch[1](670/720): Loss: 0.000621\n",
            "===> Epoch[1](671/720): Loss: 0.000435\n",
            "===> Epoch[1](672/720): Loss: 0.000765\n",
            "===> Epoch[1](673/720): Loss: 0.000381\n",
            "===> Epoch[1](674/720): Loss: 0.000679\n",
            "===> Epoch[1](675/720): Loss: 0.000665\n",
            "===> Epoch[1](676/720): Loss: 0.000192\n",
            "===> Epoch[1](677/720): Loss: 0.001239\n",
            "===> Epoch[1](678/720): Loss: 0.001047\n",
            "===> Epoch[1](679/720): Loss: 0.000600\n",
            "===> Epoch[1](680/720): Loss: 0.000343\n",
            "===> Epoch[1](681/720): Loss: 0.000205\n",
            "===> Epoch[1](682/720): Loss: 0.000345\n",
            "===> Epoch[1](683/720): Loss: 0.001025\n",
            "===> Epoch[1](684/720): Loss: 0.000168\n",
            "===> Epoch[1](685/720): Loss: 0.001249\n",
            "===> Epoch[1](686/720): Loss: 0.001817\n",
            "===> Epoch[1](687/720): Loss: 0.000254\n",
            "===> Epoch[1](688/720): Loss: 0.000342\n",
            "===> Epoch[1](689/720): Loss: 0.000743\n",
            "===> Epoch[1](690/720): Loss: 0.000497\n",
            "===> Epoch[1](691/720): Loss: 0.000860\n",
            "===> Epoch[1](692/720): Loss: 0.000356\n",
            "===> Epoch[1](693/720): Loss: 0.000401\n",
            "===> Epoch[1](694/720): Loss: 0.000370\n",
            "===> Epoch[1](695/720): Loss: 0.000839\n",
            "===> Epoch[1](696/720): Loss: 0.000463\n",
            "===> Epoch[1](697/720): Loss: 0.000656\n",
            "===> Epoch[1](698/720): Loss: 0.000453\n",
            "===> Epoch[1](699/720): Loss: 0.000727\n",
            "===> Epoch[1](700/720): Loss: 0.000810\n",
            "===> Epoch[1](701/720): Loss: 0.000698\n",
            "===> Epoch[1](702/720): Loss: 0.000418\n",
            "===> Epoch[1](703/720): Loss: 0.000794\n",
            "===> Epoch[1](704/720): Loss: 0.000478\n",
            "===> Epoch[1](705/720): Loss: 0.001155\n",
            "===> Epoch[1](706/720): Loss: 0.000310\n",
            "===> Epoch[1](707/720): Loss: 0.000774\n",
            "===> Epoch[1](708/720): Loss: 0.000287\n",
            "===> Epoch[1](709/720): Loss: 0.000537\n",
            "===> Epoch[1](710/720): Loss: 0.001865\n",
            "===> Epoch[1](711/720): Loss: 0.000410\n",
            "===> Epoch[1](712/720): Loss: 0.000871\n",
            "===> Epoch[1](713/720): Loss: 0.000258\n",
            "===> Epoch[1](714/720): Loss: 0.001077\n",
            "===> Epoch[1](715/720): Loss: 0.000109\n",
            "===> Epoch[1](716/720): Loss: 0.000552\n",
            "===> Epoch[1](717/720): Loss: 0.000360\n",
            "===> Epoch[1](718/720): Loss: 0.000317\n",
            "===> Epoch[1](719/720): Loss: 0.000290\n",
            "===> Epoch[1](720/720): Loss: 0.000402\n",
            "===> Epoch 1 Complete: Avg. Loss: 0.004011\n",
            "=====>  Training 1 epochs completed\n",
            "=====>  Testing 1 epochs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "=====>  lr scheduler activated in 1 epochs completed\n",
            "=====>  Save checkpoint 1 epochs\n",
            "/content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_1.pth\n",
            "Checkpoint saved to /content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_1.pth\n",
            "=====>  Save checkpoint 1 epochs completed\n",
            "=====>  Training 2 epochs\n",
            "===> Training # 2 epoch\n",
            "===> Epoch[2](1/720): Loss: 0.000484\n",
            "===> Epoch[2](2/720): Loss: 0.000847\n",
            "===> Epoch[2](3/720): Loss: 0.000517\n",
            "===> Epoch[2](4/720): Loss: 0.000398\n",
            "===> Epoch[2](5/720): Loss: 0.001296\n",
            "===> Epoch[2](6/720): Loss: 0.000216\n",
            "===> Epoch[2](7/720): Loss: 0.000649\n",
            "===> Epoch[2](8/720): Loss: 0.001645\n",
            "===> Epoch[2](9/720): Loss: 0.000624\n",
            "===> Epoch[2](10/720): Loss: 0.000289\n",
            "===> Epoch[2](11/720): Loss: 0.000242\n",
            "===> Epoch[2](12/720): Loss: 0.001068\n",
            "===> Epoch[2](13/720): Loss: 0.000273\n",
            "===> Epoch[2](14/720): Loss: 0.001515\n",
            "===> Epoch[2](15/720): Loss: 0.000232\n",
            "===> Epoch[2](16/720): Loss: 0.000271\n",
            "===> Epoch[2](17/720): Loss: 0.000414\n",
            "===> Epoch[2](18/720): Loss: 0.001273\n",
            "===> Epoch[2](19/720): Loss: 0.000173\n",
            "===> Epoch[2](20/720): Loss: 0.000265\n",
            "===> Epoch[2](21/720): Loss: 0.000337\n",
            "===> Epoch[2](22/720): Loss: 0.000637\n",
            "===> Epoch[2](23/720): Loss: 0.000723\n",
            "===> Epoch[2](24/720): Loss: 0.000602\n",
            "===> Epoch[2](25/720): Loss: 0.001065\n",
            "===> Epoch[2](26/720): Loss: 0.000276\n",
            "===> Epoch[2](27/720): Loss: 0.000239\n",
            "===> Epoch[2](28/720): Loss: 0.000338\n",
            "===> Epoch[2](29/720): Loss: 0.000242\n",
            "===> Epoch[2](30/720): Loss: 0.000112\n",
            "===> Epoch[2](31/720): Loss: 0.000339\n",
            "===> Epoch[2](32/720): Loss: 0.000378\n",
            "===> Epoch[2](33/720): Loss: 0.000373\n",
            "===> Epoch[2](34/720): Loss: 0.000608\n",
            "===> Epoch[2](35/720): Loss: 0.000347\n",
            "===> Epoch[2](36/720): Loss: 0.000579\n",
            "===> Epoch[2](37/720): Loss: 0.001178\n",
            "===> Epoch[2](38/720): Loss: 0.000898\n",
            "===> Epoch[2](39/720): Loss: 0.000375\n",
            "===> Epoch[2](40/720): Loss: 0.000387\n",
            "===> Epoch[2](41/720): Loss: 0.002392\n",
            "===> Epoch[2](42/720): Loss: 0.001194\n",
            "===> Epoch[2](43/720): Loss: 0.001022\n",
            "===> Epoch[2](44/720): Loss: 0.000427\n",
            "===> Epoch[2](45/720): Loss: 0.001603\n",
            "===> Epoch[2](46/720): Loss: 0.000477\n",
            "===> Epoch[2](47/720): Loss: 0.000547\n",
            "===> Epoch[2](48/720): Loss: 0.001037\n",
            "===> Epoch[2](49/720): Loss: 0.001021\n",
            "===> Epoch[2](50/720): Loss: 0.000483\n",
            "===> Epoch[2](51/720): Loss: 0.000332\n",
            "===> Epoch[2](52/720): Loss: 0.001068\n",
            "===> Epoch[2](53/720): Loss: 0.001756\n",
            "===> Epoch[2](54/720): Loss: 0.002486\n",
            "===> Epoch[2](55/720): Loss: 0.001380\n",
            "===> Epoch[2](56/720): Loss: 0.000733\n",
            "===> Epoch[2](57/720): Loss: 0.001986\n",
            "===> Epoch[2](58/720): Loss: 0.000262\n",
            "===> Epoch[2](59/720): Loss: 0.000780\n",
            "===> Epoch[2](60/720): Loss: 0.001115\n",
            "===> Epoch[2](61/720): Loss: 0.000415\n",
            "===> Epoch[2](62/720): Loss: 0.000534\n",
            "===> Epoch[2](63/720): Loss: 0.000362\n",
            "===> Epoch[2](64/720): Loss: 0.000331\n",
            "===> Epoch[2](65/720): Loss: 0.000227\n",
            "===> Epoch[2](66/720): Loss: 0.000383\n",
            "===> Epoch[2](67/720): Loss: 0.001255\n",
            "===> Epoch[2](68/720): Loss: 0.000443\n",
            "===> Epoch[2](69/720): Loss: 0.000580\n",
            "===> Epoch[2](70/720): Loss: 0.001116\n",
            "===> Epoch[2](71/720): Loss: 0.001542\n",
            "===> Epoch[2](72/720): Loss: 0.002801\n",
            "===> Epoch[2](73/720): Loss: 0.000708\n",
            "===> Epoch[2](74/720): Loss: 0.001508\n",
            "===> Epoch[2](75/720): Loss: 0.003527\n",
            "===> Epoch[2](76/720): Loss: 0.000384\n",
            "===> Epoch[2](77/720): Loss: 0.002266\n",
            "===> Epoch[2](78/720): Loss: 0.005579\n",
            "===> Epoch[2](79/720): Loss: 0.001332\n",
            "===> Epoch[2](80/720): Loss: 0.003371\n",
            "===> Epoch[2](81/720): Loss: 0.006403\n",
            "===> Epoch[2](82/720): Loss: 0.003263\n",
            "===> Epoch[2](83/720): Loss: 0.009771\n",
            "===> Epoch[2](84/720): Loss: 0.005852\n",
            "===> Epoch[2](85/720): Loss: 0.001151\n",
            "===> Epoch[2](86/720): Loss: 0.004282\n",
            "===> Epoch[2](87/720): Loss: 0.002164\n",
            "===> Epoch[2](88/720): Loss: 0.001550\n",
            "===> Epoch[2](89/720): Loss: 0.001729\n",
            "===> Epoch[2](90/720): Loss: 0.000763\n",
            "===> Epoch[2](91/720): Loss: 0.000911\n",
            "===> Epoch[2](92/720): Loss: 0.000916\n",
            "===> Epoch[2](93/720): Loss: 0.002677\n",
            "===> Epoch[2](94/720): Loss: 0.000583\n",
            "===> Epoch[2](95/720): Loss: 0.003219\n",
            "===> Epoch[2](96/720): Loss: 0.000868\n",
            "===> Epoch[2](97/720): Loss: 0.002185\n",
            "===> Epoch[2](98/720): Loss: 0.000715\n",
            "===> Epoch[2](99/720): Loss: 0.001070\n",
            "===> Epoch[2](100/720): Loss: 0.001045\n",
            "===> Epoch[2](101/720): Loss: 0.001836\n",
            "===> Epoch[2](102/720): Loss: 0.000624\n",
            "===> Epoch[2](103/720): Loss: 0.000610\n",
            "===> Epoch[2](104/720): Loss: 0.001800\n",
            "===> Epoch[2](105/720): Loss: 0.000308\n",
            "===> Epoch[2](106/720): Loss: 0.000515\n",
            "===> Epoch[2](107/720): Loss: 0.000546\n",
            "===> Epoch[2](108/720): Loss: 0.000371\n",
            "===> Epoch[2](109/720): Loss: 0.000588\n",
            "===> Epoch[2](110/720): Loss: 0.000493\n",
            "===> Epoch[2](111/720): Loss: 0.000327\n",
            "===> Epoch[2](112/720): Loss: 0.000488\n",
            "===> Epoch[2](113/720): Loss: 0.000557\n",
            "===> Epoch[2](114/720): Loss: 0.001517\n",
            "===> Epoch[2](115/720): Loss: 0.000251\n",
            "===> Epoch[2](116/720): Loss: 0.001745\n",
            "===> Epoch[2](117/720): Loss: 0.001342\n",
            "===> Epoch[2](118/720): Loss: 0.000258\n",
            "===> Epoch[2](119/720): Loss: 0.000991\n",
            "===> Epoch[2](120/720): Loss: 0.000687\n",
            "===> Epoch[2](121/720): Loss: 0.000340\n",
            "===> Epoch[2](122/720): Loss: 0.002841\n",
            "===> Epoch[2](123/720): Loss: 0.000631\n",
            "===> Epoch[2](124/720): Loss: 0.001349\n",
            "===> Epoch[2](125/720): Loss: 0.000866\n",
            "===> Epoch[2](126/720): Loss: 0.000233\n",
            "===> Epoch[2](127/720): Loss: 0.000701\n",
            "===> Epoch[2](128/720): Loss: 0.000560\n",
            "===> Epoch[2](129/720): Loss: 0.000385\n",
            "===> Epoch[2](130/720): Loss: 0.000479\n",
            "===> Epoch[2](131/720): Loss: 0.000366\n",
            "===> Epoch[2](132/720): Loss: 0.001451\n",
            "===> Epoch[2](133/720): Loss: 0.000261\n",
            "===> Epoch[2](134/720): Loss: 0.000266\n",
            "===> Epoch[2](135/720): Loss: 0.000364\n",
            "===> Epoch[2](136/720): Loss: 0.001029\n",
            "===> Epoch[2](137/720): Loss: 0.001302\n",
            "===> Epoch[2](138/720): Loss: 0.001202\n",
            "===> Epoch[2](139/720): Loss: 0.000308\n",
            "===> Epoch[2](140/720): Loss: 0.000573\n",
            "===> Epoch[2](141/720): Loss: 0.001005\n",
            "===> Epoch[2](142/720): Loss: 0.000793\n",
            "===> Epoch[2](143/720): Loss: 0.000514\n",
            "===> Epoch[2](144/720): Loss: 0.000413\n",
            "===> Epoch[2](145/720): Loss: 0.001144\n",
            "===> Epoch[2](146/720): Loss: 0.000435\n",
            "===> Epoch[2](147/720): Loss: 0.001351\n",
            "===> Epoch[2](148/720): Loss: 0.001450\n",
            "===> Epoch[2](149/720): Loss: 0.000444\n",
            "===> Epoch[2](150/720): Loss: 0.000542\n",
            "===> Epoch[2](151/720): Loss: 0.000639\n",
            "===> Epoch[2](152/720): Loss: 0.000397\n",
            "===> Epoch[2](153/720): Loss: 0.000292\n",
            "===> Epoch[2](154/720): Loss: 0.000584\n",
            "===> Epoch[2](155/720): Loss: 0.001018\n",
            "===> Epoch[2](156/720): Loss: 0.000600\n",
            "===> Epoch[2](157/720): Loss: 0.000504\n",
            "===> Epoch[2](158/720): Loss: 0.000396\n",
            "===> Epoch[2](159/720): Loss: 0.000374\n",
            "===> Epoch[2](160/720): Loss: 0.000249\n",
            "===> Epoch[2](161/720): Loss: 0.001489\n",
            "===> Epoch[2](162/720): Loss: 0.000642\n",
            "===> Epoch[2](163/720): Loss: 0.000394\n",
            "===> Epoch[2](164/720): Loss: 0.000431\n",
            "===> Epoch[2](165/720): Loss: 0.000366\n",
            "===> Epoch[2](166/720): Loss: 0.000284\n",
            "===> Epoch[2](167/720): Loss: 0.000415\n",
            "===> Epoch[2](168/720): Loss: 0.000587\n",
            "===> Epoch[2](169/720): Loss: 0.000814\n",
            "===> Epoch[2](170/720): Loss: 0.000553\n",
            "===> Epoch[2](171/720): Loss: 0.000304\n",
            "===> Epoch[2](172/720): Loss: 0.000244\n",
            "===> Epoch[2](173/720): Loss: 0.000390\n",
            "===> Epoch[2](174/720): Loss: 0.000954\n",
            "===> Epoch[2](175/720): Loss: 0.001380\n",
            "===> Epoch[2](176/720): Loss: 0.001142\n",
            "===> Epoch[2](177/720): Loss: 0.000369\n",
            "===> Epoch[2](178/720): Loss: 0.000441\n",
            "===> Epoch[2](179/720): Loss: 0.000387\n",
            "===> Epoch[2](180/720): Loss: 0.001105\n",
            "===> Epoch[2](181/720): Loss: 0.000818\n",
            "===> Epoch[2](182/720): Loss: 0.000246\n",
            "===> Epoch[2](183/720): Loss: 0.000273\n",
            "===> Epoch[2](184/720): Loss: 0.000921\n",
            "===> Epoch[2](185/720): Loss: 0.000455\n",
            "===> Epoch[2](186/720): Loss: 0.000153\n",
            "===> Epoch[2](187/720): Loss: 0.000373\n",
            "===> Epoch[2](188/720): Loss: 0.000963\n",
            "===> Epoch[2](189/720): Loss: 0.000429\n",
            "===> Epoch[2](190/720): Loss: 0.000265\n",
            "===> Epoch[2](191/720): Loss: 0.003274\n",
            "===> Epoch[2](192/720): Loss: 0.000336\n",
            "===> Epoch[2](193/720): Loss: 0.000226\n",
            "===> Epoch[2](194/720): Loss: 0.000174\n",
            "===> Epoch[2](195/720): Loss: 0.000201\n",
            "===> Epoch[2](196/720): Loss: 0.000513\n",
            "===> Epoch[2](197/720): Loss: 0.000284\n",
            "===> Epoch[2](198/720): Loss: 0.000566\n",
            "===> Epoch[2](199/720): Loss: 0.000222\n",
            "===> Epoch[2](200/720): Loss: 0.000639\n",
            "===> Epoch[2](201/720): Loss: 0.000307\n",
            "===> Epoch[2](202/720): Loss: 0.000242\n",
            "===> Epoch[2](203/720): Loss: 0.001131\n",
            "===> Epoch[2](204/720): Loss: 0.000603\n",
            "===> Epoch[2](205/720): Loss: 0.000292\n",
            "===> Epoch[2](206/720): Loss: 0.000304\n",
            "===> Epoch[2](207/720): Loss: 0.001168\n",
            "===> Epoch[2](208/720): Loss: 0.000314\n",
            "===> Epoch[2](209/720): Loss: 0.000832\n",
            "===> Epoch[2](210/720): Loss: 0.000198\n",
            "===> Epoch[2](211/720): Loss: 0.000366\n",
            "===> Epoch[2](212/720): Loss: 0.000367\n",
            "===> Epoch[2](213/720): Loss: 0.002661\n",
            "===> Epoch[2](214/720): Loss: 0.000440\n",
            "===> Epoch[2](215/720): Loss: 0.000303\n",
            "===> Epoch[2](216/720): Loss: 0.000421\n",
            "===> Epoch[2](217/720): Loss: 0.000965\n",
            "===> Epoch[2](218/720): Loss: 0.000316\n",
            "===> Epoch[2](219/720): Loss: 0.000713\n",
            "===> Epoch[2](220/720): Loss: 0.000302\n",
            "===> Epoch[2](221/720): Loss: 0.001199\n",
            "===> Epoch[2](222/720): Loss: 0.000397\n",
            "===> Epoch[2](223/720): Loss: 0.000975\n",
            "===> Epoch[2](224/720): Loss: 0.000640\n",
            "===> Epoch[2](225/720): Loss: 0.000543\n",
            "===> Epoch[2](226/720): Loss: 0.001300\n",
            "===> Epoch[2](227/720): Loss: 0.000759\n",
            "===> Epoch[2](228/720): Loss: 0.000328\n",
            "===> Epoch[2](229/720): Loss: 0.000344\n",
            "===> Epoch[2](230/720): Loss: 0.000350\n",
            "===> Epoch[2](231/720): Loss: 0.000199\n",
            "===> Epoch[2](232/720): Loss: 0.000705\n",
            "===> Epoch[2](233/720): Loss: 0.000328\n",
            "===> Epoch[2](234/720): Loss: 0.000331\n",
            "===> Epoch[2](235/720): Loss: 0.001074\n",
            "===> Epoch[2](236/720): Loss: 0.000493\n",
            "===> Epoch[2](237/720): Loss: 0.002346\n",
            "===> Epoch[2](238/720): Loss: 0.001007\n",
            "===> Epoch[2](239/720): Loss: 0.000986\n",
            "===> Epoch[2](240/720): Loss: 0.000391\n",
            "===> Epoch[2](241/720): Loss: 0.000743\n",
            "===> Epoch[2](242/720): Loss: 0.001136\n",
            "===> Epoch[2](243/720): Loss: 0.000382\n",
            "===> Epoch[2](244/720): Loss: 0.000487\n",
            "===> Epoch[2](245/720): Loss: 0.000720\n",
            "===> Epoch[2](246/720): Loss: 0.000246\n",
            "===> Epoch[2](247/720): Loss: 0.000996\n",
            "===> Epoch[2](248/720): Loss: 0.000266\n",
            "===> Epoch[2](249/720): Loss: 0.000825\n",
            "===> Epoch[2](250/720): Loss: 0.000128\n",
            "===> Epoch[2](251/720): Loss: 0.000474\n",
            "===> Epoch[2](252/720): Loss: 0.000602\n",
            "===> Epoch[2](253/720): Loss: 0.000200\n",
            "===> Epoch[2](254/720): Loss: 0.000231\n",
            "===> Epoch[2](255/720): Loss: 0.000814\n",
            "===> Epoch[2](256/720): Loss: 0.000231\n",
            "===> Epoch[2](257/720): Loss: 0.000317\n",
            "===> Epoch[2](258/720): Loss: 0.000356\n",
            "===> Epoch[2](259/720): Loss: 0.000586\n",
            "===> Epoch[2](260/720): Loss: 0.000779\n",
            "===> Epoch[2](261/720): Loss: 0.001296\n",
            "===> Epoch[2](262/720): Loss: 0.001079\n",
            "===> Epoch[2](263/720): Loss: 0.000565\n",
            "===> Epoch[2](264/720): Loss: 0.000323\n",
            "===> Epoch[2](265/720): Loss: 0.000372\n",
            "===> Epoch[2](266/720): Loss: 0.000497\n",
            "===> Epoch[2](267/720): Loss: 0.000943\n",
            "===> Epoch[2](268/720): Loss: 0.000685\n",
            "===> Epoch[2](269/720): Loss: 0.000291\n",
            "===> Epoch[2](270/720): Loss: 0.001400\n",
            "===> Epoch[2](271/720): Loss: 0.000189\n",
            "===> Epoch[2](272/720): Loss: 0.001038\n",
            "===> Epoch[2](273/720): Loss: 0.000386\n",
            "===> Epoch[2](274/720): Loss: 0.000369\n",
            "===> Epoch[2](275/720): Loss: 0.000831\n",
            "===> Epoch[2](276/720): Loss: 0.001002\n",
            "===> Epoch[2](277/720): Loss: 0.000574\n",
            "===> Epoch[2](278/720): Loss: 0.001471\n",
            "===> Epoch[2](279/720): Loss: 0.000220\n",
            "===> Epoch[2](280/720): Loss: 0.001016\n",
            "===> Epoch[2](281/720): Loss: 0.000216\n",
            "===> Epoch[2](282/720): Loss: 0.000888\n",
            "===> Epoch[2](283/720): Loss: 0.000499\n",
            "===> Epoch[2](284/720): Loss: 0.000803\n",
            "===> Epoch[2](285/720): Loss: 0.000248\n",
            "===> Epoch[2](286/720): Loss: 0.000237\n",
            "===> Epoch[2](287/720): Loss: 0.000154\n",
            "===> Epoch[2](288/720): Loss: 0.000159\n",
            "===> Epoch[2](289/720): Loss: 0.001159\n",
            "===> Epoch[2](290/720): Loss: 0.001096\n",
            "===> Epoch[2](291/720): Loss: 0.000512\n",
            "===> Epoch[2](292/720): Loss: 0.000235\n",
            "===> Epoch[2](293/720): Loss: 0.000548\n",
            "===> Epoch[2](294/720): Loss: 0.000626\n",
            "===> Epoch[2](295/720): Loss: 0.000597\n",
            "===> Epoch[2](296/720): Loss: 0.000910\n",
            "===> Epoch[2](297/720): Loss: 0.000437\n",
            "===> Epoch[2](298/720): Loss: 0.000376\n",
            "===> Epoch[2](299/720): Loss: 0.000411\n",
            "===> Epoch[2](300/720): Loss: 0.000149\n",
            "===> Epoch[2](301/720): Loss: 0.000487\n",
            "===> Epoch[2](302/720): Loss: 0.000627\n",
            "===> Epoch[2](303/720): Loss: 0.001238\n",
            "===> Epoch[2](304/720): Loss: 0.000182\n",
            "===> Epoch[2](305/720): Loss: 0.000389\n",
            "===> Epoch[2](306/720): Loss: 0.000179\n",
            "===> Epoch[2](307/720): Loss: 0.000900\n",
            "===> Epoch[2](308/720): Loss: 0.000188\n",
            "===> Epoch[2](309/720): Loss: 0.001250\n",
            "===> Epoch[2](310/720): Loss: 0.000465\n",
            "===> Epoch[2](311/720): Loss: 0.000377\n",
            "===> Epoch[2](312/720): Loss: 0.000253\n",
            "===> Epoch[2](313/720): Loss: 0.000354\n",
            "===> Epoch[2](314/720): Loss: 0.000623\n",
            "===> Epoch[2](315/720): Loss: 0.000203\n",
            "===> Epoch[2](316/720): Loss: 0.000545\n",
            "===> Epoch[2](317/720): Loss: 0.001398\n",
            "===> Epoch[2](318/720): Loss: 0.000264\n",
            "===> Epoch[2](319/720): Loss: 0.000351\n",
            "===> Epoch[2](320/720): Loss: 0.000412\n",
            "===> Epoch[2](321/720): Loss: 0.000421\n",
            "===> Epoch[2](322/720): Loss: 0.001553\n",
            "===> Epoch[2](323/720): Loss: 0.000357\n",
            "===> Epoch[2](324/720): Loss: 0.000231\n",
            "===> Epoch[2](325/720): Loss: 0.001454\n",
            "===> Epoch[2](326/720): Loss: 0.001005\n",
            "===> Epoch[2](327/720): Loss: 0.000146\n",
            "===> Epoch[2](328/720): Loss: 0.000201\n",
            "===> Epoch[2](329/720): Loss: 0.000416\n",
            "===> Epoch[2](330/720): Loss: 0.000444\n",
            "===> Epoch[2](331/720): Loss: 0.002057\n",
            "===> Epoch[2](332/720): Loss: 0.000252\n",
            "===> Epoch[2](333/720): Loss: 0.000604\n",
            "===> Epoch[2](334/720): Loss: 0.000248\n",
            "===> Epoch[2](335/720): Loss: 0.000305\n",
            "===> Epoch[2](336/720): Loss: 0.001034\n",
            "===> Epoch[2](337/720): Loss: 0.000319\n",
            "===> Epoch[2](338/720): Loss: 0.000856\n",
            "===> Epoch[2](339/720): Loss: 0.000739\n",
            "===> Epoch[2](340/720): Loss: 0.000349\n",
            "===> Epoch[2](341/720): Loss: 0.001112\n",
            "===> Epoch[2](342/720): Loss: 0.002866\n",
            "===> Epoch[2](343/720): Loss: 0.000292\n",
            "===> Epoch[2](344/720): Loss: 0.000482\n",
            "===> Epoch[2](345/720): Loss: 0.000487\n",
            "===> Epoch[2](346/720): Loss: 0.000130\n",
            "===> Epoch[2](347/720): Loss: 0.000844\n",
            "===> Epoch[2](348/720): Loss: 0.000960\n",
            "===> Epoch[2](349/720): Loss: 0.001261\n",
            "===> Epoch[2](350/720): Loss: 0.001017\n",
            "===> Epoch[2](351/720): Loss: 0.000210\n",
            "===> Epoch[2](352/720): Loss: 0.001107\n",
            "===> Epoch[2](353/720): Loss: 0.000503\n",
            "===> Epoch[2](354/720): Loss: 0.000423\n",
            "===> Epoch[2](355/720): Loss: 0.000450\n",
            "===> Epoch[2](356/720): Loss: 0.000156\n",
            "===> Epoch[2](357/720): Loss: 0.000668\n",
            "===> Epoch[2](358/720): Loss: 0.000478\n",
            "===> Epoch[2](359/720): Loss: 0.000882\n",
            "===> Epoch[2](360/720): Loss: 0.001594\n",
            "===> Epoch[2](361/720): Loss: 0.000502\n",
            "===> Epoch[2](362/720): Loss: 0.000397\n",
            "===> Epoch[2](363/720): Loss: 0.000253\n",
            "===> Epoch[2](364/720): Loss: 0.001206\n",
            "===> Epoch[2](365/720): Loss: 0.000347\n",
            "===> Epoch[2](366/720): Loss: 0.001637\n",
            "===> Epoch[2](367/720): Loss: 0.000461\n",
            "===> Epoch[2](368/720): Loss: 0.000234\n",
            "===> Epoch[2](369/720): Loss: 0.000347\n",
            "===> Epoch[2](370/720): Loss: 0.000542\n",
            "===> Epoch[2](371/720): Loss: 0.001302\n",
            "===> Epoch[2](372/720): Loss: 0.000895\n",
            "===> Epoch[2](373/720): Loss: 0.000292\n",
            "===> Epoch[2](374/720): Loss: 0.000584\n",
            "===> Epoch[2](375/720): Loss: 0.000716\n",
            "===> Epoch[2](376/720): Loss: 0.000271\n",
            "===> Epoch[2](377/720): Loss: 0.000334\n",
            "===> Epoch[2](378/720): Loss: 0.000668\n",
            "===> Epoch[2](379/720): Loss: 0.000556\n",
            "===> Epoch[2](380/720): Loss: 0.000834\n",
            "===> Epoch[2](381/720): Loss: 0.000308\n",
            "===> Epoch[2](382/720): Loss: 0.000527\n",
            "===> Epoch[2](383/720): Loss: 0.001177\n",
            "===> Epoch[2](384/720): Loss: 0.000730\n",
            "===> Epoch[2](385/720): Loss: 0.001793\n",
            "===> Epoch[2](386/720): Loss: 0.000809\n",
            "===> Epoch[2](387/720): Loss: 0.000525\n",
            "===> Epoch[2](388/720): Loss: 0.000852\n",
            "===> Epoch[2](389/720): Loss: 0.000264\n",
            "===> Epoch[2](390/720): Loss: 0.001843\n",
            "===> Epoch[2](391/720): Loss: 0.000199\n",
            "===> Epoch[2](392/720): Loss: 0.000246\n",
            "===> Epoch[2](393/720): Loss: 0.001975\n",
            "===> Epoch[2](394/720): Loss: 0.000264\n",
            "===> Epoch[2](395/720): Loss: 0.000658\n",
            "===> Epoch[2](396/720): Loss: 0.000375\n",
            "===> Epoch[2](397/720): Loss: 0.000245\n",
            "===> Epoch[2](398/720): Loss: 0.000337\n",
            "===> Epoch[2](399/720): Loss: 0.000364\n",
            "===> Epoch[2](400/720): Loss: 0.000684\n",
            "===> Epoch[2](401/720): Loss: 0.000244\n",
            "===> Epoch[2](402/720): Loss: 0.000433\n",
            "===> Epoch[2](403/720): Loss: 0.000247\n",
            "===> Epoch[2](404/720): Loss: 0.000427\n",
            "===> Epoch[2](405/720): Loss: 0.000461\n",
            "===> Epoch[2](406/720): Loss: 0.000516\n",
            "===> Epoch[2](407/720): Loss: 0.000475\n",
            "===> Epoch[2](408/720): Loss: 0.000459\n",
            "===> Epoch[2](409/720): Loss: 0.000596\n",
            "===> Epoch[2](410/720): Loss: 0.000645\n",
            "===> Epoch[2](411/720): Loss: 0.000184\n",
            "===> Epoch[2](412/720): Loss: 0.000161\n",
            "===> Epoch[2](413/720): Loss: 0.000359\n",
            "===> Epoch[2](414/720): Loss: 0.000369\n",
            "===> Epoch[2](415/720): Loss: 0.001382\n",
            "===> Epoch[2](416/720): Loss: 0.000265\n",
            "===> Epoch[2](417/720): Loss: 0.000191\n",
            "===> Epoch[2](418/720): Loss: 0.000163\n",
            "===> Epoch[2](419/720): Loss: 0.000088\n",
            "===> Epoch[2](420/720): Loss: 0.001021\n",
            "===> Epoch[2](421/720): Loss: 0.000769\n",
            "===> Epoch[2](422/720): Loss: 0.000257\n",
            "===> Epoch[2](423/720): Loss: 0.000221\n",
            "===> Epoch[2](424/720): Loss: 0.000185\n",
            "===> Epoch[2](425/720): Loss: 0.000849\n",
            "===> Epoch[2](426/720): Loss: 0.000730\n",
            "===> Epoch[2](427/720): Loss: 0.000192\n",
            "===> Epoch[2](428/720): Loss: 0.000251\n",
            "===> Epoch[2](429/720): Loss: 0.000732\n",
            "===> Epoch[2](430/720): Loss: 0.000353\n",
            "===> Epoch[2](431/720): Loss: 0.000268\n",
            "===> Epoch[2](432/720): Loss: 0.000267\n",
            "===> Epoch[2](433/720): Loss: 0.000546\n",
            "===> Epoch[2](434/720): Loss: 0.000521\n",
            "===> Epoch[2](435/720): Loss: 0.000453\n",
            "===> Epoch[2](436/720): Loss: 0.000361\n",
            "===> Epoch[2](437/720): Loss: 0.001236\n",
            "===> Epoch[2](438/720): Loss: 0.000130\n",
            "===> Epoch[2](439/720): Loss: 0.000900\n",
            "===> Epoch[2](440/720): Loss: 0.000572\n",
            "===> Epoch[2](441/720): Loss: 0.000274\n",
            "===> Epoch[2](442/720): Loss: 0.000264\n",
            "===> Epoch[2](443/720): Loss: 0.001054\n",
            "===> Epoch[2](444/720): Loss: 0.000971\n",
            "===> Epoch[2](445/720): Loss: 0.000356\n",
            "===> Epoch[2](446/720): Loss: 0.000764\n",
            "===> Epoch[2](447/720): Loss: 0.000406\n",
            "===> Epoch[2](448/720): Loss: 0.000768\n",
            "===> Epoch[2](449/720): Loss: 0.000859\n",
            "===> Epoch[2](450/720): Loss: 0.000873\n",
            "===> Epoch[2](451/720): Loss: 0.000249\n",
            "===> Epoch[2](452/720): Loss: 0.000451\n",
            "===> Epoch[2](453/720): Loss: 0.000640\n",
            "===> Epoch[2](454/720): Loss: 0.000683\n",
            "===> Epoch[2](455/720): Loss: 0.000255\n",
            "===> Epoch[2](456/720): Loss: 0.000388\n",
            "===> Epoch[2](457/720): Loss: 0.001196\n",
            "===> Epoch[2](458/720): Loss: 0.000523\n",
            "===> Epoch[2](459/720): Loss: 0.000301\n",
            "===> Epoch[2](460/720): Loss: 0.000360\n",
            "===> Epoch[2](461/720): Loss: 0.000665\n",
            "===> Epoch[2](462/720): Loss: 0.000956\n",
            "===> Epoch[2](463/720): Loss: 0.000289\n",
            "===> Epoch[2](464/720): Loss: 0.000961\n",
            "===> Epoch[2](465/720): Loss: 0.000263\n",
            "===> Epoch[2](466/720): Loss: 0.000212\n",
            "===> Epoch[2](467/720): Loss: 0.000912\n",
            "===> Epoch[2](468/720): Loss: 0.001400\n",
            "===> Epoch[2](469/720): Loss: 0.002065\n",
            "===> Epoch[2](470/720): Loss: 0.000216\n",
            "===> Epoch[2](471/720): Loss: 0.000216\n",
            "===> Epoch[2](472/720): Loss: 0.000253\n",
            "===> Epoch[2](473/720): Loss: 0.000206\n",
            "===> Epoch[2](474/720): Loss: 0.000260\n",
            "===> Epoch[2](475/720): Loss: 0.000306\n",
            "===> Epoch[2](476/720): Loss: 0.000820\n",
            "===> Epoch[2](477/720): Loss: 0.000299\n",
            "===> Epoch[2](478/720): Loss: 0.000197\n",
            "===> Epoch[2](479/720): Loss: 0.000991\n",
            "===> Epoch[2](480/720): Loss: 0.000152\n",
            "===> Epoch[2](481/720): Loss: 0.001420\n",
            "===> Epoch[2](482/720): Loss: 0.000272\n",
            "===> Epoch[2](483/720): Loss: 0.000177\n",
            "===> Epoch[2](484/720): Loss: 0.000280\n",
            "===> Epoch[2](485/720): Loss: 0.000218\n",
            "===> Epoch[2](486/720): Loss: 0.000194\n",
            "===> Epoch[2](487/720): Loss: 0.000247\n",
            "===> Epoch[2](488/720): Loss: 0.000622\n",
            "===> Epoch[2](489/720): Loss: 0.000452\n",
            "===> Epoch[2](490/720): Loss: 0.000129\n",
            "===> Epoch[2](491/720): Loss: 0.000412\n",
            "===> Epoch[2](492/720): Loss: 0.000189\n",
            "===> Epoch[2](493/720): Loss: 0.000376\n",
            "===> Epoch[2](494/720): Loss: 0.001876\n",
            "===> Epoch[2](495/720): Loss: 0.000228\n",
            "===> Epoch[2](496/720): Loss: 0.001102\n",
            "===> Epoch[2](497/720): Loss: 0.000188\n",
            "===> Epoch[2](498/720): Loss: 0.000376\n",
            "===> Epoch[2](499/720): Loss: 0.000459\n",
            "===> Epoch[2](500/720): Loss: 0.000271\n",
            "===> Epoch[2](501/720): Loss: 0.000524\n",
            "===> Epoch[2](502/720): Loss: 0.000326\n",
            "===> Epoch[2](503/720): Loss: 0.000257\n",
            "===> Epoch[2](504/720): Loss: 0.000574\n",
            "===> Epoch[2](505/720): Loss: 0.000304\n",
            "===> Epoch[2](506/720): Loss: 0.000259\n",
            "===> Epoch[2](507/720): Loss: 0.000458\n",
            "===> Epoch[2](508/720): Loss: 0.000747\n",
            "===> Epoch[2](509/720): Loss: 0.004864\n",
            "===> Epoch[2](510/720): Loss: 0.002523\n",
            "===> Epoch[2](511/720): Loss: 0.000922\n",
            "===> Epoch[2](512/720): Loss: 0.001233\n",
            "===> Epoch[2](513/720): Loss: 0.001579\n",
            "===> Epoch[2](514/720): Loss: 0.000381\n",
            "===> Epoch[2](515/720): Loss: 0.001256\n",
            "===> Epoch[2](516/720): Loss: 0.000998\n",
            "===> Epoch[2](517/720): Loss: 0.001291\n",
            "===> Epoch[2](518/720): Loss: 0.004690\n",
            "===> Epoch[2](519/720): Loss: 0.002284\n",
            "===> Epoch[2](520/720): Loss: 0.000625\n",
            "===> Epoch[2](521/720): Loss: 0.004658\n",
            "===> Epoch[2](522/720): Loss: 0.002728\n",
            "===> Epoch[2](523/720): Loss: 0.003052\n",
            "===> Epoch[2](524/720): Loss: 0.002700\n",
            "===> Epoch[2](525/720): Loss: 0.000391\n",
            "===> Epoch[2](526/720): Loss: 0.001636\n",
            "===> Epoch[2](527/720): Loss: 0.000629\n",
            "===> Epoch[2](528/720): Loss: 0.001179\n",
            "===> Epoch[2](529/720): Loss: 0.000744\n",
            "===> Epoch[2](530/720): Loss: 0.001447\n",
            "===> Epoch[2](531/720): Loss: 0.000443\n",
            "===> Epoch[2](532/720): Loss: 0.001361\n",
            "===> Epoch[2](533/720): Loss: 0.001897\n",
            "===> Epoch[2](534/720): Loss: 0.000641\n",
            "===> Epoch[2](535/720): Loss: 0.001958\n",
            "===> Epoch[2](536/720): Loss: 0.000987\n",
            "===> Epoch[2](537/720): Loss: 0.000635\n",
            "===> Epoch[2](538/720): Loss: 0.001364\n",
            "===> Epoch[2](539/720): Loss: 0.001806\n",
            "===> Epoch[2](540/720): Loss: 0.000403\n",
            "===> Epoch[2](541/720): Loss: 0.001549\n",
            "===> Epoch[2](542/720): Loss: 0.000227\n",
            "===> Epoch[2](543/720): Loss: 0.001012\n",
            "===> Epoch[2](544/720): Loss: 0.000412\n",
            "===> Epoch[2](545/720): Loss: 0.000875\n",
            "===> Epoch[2](546/720): Loss: 0.001012\n",
            "===> Epoch[2](547/720): Loss: 0.000582\n",
            "===> Epoch[2](548/720): Loss: 0.000700\n",
            "===> Epoch[2](549/720): Loss: 0.000283\n",
            "===> Epoch[2](550/720): Loss: 0.000616\n",
            "===> Epoch[2](551/720): Loss: 0.000530\n",
            "===> Epoch[2](552/720): Loss: 0.000482\n",
            "===> Epoch[2](553/720): Loss: 0.000221\n",
            "===> Epoch[2](554/720): Loss: 0.000806\n",
            "===> Epoch[2](555/720): Loss: 0.001265\n",
            "===> Epoch[2](556/720): Loss: 0.000411\n",
            "===> Epoch[2](557/720): Loss: 0.000682\n",
            "===> Epoch[2](558/720): Loss: 0.001363\n",
            "===> Epoch[2](559/720): Loss: 0.000812\n",
            "===> Epoch[2](560/720): Loss: 0.000901\n",
            "===> Epoch[2](561/720): Loss: 0.000697\n",
            "===> Epoch[2](562/720): Loss: 0.000817\n",
            "===> Epoch[2](563/720): Loss: 0.000494\n",
            "===> Epoch[2](564/720): Loss: 0.000408\n",
            "===> Epoch[2](565/720): Loss: 0.000632\n",
            "===> Epoch[2](566/720): Loss: 0.000849\n",
            "===> Epoch[2](567/720): Loss: 0.000221\n",
            "===> Epoch[2](568/720): Loss: 0.000613\n",
            "===> Epoch[2](569/720): Loss: 0.000368\n",
            "===> Epoch[2](570/720): Loss: 0.000685\n",
            "===> Epoch[2](571/720): Loss: 0.001101\n",
            "===> Epoch[2](572/720): Loss: 0.000269\n",
            "===> Epoch[2](573/720): Loss: 0.000261\n",
            "===> Epoch[2](574/720): Loss: 0.000340\n",
            "===> Epoch[2](575/720): Loss: 0.000417\n",
            "===> Epoch[2](576/720): Loss: 0.000237\n",
            "===> Epoch[2](577/720): Loss: 0.000949\n",
            "===> Epoch[2](578/720): Loss: 0.000158\n",
            "===> Epoch[2](579/720): Loss: 0.002675\n",
            "===> Epoch[2](580/720): Loss: 0.000210\n",
            "===> Epoch[2](581/720): Loss: 0.002973\n",
            "===> Epoch[2](582/720): Loss: 0.000549\n",
            "===> Epoch[2](583/720): Loss: 0.001173\n",
            "===> Epoch[2](584/720): Loss: 0.000587\n",
            "===> Epoch[2](585/720): Loss: 0.000411\n",
            "===> Epoch[2](586/720): Loss: 0.000444\n",
            "===> Epoch[2](587/720): Loss: 0.001103\n",
            "===> Epoch[2](588/720): Loss: 0.000138\n",
            "===> Epoch[2](589/720): Loss: 0.000387\n",
            "===> Epoch[2](590/720): Loss: 0.000579\n",
            "===> Epoch[2](591/720): Loss: 0.000297\n",
            "===> Epoch[2](592/720): Loss: 0.002425\n",
            "===> Epoch[2](593/720): Loss: 0.000269\n",
            "===> Epoch[2](594/720): Loss: 0.000331\n",
            "===> Epoch[2](595/720): Loss: 0.000382\n",
            "===> Epoch[2](596/720): Loss: 0.000488\n",
            "===> Epoch[2](597/720): Loss: 0.000225\n",
            "===> Epoch[2](598/720): Loss: 0.000145\n",
            "===> Epoch[2](599/720): Loss: 0.000288\n",
            "===> Epoch[2](600/720): Loss: 0.000302\n",
            "===> Epoch[2](601/720): Loss: 0.000430\n",
            "===> Epoch[2](602/720): Loss: 0.000282\n",
            "===> Epoch[2](603/720): Loss: 0.000302\n",
            "===> Epoch[2](604/720): Loss: 0.000166\n",
            "===> Epoch[2](605/720): Loss: 0.000471\n",
            "===> Epoch[2](606/720): Loss: 0.000862\n",
            "===> Epoch[2](607/720): Loss: 0.001741\n",
            "===> Epoch[2](608/720): Loss: 0.000092\n",
            "===> Epoch[2](609/720): Loss: 0.000445\n",
            "===> Epoch[2](610/720): Loss: 0.000270\n",
            "===> Epoch[2](611/720): Loss: 0.000403\n",
            "===> Epoch[2](612/720): Loss: 0.000877\n",
            "===> Epoch[2](613/720): Loss: 0.000519\n",
            "===> Epoch[2](614/720): Loss: 0.000943\n",
            "===> Epoch[2](615/720): Loss: 0.000970\n",
            "===> Epoch[2](616/720): Loss: 0.000325\n",
            "===> Epoch[2](617/720): Loss: 0.000312\n",
            "===> Epoch[2](618/720): Loss: 0.000194\n",
            "===> Epoch[2](619/720): Loss: 0.000627\n",
            "===> Epoch[2](620/720): Loss: 0.000328\n",
            "===> Epoch[2](621/720): Loss: 0.000891\n",
            "===> Epoch[2](622/720): Loss: 0.000363\n",
            "===> Epoch[2](623/720): Loss: 0.000188\n",
            "===> Epoch[2](624/720): Loss: 0.000515\n",
            "===> Epoch[2](625/720): Loss: 0.000244\n",
            "===> Epoch[2](626/720): Loss: 0.000192\n",
            "===> Epoch[2](627/720): Loss: 0.000209\n",
            "===> Epoch[2](628/720): Loss: 0.000204\n",
            "===> Epoch[2](629/720): Loss: 0.000425\n",
            "===> Epoch[2](630/720): Loss: 0.000441\n",
            "===> Epoch[2](631/720): Loss: 0.000326\n",
            "===> Epoch[2](632/720): Loss: 0.000996\n",
            "===> Epoch[2](633/720): Loss: 0.001083\n",
            "===> Epoch[2](634/720): Loss: 0.000845\n",
            "===> Epoch[2](635/720): Loss: 0.000496\n",
            "===> Epoch[2](636/720): Loss: 0.000682\n",
            "===> Epoch[2](637/720): Loss: 0.000698\n",
            "===> Epoch[2](638/720): Loss: 0.000188\n",
            "===> Epoch[2](639/720): Loss: 0.000531\n",
            "===> Epoch[2](640/720): Loss: 0.001740\n",
            "===> Epoch[2](641/720): Loss: 0.001904\n",
            "===> Epoch[2](642/720): Loss: 0.000812\n",
            "===> Epoch[2](643/720): Loss: 0.003173\n",
            "===> Epoch[2](644/720): Loss: 0.001082\n",
            "===> Epoch[2](645/720): Loss: 0.002498\n",
            "===> Epoch[2](646/720): Loss: 0.001287\n",
            "===> Epoch[2](647/720): Loss: 0.001410\n",
            "===> Epoch[2](648/720): Loss: 0.002060\n",
            "===> Epoch[2](649/720): Loss: 0.001059\n",
            "===> Epoch[2](650/720): Loss: 0.003039\n",
            "===> Epoch[2](651/720): Loss: 0.000462\n",
            "===> Epoch[2](652/720): Loss: 0.003676\n",
            "===> Epoch[2](653/720): Loss: 0.001037\n",
            "===> Epoch[2](654/720): Loss: 0.001487\n",
            "===> Epoch[2](655/720): Loss: 0.002106\n",
            "===> Epoch[2](656/720): Loss: 0.001660\n",
            "===> Epoch[2](657/720): Loss: 0.004149\n",
            "===> Epoch[2](658/720): Loss: 0.000474\n",
            "===> Epoch[2](659/720): Loss: 0.002424\n",
            "===> Epoch[2](660/720): Loss: 0.000328\n",
            "===> Epoch[2](661/720): Loss: 0.002074\n",
            "===> Epoch[2](662/720): Loss: 0.002079\n",
            "===> Epoch[2](663/720): Loss: 0.000960\n",
            "===> Epoch[2](664/720): Loss: 0.000917\n",
            "===> Epoch[2](665/720): Loss: 0.000496\n",
            "===> Epoch[2](666/720): Loss: 0.000794\n",
            "===> Epoch[2](667/720): Loss: 0.001862\n",
            "===> Epoch[2](668/720): Loss: 0.002848\n",
            "===> Epoch[2](669/720): Loss: 0.001282\n",
            "===> Epoch[2](670/720): Loss: 0.001450\n",
            "===> Epoch[2](671/720): Loss: 0.000371\n",
            "===> Epoch[2](672/720): Loss: 0.001780\n",
            "===> Epoch[2](673/720): Loss: 0.000593\n",
            "===> Epoch[2](674/720): Loss: 0.001974\n",
            "===> Epoch[2](675/720): Loss: 0.001015\n",
            "===> Epoch[2](676/720): Loss: 0.001288\n",
            "===> Epoch[2](677/720): Loss: 0.002036\n",
            "===> Epoch[2](678/720): Loss: 0.001705\n",
            "===> Epoch[2](679/720): Loss: 0.002395\n",
            "===> Epoch[2](680/720): Loss: 0.000783\n",
            "===> Epoch[2](681/720): Loss: 0.001474\n",
            "===> Epoch[2](682/720): Loss: 0.001179\n",
            "===> Epoch[2](683/720): Loss: 0.002468\n",
            "===> Epoch[2](684/720): Loss: 0.000713\n",
            "===> Epoch[2](685/720): Loss: 0.000861\n",
            "===> Epoch[2](686/720): Loss: 0.000739\n",
            "===> Epoch[2](687/720): Loss: 0.001288\n",
            "===> Epoch[2](688/720): Loss: 0.000964\n",
            "===> Epoch[2](689/720): Loss: 0.000894\n",
            "===> Epoch[2](690/720): Loss: 0.001487\n",
            "===> Epoch[2](691/720): Loss: 0.001007\n",
            "===> Epoch[2](692/720): Loss: 0.000717\n",
            "===> Epoch[2](693/720): Loss: 0.000837\n",
            "===> Epoch[2](694/720): Loss: 0.000957\n",
            "===> Epoch[2](695/720): Loss: 0.000810\n",
            "===> Epoch[2](696/720): Loss: 0.000964\n",
            "===> Epoch[2](697/720): Loss: 0.000464\n",
            "===> Epoch[2](698/720): Loss: 0.001799\n",
            "===> Epoch[2](699/720): Loss: 0.000793\n",
            "===> Epoch[2](700/720): Loss: 0.000413\n",
            "===> Epoch[2](701/720): Loss: 0.000527\n",
            "===> Epoch[2](702/720): Loss: 0.000372\n",
            "===> Epoch[2](703/720): Loss: 0.000555\n",
            "===> Epoch[2](704/720): Loss: 0.000724\n",
            "===> Epoch[2](705/720): Loss: 0.001369\n",
            "===> Epoch[2](706/720): Loss: 0.000533\n",
            "===> Epoch[2](707/720): Loss: 0.000744\n",
            "===> Epoch[2](708/720): Loss: 0.000760\n",
            "===> Epoch[2](709/720): Loss: 0.000357\n",
            "===> Epoch[2](710/720): Loss: 0.000788\n",
            "===> Epoch[2](711/720): Loss: 0.000203\n",
            "===> Epoch[2](712/720): Loss: 0.000594\n",
            "===> Epoch[2](713/720): Loss: 0.000146\n",
            "===> Epoch[2](714/720): Loss: 0.000682\n",
            "===> Epoch[2](715/720): Loss: 0.000337\n",
            "===> Epoch[2](716/720): Loss: 0.000333\n",
            "===> Epoch[2](717/720): Loss: 0.000259\n",
            "===> Epoch[2](718/720): Loss: 0.000223\n",
            "===> Epoch[2](719/720): Loss: 0.000303\n",
            "===> Epoch[2](720/720): Loss: 0.000442\n",
            "===> Epoch 2 Complete: Avg. Loss: 0.000817\n",
            "=====>  Training 2 epochs completed\n",
            "=====>  Testing 2 epochs\n",
            "=====>  lr scheduler activated in 2 epochs completed\n",
            "=====>  Save checkpoint 2 epochs\n",
            "/content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_2.pth\n",
            "Checkpoint saved to /content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_2.pth\n",
            "=====>  Save checkpoint 2 epochs completed\n",
            "=====>  Training 3 epochs\n",
            "===> Training # 3 epoch\n",
            "===> Epoch[3](1/720): Loss: 0.000268\n",
            "===> Epoch[3](2/720): Loss: 0.000174\n",
            "===> Epoch[3](3/720): Loss: 0.000903\n",
            "===> Epoch[3](4/720): Loss: 0.001445\n",
            "===> Epoch[3](5/720): Loss: 0.001003\n",
            "===> Epoch[3](6/720): Loss: 0.000574\n",
            "===> Epoch[3](7/720): Loss: 0.000254\n",
            "===> Epoch[3](8/720): Loss: 0.001135\n",
            "===> Epoch[3](9/720): Loss: 0.000245\n",
            "===> Epoch[3](10/720): Loss: 0.000227\n",
            "===> Epoch[3](11/720): Loss: 0.000282\n",
            "===> Epoch[3](12/720): Loss: 0.000249\n",
            "===> Epoch[3](13/720): Loss: 0.000997\n",
            "===> Epoch[3](14/720): Loss: 0.000856\n",
            "===> Epoch[3](15/720): Loss: 0.000474\n",
            "===> Epoch[3](16/720): Loss: 0.000482\n",
            "===> Epoch[3](17/720): Loss: 0.000347\n",
            "===> Epoch[3](18/720): Loss: 0.000212\n",
            "===> Epoch[3](19/720): Loss: 0.000744\n",
            "===> Epoch[3](20/720): Loss: 0.000663\n",
            "===> Epoch[3](21/720): Loss: 0.000292\n",
            "===> Epoch[3](22/720): Loss: 0.000309\n",
            "===> Epoch[3](23/720): Loss: 0.000310\n",
            "===> Epoch[3](24/720): Loss: 0.000162\n",
            "===> Epoch[3](25/720): Loss: 0.000846\n",
            "===> Epoch[3](26/720): Loss: 0.001040\n",
            "===> Epoch[3](27/720): Loss: 0.000511\n",
            "===> Epoch[3](28/720): Loss: 0.000320\n",
            "===> Epoch[3](29/720): Loss: 0.000249\n",
            "===> Epoch[3](30/720): Loss: 0.000635\n",
            "===> Epoch[3](31/720): Loss: 0.001010\n",
            "===> Epoch[3](32/720): Loss: 0.000384\n",
            "===> Epoch[3](33/720): Loss: 0.000165\n",
            "===> Epoch[3](34/720): Loss: 0.000256\n",
            "===> Epoch[3](35/720): Loss: 0.000945\n",
            "===> Epoch[3](36/720): Loss: 0.000516\n",
            "===> Epoch[3](37/720): Loss: 0.000781\n",
            "===> Epoch[3](38/720): Loss: 0.001077\n",
            "===> Epoch[3](39/720): Loss: 0.000474\n",
            "===> Epoch[3](40/720): Loss: 0.000293\n",
            "===> Epoch[3](41/720): Loss: 0.000744\n",
            "===> Epoch[3](42/720): Loss: 0.000858\n",
            "===> Epoch[3](43/720): Loss: 0.000604\n",
            "===> Epoch[3](44/720): Loss: 0.000309\n",
            "===> Epoch[3](45/720): Loss: 0.000261\n",
            "===> Epoch[3](46/720): Loss: 0.000220\n",
            "===> Epoch[3](47/720): Loss: 0.000136\n",
            "===> Epoch[3](48/720): Loss: 0.000277\n",
            "===> Epoch[3](49/720): Loss: 0.000229\n",
            "===> Epoch[3](50/720): Loss: 0.000905\n",
            "===> Epoch[3](51/720): Loss: 0.000594\n",
            "===> Epoch[3](52/720): Loss: 0.000167\n",
            "===> Epoch[3](53/720): Loss: 0.000366\n",
            "===> Epoch[3](54/720): Loss: 0.001254\n",
            "===> Epoch[3](55/720): Loss: 0.000151\n",
            "===> Epoch[3](56/720): Loss: 0.000611\n",
            "===> Epoch[3](57/720): Loss: 0.000605\n",
            "===> Epoch[3](58/720): Loss: 0.000366\n",
            "===> Epoch[3](59/720): Loss: 0.000258\n",
            "===> Epoch[3](60/720): Loss: 0.000653\n",
            "===> Epoch[3](61/720): Loss: 0.000377\n",
            "===> Epoch[3](62/720): Loss: 0.000908\n",
            "===> Epoch[3](63/720): Loss: 0.000861\n",
            "===> Epoch[3](64/720): Loss: 0.001727\n",
            "===> Epoch[3](65/720): Loss: 0.000231\n",
            "===> Epoch[3](66/720): Loss: 0.000690\n",
            "===> Epoch[3](67/720): Loss: 0.000519\n",
            "===> Epoch[3](68/720): Loss: 0.000511\n",
            "===> Epoch[3](69/720): Loss: 0.000231\n",
            "===> Epoch[3](70/720): Loss: 0.000676\n",
            "===> Epoch[3](71/720): Loss: 0.000526\n",
            "===> Epoch[3](72/720): Loss: 0.000399\n",
            "===> Epoch[3](73/720): Loss: 0.000434\n",
            "===> Epoch[3](74/720): Loss: 0.000271\n",
            "===> Epoch[3](75/720): Loss: 0.000488\n",
            "===> Epoch[3](76/720): Loss: 0.000943\n",
            "===> Epoch[3](77/720): Loss: 0.000312\n",
            "===> Epoch[3](78/720): Loss: 0.000893\n",
            "===> Epoch[3](79/720): Loss: 0.000841\n",
            "===> Epoch[3](80/720): Loss: 0.001540\n",
            "===> Epoch[3](81/720): Loss: 0.000142\n",
            "===> Epoch[3](82/720): Loss: 0.000375\n",
            "===> Epoch[3](83/720): Loss: 0.000346\n",
            "===> Epoch[3](84/720): Loss: 0.000171\n",
            "===> Epoch[3](85/720): Loss: 0.001909\n",
            "===> Epoch[3](86/720): Loss: 0.000452\n",
            "===> Epoch[3](87/720): Loss: 0.000221\n",
            "===> Epoch[3](88/720): Loss: 0.002657\n",
            "===> Epoch[3](89/720): Loss: 0.000945\n",
            "===> Epoch[3](90/720): Loss: 0.000569\n",
            "===> Epoch[3](91/720): Loss: 0.000621\n",
            "===> Epoch[3](92/720): Loss: 0.000385\n",
            "===> Epoch[3](93/720): Loss: 0.000371\n",
            "===> Epoch[3](94/720): Loss: 0.000249\n",
            "===> Epoch[3](95/720): Loss: 0.001022\n",
            "===> Epoch[3](96/720): Loss: 0.000607\n",
            "===> Epoch[3](97/720): Loss: 0.000228\n",
            "===> Epoch[3](98/720): Loss: 0.002035\n",
            "===> Epoch[3](99/720): Loss: 0.000284\n",
            "===> Epoch[3](100/720): Loss: 0.000563\n",
            "===> Epoch[3](101/720): Loss: 0.001460\n",
            "===> Epoch[3](102/720): Loss: 0.000538\n",
            "===> Epoch[3](103/720): Loss: 0.000444\n",
            "===> Epoch[3](104/720): Loss: 0.000909\n",
            "===> Epoch[3](105/720): Loss: 0.000218\n",
            "===> Epoch[3](106/720): Loss: 0.000446\n",
            "===> Epoch[3](107/720): Loss: 0.000224\n",
            "===> Epoch[3](108/720): Loss: 0.000356\n",
            "===> Epoch[3](109/720): Loss: 0.000587\n",
            "===> Epoch[3](110/720): Loss: 0.000376\n",
            "===> Epoch[3](111/720): Loss: 0.000639\n",
            "===> Epoch[3](112/720): Loss: 0.000575\n",
            "===> Epoch[3](113/720): Loss: 0.000261\n",
            "===> Epoch[3](114/720): Loss: 0.001076\n",
            "===> Epoch[3](115/720): Loss: 0.000266\n",
            "===> Epoch[3](116/720): Loss: 0.000311\n",
            "===> Epoch[3](117/720): Loss: 0.000400\n",
            "===> Epoch[3](118/720): Loss: 0.000381\n",
            "===> Epoch[3](119/720): Loss: 0.000121\n",
            "===> Epoch[3](120/720): Loss: 0.000315\n",
            "===> Epoch[3](121/720): Loss: 0.000320\n",
            "===> Epoch[3](122/720): Loss: 0.001057\n",
            "===> Epoch[3](123/720): Loss: 0.001165\n",
            "===> Epoch[3](124/720): Loss: 0.000637\n",
            "===> Epoch[3](125/720): Loss: 0.000466\n",
            "===> Epoch[3](126/720): Loss: 0.000242\n",
            "===> Epoch[3](127/720): Loss: 0.000567\n",
            "===> Epoch[3](128/720): Loss: 0.001009\n",
            "===> Epoch[3](129/720): Loss: 0.000313\n",
            "===> Epoch[3](130/720): Loss: 0.000183\n",
            "===> Epoch[3](131/720): Loss: 0.000387\n",
            "===> Epoch[3](132/720): Loss: 0.000497\n",
            "===> Epoch[3](133/720): Loss: 0.000151\n",
            "===> Epoch[3](134/720): Loss: 0.001228\n",
            "===> Epoch[3](135/720): Loss: 0.000121\n",
            "===> Epoch[3](136/720): Loss: 0.000609\n",
            "===> Epoch[3](137/720): Loss: 0.000171\n",
            "===> Epoch[3](138/720): Loss: 0.000323\n",
            "===> Epoch[3](139/720): Loss: 0.000269\n",
            "===> Epoch[3](140/720): Loss: 0.000388\n",
            "===> Epoch[3](141/720): Loss: 0.000897\n",
            "===> Epoch[3](142/720): Loss: 0.000182\n",
            "===> Epoch[3](143/720): Loss: 0.000699\n",
            "===> Epoch[3](144/720): Loss: 0.002081\n",
            "===> Epoch[3](145/720): Loss: 0.000578\n",
            "===> Epoch[3](146/720): Loss: 0.000241\n",
            "===> Epoch[3](147/720): Loss: 0.000222\n",
            "===> Epoch[3](148/720): Loss: 0.000196\n",
            "===> Epoch[3](149/720): Loss: 0.001057\n",
            "===> Epoch[3](150/720): Loss: 0.000345\n",
            "===> Epoch[3](151/720): Loss: 0.000328\n",
            "===> Epoch[3](152/720): Loss: 0.000694\n",
            "===> Epoch[3](153/720): Loss: 0.000579\n",
            "===> Epoch[3](154/720): Loss: 0.000346\n",
            "===> Epoch[3](155/720): Loss: 0.000348\n",
            "===> Epoch[3](156/720): Loss: 0.000469\n",
            "===> Epoch[3](157/720): Loss: 0.001564\n",
            "===> Epoch[3](158/720): Loss: 0.000448\n",
            "===> Epoch[3](159/720): Loss: 0.000792\n",
            "===> Epoch[3](160/720): Loss: 0.000175\n",
            "===> Epoch[3](161/720): Loss: 0.000684\n",
            "===> Epoch[3](162/720): Loss: 0.000487\n",
            "===> Epoch[3](163/720): Loss: 0.000306\n",
            "===> Epoch[3](164/720): Loss: 0.000689\n",
            "===> Epoch[3](165/720): Loss: 0.000164\n",
            "===> Epoch[3](166/720): Loss: 0.000354\n",
            "===> Epoch[3](167/720): Loss: 0.000162\n",
            "===> Epoch[3](168/720): Loss: 0.000796\n",
            "===> Epoch[3](169/720): Loss: 0.000514\n",
            "===> Epoch[3](170/720): Loss: 0.000176\n",
            "===> Epoch[3](171/720): Loss: 0.000506\n",
            "===> Epoch[3](172/720): Loss: 0.000349\n",
            "===> Epoch[3](173/720): Loss: 0.000406\n",
            "===> Epoch[3](174/720): Loss: 0.002206\n",
            "===> Epoch[3](175/720): Loss: 0.000321\n",
            "===> Epoch[3](176/720): Loss: 0.000297\n",
            "===> Epoch[3](177/720): Loss: 0.000341\n",
            "===> Epoch[3](178/720): Loss: 0.001075\n",
            "===> Epoch[3](179/720): Loss: 0.000109\n",
            "===> Epoch[3](180/720): Loss: 0.000098\n",
            "===> Epoch[3](181/720): Loss: 0.000406\n",
            "===> Epoch[3](182/720): Loss: 0.000163\n",
            "===> Epoch[3](183/720): Loss: 0.000412\n",
            "===> Epoch[3](184/720): Loss: 0.000326\n",
            "===> Epoch[3](185/720): Loss: 0.000452\n",
            "===> Epoch[3](186/720): Loss: 0.001745\n",
            "===> Epoch[3](187/720): Loss: 0.000266\n",
            "===> Epoch[3](188/720): Loss: 0.000400\n",
            "===> Epoch[3](189/720): Loss: 0.000968\n",
            "===> Epoch[3](190/720): Loss: 0.000383\n",
            "===> Epoch[3](191/720): Loss: 0.000141\n",
            "===> Epoch[3](192/720): Loss: 0.001125\n",
            "===> Epoch[3](193/720): Loss: 0.000520\n",
            "===> Epoch[3](194/720): Loss: 0.000529\n",
            "===> Epoch[3](195/720): Loss: 0.000164\n",
            "===> Epoch[3](196/720): Loss: 0.000198\n",
            "===> Epoch[3](197/720): Loss: 0.000970\n",
            "===> Epoch[3](198/720): Loss: 0.000296\n",
            "===> Epoch[3](199/720): Loss: 0.000868\n",
            "===> Epoch[3](200/720): Loss: 0.000786\n",
            "===> Epoch[3](201/720): Loss: 0.000152\n",
            "===> Epoch[3](202/720): Loss: 0.000339\n",
            "===> Epoch[3](203/720): Loss: 0.001174\n",
            "===> Epoch[3](204/720): Loss: 0.000890\n",
            "===> Epoch[3](205/720): Loss: 0.000436\n",
            "===> Epoch[3](206/720): Loss: 0.000581\n",
            "===> Epoch[3](207/720): Loss: 0.001716\n",
            "===> Epoch[3](208/720): Loss: 0.000618\n",
            "===> Epoch[3](209/720): Loss: 0.000179\n",
            "===> Epoch[3](210/720): Loss: 0.000981\n",
            "===> Epoch[3](211/720): Loss: 0.000456\n",
            "===> Epoch[3](212/720): Loss: 0.000356\n",
            "===> Epoch[3](213/720): Loss: 0.000745\n",
            "===> Epoch[3](214/720): Loss: 0.000160\n",
            "===> Epoch[3](215/720): Loss: 0.000615\n",
            "===> Epoch[3](216/720): Loss: 0.000466\n",
            "===> Epoch[3](217/720): Loss: 0.000588\n",
            "===> Epoch[3](218/720): Loss: 0.000093\n",
            "===> Epoch[3](219/720): Loss: 0.000682\n",
            "===> Epoch[3](220/720): Loss: 0.001400\n",
            "===> Epoch[3](221/720): Loss: 0.000724\n",
            "===> Epoch[3](222/720): Loss: 0.000210\n",
            "===> Epoch[3](223/720): Loss: 0.000844\n",
            "===> Epoch[3](224/720): Loss: 0.000533\n",
            "===> Epoch[3](225/720): Loss: 0.000275\n",
            "===> Epoch[3](226/720): Loss: 0.000317\n",
            "===> Epoch[3](227/720): Loss: 0.000277\n",
            "===> Epoch[3](228/720): Loss: 0.000303\n",
            "===> Epoch[3](229/720): Loss: 0.000614\n",
            "===> Epoch[3](230/720): Loss: 0.000954\n",
            "===> Epoch[3](231/720): Loss: 0.000386\n",
            "===> Epoch[3](232/720): Loss: 0.000193\n",
            "===> Epoch[3](233/720): Loss: 0.000714\n",
            "===> Epoch[3](234/720): Loss: 0.000265\n",
            "===> Epoch[3](235/720): Loss: 0.001315\n",
            "===> Epoch[3](236/720): Loss: 0.000388\n",
            "===> Epoch[3](237/720): Loss: 0.000536\n",
            "===> Epoch[3](238/720): Loss: 0.000139\n",
            "===> Epoch[3](239/720): Loss: 0.000239\n",
            "===> Epoch[3](240/720): Loss: 0.000700\n",
            "===> Epoch[3](241/720): Loss: 0.000230\n",
            "===> Epoch[3](242/720): Loss: 0.001045\n",
            "===> Epoch[3](243/720): Loss: 0.000184\n",
            "===> Epoch[3](244/720): Loss: 0.000329\n",
            "===> Epoch[3](245/720): Loss: 0.000405\n",
            "===> Epoch[3](246/720): Loss: 0.001493\n",
            "===> Epoch[3](247/720): Loss: 0.000327\n",
            "===> Epoch[3](248/720): Loss: 0.000441\n",
            "===> Epoch[3](249/720): Loss: 0.001388\n",
            "===> Epoch[3](250/720): Loss: 0.000167\n",
            "===> Epoch[3](251/720): Loss: 0.000337\n",
            "===> Epoch[3](252/720): Loss: 0.000181\n",
            "===> Epoch[3](253/720): Loss: 0.001749\n",
            "===> Epoch[3](254/720): Loss: 0.000323\n",
            "===> Epoch[3](255/720): Loss: 0.000401\n",
            "===> Epoch[3](256/720): Loss: 0.000326\n",
            "===> Epoch[3](257/720): Loss: 0.000806\n",
            "===> Epoch[3](258/720): Loss: 0.001743\n",
            "===> Epoch[3](259/720): Loss: 0.001027\n",
            "===> Epoch[3](260/720): Loss: 0.000216\n",
            "===> Epoch[3](261/720): Loss: 0.000256\n",
            "===> Epoch[3](262/720): Loss: 0.000144\n",
            "===> Epoch[3](263/720): Loss: 0.000203\n",
            "===> Epoch[3](264/720): Loss: 0.001245\n",
            "===> Epoch[3](265/720): Loss: 0.000229\n",
            "===> Epoch[3](266/720): Loss: 0.000233\n",
            "===> Epoch[3](267/720): Loss: 0.000244\n",
            "===> Epoch[3](268/720): Loss: 0.000366\n",
            "===> Epoch[3](269/720): Loss: 0.000239\n",
            "===> Epoch[3](270/720): Loss: 0.000242\n",
            "===> Epoch[3](271/720): Loss: 0.000233\n",
            "===> Epoch[3](272/720): Loss: 0.000763\n",
            "===> Epoch[3](273/720): Loss: 0.000574\n",
            "===> Epoch[3](274/720): Loss: 0.000603\n",
            "===> Epoch[3](275/720): Loss: 0.000705\n",
            "===> Epoch[3](276/720): Loss: 0.000260\n",
            "===> Epoch[3](277/720): Loss: 0.000383\n",
            "===> Epoch[3](278/720): Loss: 0.000192\n",
            "===> Epoch[3](279/720): Loss: 0.001591\n",
            "===> Epoch[3](280/720): Loss: 0.000684\n",
            "===> Epoch[3](281/720): Loss: 0.001293\n",
            "===> Epoch[3](282/720): Loss: 0.000366\n",
            "===> Epoch[3](283/720): Loss: 0.000862\n",
            "===> Epoch[3](284/720): Loss: 0.000246\n",
            "===> Epoch[3](285/720): Loss: 0.000120\n",
            "===> Epoch[3](286/720): Loss: 0.000474\n",
            "===> Epoch[3](287/720): Loss: 0.000446\n",
            "===> Epoch[3](288/720): Loss: 0.000554\n",
            "===> Epoch[3](289/720): Loss: 0.000572\n",
            "===> Epoch[3](290/720): Loss: 0.000290\n",
            "===> Epoch[3](291/720): Loss: 0.000842\n",
            "===> Epoch[3](292/720): Loss: 0.000469\n",
            "===> Epoch[3](293/720): Loss: 0.001572\n",
            "===> Epoch[3](294/720): Loss: 0.000690\n",
            "===> Epoch[3](295/720): Loss: 0.003248\n",
            "===> Epoch[3](296/720): Loss: 0.000216\n",
            "===> Epoch[3](297/720): Loss: 0.000827\n",
            "===> Epoch[3](298/720): Loss: 0.003414\n",
            "===> Epoch[3](299/720): Loss: 0.000449\n",
            "===> Epoch[3](300/720): Loss: 0.000780\n",
            "===> Epoch[3](301/720): Loss: 0.000801\n",
            "===> Epoch[3](302/720): Loss: 0.000211\n",
            "===> Epoch[3](303/720): Loss: 0.001164\n",
            "===> Epoch[3](304/720): Loss: 0.000839\n",
            "===> Epoch[3](305/720): Loss: 0.001823\n",
            "===> Epoch[3](306/720): Loss: 0.000818\n",
            "===> Epoch[3](307/720): Loss: 0.001355\n",
            "===> Epoch[3](308/720): Loss: 0.000745\n",
            "===> Epoch[3](309/720): Loss: 0.000738\n",
            "===> Epoch[3](310/720): Loss: 0.000293\n",
            "===> Epoch[3](311/720): Loss: 0.001031\n",
            "===> Epoch[3](312/720): Loss: 0.000209\n",
            "===> Epoch[3](313/720): Loss: 0.001615\n",
            "===> Epoch[3](314/720): Loss: 0.000408\n",
            "===> Epoch[3](315/720): Loss: 0.000536\n",
            "===> Epoch[3](316/720): Loss: 0.000262\n",
            "===> Epoch[3](317/720): Loss: 0.000396\n",
            "===> Epoch[3](318/720): Loss: 0.000404\n",
            "===> Epoch[3](319/720): Loss: 0.000439\n",
            "===> Epoch[3](320/720): Loss: 0.001255\n",
            "===> Epoch[3](321/720): Loss: 0.001379\n",
            "===> Epoch[3](322/720): Loss: 0.001166\n",
            "===> Epoch[3](323/720): Loss: 0.001175\n",
            "===> Epoch[3](324/720): Loss: 0.000415\n",
            "===> Epoch[3](325/720): Loss: 0.000874\n",
            "===> Epoch[3](326/720): Loss: 0.001929\n",
            "===> Epoch[3](327/720): Loss: 0.000946\n",
            "===> Epoch[3](328/720): Loss: 0.000490\n",
            "===> Epoch[3](329/720): Loss: 0.001133\n",
            "===> Epoch[3](330/720): Loss: 0.000375\n",
            "===> Epoch[3](331/720): Loss: 0.000329\n",
            "===> Epoch[3](332/720): Loss: 0.000302\n",
            "===> Epoch[3](333/720): Loss: 0.000510\n",
            "===> Epoch[3](334/720): Loss: 0.000356\n",
            "===> Epoch[3](335/720): Loss: 0.001074\n",
            "===> Epoch[3](336/720): Loss: 0.000212\n",
            "===> Epoch[3](337/720): Loss: 0.000237\n",
            "===> Epoch[3](338/720): Loss: 0.000345\n",
            "===> Epoch[3](339/720): Loss: 0.000752\n",
            "===> Epoch[3](340/720): Loss: 0.000253\n",
            "===> Epoch[3](341/720): Loss: 0.000432\n",
            "===> Epoch[3](342/720): Loss: 0.000190\n",
            "===> Epoch[3](343/720): Loss: 0.000609\n",
            "===> Epoch[3](344/720): Loss: 0.000250\n",
            "===> Epoch[3](345/720): Loss: 0.001938\n",
            "===> Epoch[3](346/720): Loss: 0.000338\n",
            "===> Epoch[3](347/720): Loss: 0.000497\n",
            "===> Epoch[3](348/720): Loss: 0.000162\n",
            "===> Epoch[3](349/720): Loss: 0.000235\n",
            "===> Epoch[3](350/720): Loss: 0.000971\n",
            "===> Epoch[3](351/720): Loss: 0.000281\n",
            "===> Epoch[3](352/720): Loss: 0.000333\n",
            "===> Epoch[3](353/720): Loss: 0.000281\n",
            "===> Epoch[3](354/720): Loss: 0.000327\n",
            "===> Epoch[3](355/720): Loss: 0.000625\n",
            "===> Epoch[3](356/720): Loss: 0.000543\n",
            "===> Epoch[3](357/720): Loss: 0.000125\n",
            "===> Epoch[3](358/720): Loss: 0.001527\n",
            "===> Epoch[3](359/720): Loss: 0.000730\n",
            "===> Epoch[3](360/720): Loss: 0.000334\n",
            "===> Epoch[3](361/720): Loss: 0.001382\n",
            "===> Epoch[3](362/720): Loss: 0.000312\n",
            "===> Epoch[3](363/720): Loss: 0.001326\n",
            "===> Epoch[3](364/720): Loss: 0.001027\n",
            "===> Epoch[3](365/720): Loss: 0.000265\n",
            "===> Epoch[3](366/720): Loss: 0.000367\n",
            "===> Epoch[3](367/720): Loss: 0.000419\n",
            "===> Epoch[3](368/720): Loss: 0.000726\n",
            "===> Epoch[3](369/720): Loss: 0.000213\n",
            "===> Epoch[3](370/720): Loss: 0.001757\n",
            "===> Epoch[3](371/720): Loss: 0.000279\n",
            "===> Epoch[3](372/720): Loss: 0.000352\n",
            "===> Epoch[3](373/720): Loss: 0.003577\n",
            "===> Epoch[3](374/720): Loss: 0.000134\n",
            "===> Epoch[3](375/720): Loss: 0.000255\n",
            "===> Epoch[3](376/720): Loss: 0.000699\n",
            "===> Epoch[3](377/720): Loss: 0.000169\n",
            "===> Epoch[3](378/720): Loss: 0.000385\n",
            "===> Epoch[3](379/720): Loss: 0.000565\n",
            "===> Epoch[3](380/720): Loss: 0.000987\n",
            "===> Epoch[3](381/720): Loss: 0.000233\n",
            "===> Epoch[3](382/720): Loss: 0.000393\n",
            "===> Epoch[3](383/720): Loss: 0.000299\n",
            "===> Epoch[3](384/720): Loss: 0.000833\n",
            "===> Epoch[3](385/720): Loss: 0.000405\n",
            "===> Epoch[3](386/720): Loss: 0.000708\n",
            "===> Epoch[3](387/720): Loss: 0.000533\n",
            "===> Epoch[3](388/720): Loss: 0.000473\n",
            "===> Epoch[3](389/720): Loss: 0.000353\n",
            "===> Epoch[3](390/720): Loss: 0.000465\n",
            "===> Epoch[3](391/720): Loss: 0.000190\n",
            "===> Epoch[3](392/720): Loss: 0.001010\n",
            "===> Epoch[3](393/720): Loss: 0.000328\n",
            "===> Epoch[3](394/720): Loss: 0.000620\n",
            "===> Epoch[3](395/720): Loss: 0.000344\n",
            "===> Epoch[3](396/720): Loss: 0.000298\n",
            "===> Epoch[3](397/720): Loss: 0.000214\n",
            "===> Epoch[3](398/720): Loss: 0.000288\n",
            "===> Epoch[3](399/720): Loss: 0.000829\n",
            "===> Epoch[3](400/720): Loss: 0.000493\n",
            "===> Epoch[3](401/720): Loss: 0.000565\n",
            "===> Epoch[3](402/720): Loss: 0.000145\n",
            "===> Epoch[3](403/720): Loss: 0.000975\n",
            "===> Epoch[3](404/720): Loss: 0.000917\n",
            "===> Epoch[3](405/720): Loss: 0.000312\n",
            "===> Epoch[3](406/720): Loss: 0.000787\n",
            "===> Epoch[3](407/720): Loss: 0.001470\n",
            "===> Epoch[3](408/720): Loss: 0.000425\n",
            "===> Epoch[3](409/720): Loss: 0.001021\n",
            "===> Epoch[3](410/720): Loss: 0.000104\n",
            "===> Epoch[3](411/720): Loss: 0.000179\n",
            "===> Epoch[3](412/720): Loss: 0.001071\n",
            "===> Epoch[3](413/720): Loss: 0.000309\n",
            "===> Epoch[3](414/720): Loss: 0.000211\n",
            "===> Epoch[3](415/720): Loss: 0.000590\n",
            "===> Epoch[3](416/720): Loss: 0.000935\n",
            "===> Epoch[3](417/720): Loss: 0.000798\n",
            "===> Epoch[3](418/720): Loss: 0.000736\n",
            "===> Epoch[3](419/720): Loss: 0.001113\n",
            "===> Epoch[3](420/720): Loss: 0.000372\n",
            "===> Epoch[3](421/720): Loss: 0.000865\n",
            "===> Epoch[3](422/720): Loss: 0.000260\n",
            "===> Epoch[3](423/720): Loss: 0.001296\n",
            "===> Epoch[3](424/720): Loss: 0.000116\n",
            "===> Epoch[3](425/720): Loss: 0.000902\n",
            "===> Epoch[3](426/720): Loss: 0.000453\n",
            "===> Epoch[3](427/720): Loss: 0.000376\n",
            "===> Epoch[3](428/720): Loss: 0.000209\n",
            "===> Epoch[3](429/720): Loss: 0.000768\n",
            "===> Epoch[3](430/720): Loss: 0.000400\n",
            "===> Epoch[3](431/720): Loss: 0.000188\n",
            "===> Epoch[3](432/720): Loss: 0.000179\n",
            "===> Epoch[3](433/720): Loss: 0.001422\n",
            "===> Epoch[3](434/720): Loss: 0.000235\n",
            "===> Epoch[3](435/720): Loss: 0.000110\n",
            "===> Epoch[3](436/720): Loss: 0.002871\n",
            "===> Epoch[3](437/720): Loss: 0.000156\n",
            "===> Epoch[3](438/720): Loss: 0.000236\n",
            "===> Epoch[3](439/720): Loss: 0.001037\n",
            "===> Epoch[3](440/720): Loss: 0.000240\n",
            "===> Epoch[3](441/720): Loss: 0.000530\n",
            "===> Epoch[3](442/720): Loss: 0.000521\n",
            "===> Epoch[3](443/720): Loss: 0.000473\n",
            "===> Epoch[3](444/720): Loss: 0.000282\n",
            "===> Epoch[3](445/720): Loss: 0.000906\n",
            "===> Epoch[3](446/720): Loss: 0.000886\n",
            "===> Epoch[3](447/720): Loss: 0.000192\n",
            "===> Epoch[3](448/720): Loss: 0.000576\n",
            "===> Epoch[3](449/720): Loss: 0.000380\n",
            "===> Epoch[3](450/720): Loss: 0.000336\n",
            "===> Epoch[3](451/720): Loss: 0.000545\n",
            "===> Epoch[3](452/720): Loss: 0.000214\n",
            "===> Epoch[3](453/720): Loss: 0.000252\n",
            "===> Epoch[3](454/720): Loss: 0.000332\n",
            "===> Epoch[3](455/720): Loss: 0.000255\n",
            "===> Epoch[3](456/720): Loss: 0.001223\n",
            "===> Epoch[3](457/720): Loss: 0.000932\n",
            "===> Epoch[3](458/720): Loss: 0.000188\n",
            "===> Epoch[3](459/720): Loss: 0.000245\n",
            "===> Epoch[3](460/720): Loss: 0.000197\n",
            "===> Epoch[3](461/720): Loss: 0.000410\n",
            "===> Epoch[3](462/720): Loss: 0.000752\n",
            "===> Epoch[3](463/720): Loss: 0.000457\n",
            "===> Epoch[3](464/720): Loss: 0.000380\n",
            "===> Epoch[3](465/720): Loss: 0.000930\n",
            "===> Epoch[3](466/720): Loss: 0.000660\n",
            "===> Epoch[3](467/720): Loss: 0.000335\n",
            "===> Epoch[3](468/720): Loss: 0.000425\n",
            "===> Epoch[3](469/720): Loss: 0.000706\n",
            "===> Epoch[3](470/720): Loss: 0.000901\n",
            "===> Epoch[3](471/720): Loss: 0.000269\n",
            "===> Epoch[3](472/720): Loss: 0.000378\n",
            "===> Epoch[3](473/720): Loss: 0.000208\n",
            "===> Epoch[3](474/720): Loss: 0.000390\n",
            "===> Epoch[3](475/720): Loss: 0.000634\n",
            "===> Epoch[3](476/720): Loss: 0.000284\n",
            "===> Epoch[3](477/720): Loss: 0.001103\n",
            "===> Epoch[3](478/720): Loss: 0.000254\n",
            "===> Epoch[3](479/720): Loss: 0.000323\n",
            "===> Epoch[3](480/720): Loss: 0.000780\n",
            "===> Epoch[3](481/720): Loss: 0.000541\n",
            "===> Epoch[3](482/720): Loss: 0.000442\n",
            "===> Epoch[3](483/720): Loss: 0.000205\n",
            "===> Epoch[3](484/720): Loss: 0.001027\n",
            "===> Epoch[3](485/720): Loss: 0.000195\n",
            "===> Epoch[3](486/720): Loss: 0.000630\n",
            "===> Epoch[3](487/720): Loss: 0.000146\n",
            "===> Epoch[3](488/720): Loss: 0.000169\n",
            "===> Epoch[3](489/720): Loss: 0.000760\n",
            "===> Epoch[3](490/720): Loss: 0.000595\n",
            "===> Epoch[3](491/720): Loss: 0.001279\n",
            "===> Epoch[3](492/720): Loss: 0.000310\n",
            "===> Epoch[3](493/720): Loss: 0.000409\n",
            "===> Epoch[3](494/720): Loss: 0.000404\n",
            "===> Epoch[3](495/720): Loss: 0.000340\n",
            "===> Epoch[3](496/720): Loss: 0.000287\n",
            "===> Epoch[3](497/720): Loss: 0.000323\n",
            "===> Epoch[3](498/720): Loss: 0.000238\n",
            "===> Epoch[3](499/720): Loss: 0.000462\n",
            "===> Epoch[3](500/720): Loss: 0.000817\n",
            "===> Epoch[3](501/720): Loss: 0.000367\n",
            "===> Epoch[3](502/720): Loss: 0.000321\n",
            "===> Epoch[3](503/720): Loss: 0.000284\n",
            "===> Epoch[3](504/720): Loss: 0.000298\n",
            "===> Epoch[3](505/720): Loss: 0.000245\n",
            "===> Epoch[3](506/720): Loss: 0.000616\n",
            "===> Epoch[3](507/720): Loss: 0.000327\n",
            "===> Epoch[3](508/720): Loss: 0.000264\n",
            "===> Epoch[3](509/720): Loss: 0.000361\n",
            "===> Epoch[3](510/720): Loss: 0.000614\n",
            "===> Epoch[3](511/720): Loss: 0.000120\n",
            "===> Epoch[3](512/720): Loss: 0.000459\n",
            "===> Epoch[3](513/720): Loss: 0.000592\n",
            "===> Epoch[3](514/720): Loss: 0.000599\n",
            "===> Epoch[3](515/720): Loss: 0.001013\n",
            "===> Epoch[3](516/720): Loss: 0.000674\n",
            "===> Epoch[3](517/720): Loss: 0.000704\n",
            "===> Epoch[3](518/720): Loss: 0.000587\n",
            "===> Epoch[3](519/720): Loss: 0.000466\n",
            "===> Epoch[3](520/720): Loss: 0.000107\n",
            "===> Epoch[3](521/720): Loss: 0.000319\n",
            "===> Epoch[3](522/720): Loss: 0.000392\n",
            "===> Epoch[3](523/720): Loss: 0.000425\n",
            "===> Epoch[3](524/720): Loss: 0.000394\n",
            "===> Epoch[3](525/720): Loss: 0.000449\n",
            "===> Epoch[3](526/720): Loss: 0.000652\n",
            "===> Epoch[3](527/720): Loss: 0.000251\n",
            "===> Epoch[3](528/720): Loss: 0.000285\n",
            "===> Epoch[3](529/720): Loss: 0.000156\n",
            "===> Epoch[3](530/720): Loss: 0.001460\n",
            "===> Epoch[3](531/720): Loss: 0.000595\n",
            "===> Epoch[3](532/720): Loss: 0.000733\n",
            "===> Epoch[3](533/720): Loss: 0.000449\n",
            "===> Epoch[3](534/720): Loss: 0.000444\n",
            "===> Epoch[3](535/720): Loss: 0.000240\n",
            "===> Epoch[3](536/720): Loss: 0.000316\n",
            "===> Epoch[3](537/720): Loss: 0.000255\n",
            "===> Epoch[3](538/720): Loss: 0.000966\n",
            "===> Epoch[3](539/720): Loss: 0.000252\n",
            "===> Epoch[3](540/720): Loss: 0.000410\n",
            "===> Epoch[3](541/720): Loss: 0.001442\n",
            "===> Epoch[3](542/720): Loss: 0.000630\n",
            "===> Epoch[3](543/720): Loss: 0.000396\n",
            "===> Epoch[3](544/720): Loss: 0.001368\n",
            "===> Epoch[3](545/720): Loss: 0.000367\n",
            "===> Epoch[3](546/720): Loss: 0.001019\n",
            "===> Epoch[3](547/720): Loss: 0.000991\n",
            "===> Epoch[3](548/720): Loss: 0.000398\n",
            "===> Epoch[3](549/720): Loss: 0.000129\n",
            "===> Epoch[3](550/720): Loss: 0.000507\n",
            "===> Epoch[3](551/720): Loss: 0.000462\n",
            "===> Epoch[3](552/720): Loss: 0.000380\n",
            "===> Epoch[3](553/720): Loss: 0.000407\n",
            "===> Epoch[3](554/720): Loss: 0.000092\n",
            "===> Epoch[3](555/720): Loss: 0.000615\n",
            "===> Epoch[3](556/720): Loss: 0.000528\n",
            "===> Epoch[3](557/720): Loss: 0.000277\n",
            "===> Epoch[3](558/720): Loss: 0.000627\n",
            "===> Epoch[3](559/720): Loss: 0.000331\n",
            "===> Epoch[3](560/720): Loss: 0.000223\n",
            "===> Epoch[3](561/720): Loss: 0.000497\n",
            "===> Epoch[3](562/720): Loss: 0.000490\n",
            "===> Epoch[3](563/720): Loss: 0.000392\n",
            "===> Epoch[3](564/720): Loss: 0.000295\n",
            "===> Epoch[3](565/720): Loss: 0.000141\n",
            "===> Epoch[3](566/720): Loss: 0.000422\n",
            "===> Epoch[3](567/720): Loss: 0.000387\n",
            "===> Epoch[3](568/720): Loss: 0.000634\n",
            "===> Epoch[3](569/720): Loss: 0.000311\n",
            "===> Epoch[3](570/720): Loss: 0.000280\n",
            "===> Epoch[3](571/720): Loss: 0.000431\n",
            "===> Epoch[3](572/720): Loss: 0.001275\n",
            "===> Epoch[3](573/720): Loss: 0.000757\n",
            "===> Epoch[3](574/720): Loss: 0.000173\n",
            "===> Epoch[3](575/720): Loss: 0.000466\n",
            "===> Epoch[3](576/720): Loss: 0.000895\n",
            "===> Epoch[3](577/720): Loss: 0.000637\n",
            "===> Epoch[3](578/720): Loss: 0.000473\n",
            "===> Epoch[3](579/720): Loss: 0.001719\n",
            "===> Epoch[3](580/720): Loss: 0.000256\n",
            "===> Epoch[3](581/720): Loss: 0.002360\n",
            "===> Epoch[3](582/720): Loss: 0.001544\n",
            "===> Epoch[3](583/720): Loss: 0.000168\n",
            "===> Epoch[3](584/720): Loss: 0.001173\n",
            "===> Epoch[3](585/720): Loss: 0.000728\n",
            "===> Epoch[3](586/720): Loss: 0.000519\n",
            "===> Epoch[3](587/720): Loss: 0.001468\n",
            "===> Epoch[3](588/720): Loss: 0.000694\n",
            "===> Epoch[3](589/720): Loss: 0.000794\n",
            "===> Epoch[3](590/720): Loss: 0.001127\n",
            "===> Epoch[3](591/720): Loss: 0.000434\n",
            "===> Epoch[3](592/720): Loss: 0.000804\n",
            "===> Epoch[3](593/720): Loss: 0.000888\n",
            "===> Epoch[3](594/720): Loss: 0.000954\n",
            "===> Epoch[3](595/720): Loss: 0.000458\n",
            "===> Epoch[3](596/720): Loss: 0.000690\n",
            "===> Epoch[3](597/720): Loss: 0.000397\n",
            "===> Epoch[3](598/720): Loss: 0.000310\n",
            "===> Epoch[3](599/720): Loss: 0.000393\n",
            "===> Epoch[3](600/720): Loss: 0.000422\n",
            "===> Epoch[3](601/720): Loss: 0.000488\n",
            "===> Epoch[3](602/720): Loss: 0.000341\n",
            "===> Epoch[3](603/720): Loss: 0.000181\n",
            "===> Epoch[3](604/720): Loss: 0.000253\n",
            "===> Epoch[3](605/720): Loss: 0.000234\n",
            "===> Epoch[3](606/720): Loss: 0.000460\n",
            "===> Epoch[3](607/720): Loss: 0.000982\n",
            "===> Epoch[3](608/720): Loss: 0.000405\n",
            "===> Epoch[3](609/720): Loss: 0.000457\n",
            "===> Epoch[3](610/720): Loss: 0.000236\n",
            "===> Epoch[3](611/720): Loss: 0.000383\n",
            "===> Epoch[3](612/720): Loss: 0.000384\n",
            "===> Epoch[3](613/720): Loss: 0.001078\n",
            "===> Epoch[3](614/720): Loss: 0.000271\n",
            "===> Epoch[3](615/720): Loss: 0.000247\n",
            "===> Epoch[3](616/720): Loss: 0.000475\n",
            "===> Epoch[3](617/720): Loss: 0.000887\n",
            "===> Epoch[3](618/720): Loss: 0.000520\n",
            "===> Epoch[3](619/720): Loss: 0.001055\n",
            "===> Epoch[3](620/720): Loss: 0.000429\n",
            "===> Epoch[3](621/720): Loss: 0.000140\n",
            "===> Epoch[3](622/720): Loss: 0.000354\n",
            "===> Epoch[3](623/720): Loss: 0.000522\n",
            "===> Epoch[3](624/720): Loss: 0.000293\n",
            "===> Epoch[3](625/720): Loss: 0.000605\n",
            "===> Epoch[3](626/720): Loss: 0.000339\n",
            "===> Epoch[3](627/720): Loss: 0.000542\n",
            "===> Epoch[3](628/720): Loss: 0.000350\n",
            "===> Epoch[3](629/720): Loss: 0.000196\n",
            "===> Epoch[3](630/720): Loss: 0.000677\n",
            "===> Epoch[3](631/720): Loss: 0.000550\n",
            "===> Epoch[3](632/720): Loss: 0.000280\n",
            "===> Epoch[3](633/720): Loss: 0.000435\n",
            "===> Epoch[3](634/720): Loss: 0.000397\n",
            "===> Epoch[3](635/720): Loss: 0.000377\n",
            "===> Epoch[3](636/720): Loss: 0.000827\n",
            "===> Epoch[3](637/720): Loss: 0.002004\n",
            "===> Epoch[3](638/720): Loss: 0.000638\n",
            "===> Epoch[3](639/720): Loss: 0.000587\n",
            "===> Epoch[3](640/720): Loss: 0.002069\n",
            "===> Epoch[3](641/720): Loss: 0.000410\n",
            "===> Epoch[3](642/720): Loss: 0.000193\n",
            "===> Epoch[3](643/720): Loss: 0.000295\n",
            "===> Epoch[3](644/720): Loss: 0.001178\n",
            "===> Epoch[3](645/720): Loss: 0.000237\n",
            "===> Epoch[3](646/720): Loss: 0.000715\n",
            "===> Epoch[3](647/720): Loss: 0.000419\n",
            "===> Epoch[3](648/720): Loss: 0.001200\n",
            "===> Epoch[3](649/720): Loss: 0.001465\n",
            "===> Epoch[3](650/720): Loss: 0.000366\n",
            "===> Epoch[3](651/720): Loss: 0.000611\n",
            "===> Epoch[3](652/720): Loss: 0.000384\n",
            "===> Epoch[3](653/720): Loss: 0.000389\n",
            "===> Epoch[3](654/720): Loss: 0.000387\n",
            "===> Epoch[3](655/720): Loss: 0.000367\n",
            "===> Epoch[3](656/720): Loss: 0.000414\n",
            "===> Epoch[3](657/720): Loss: 0.000200\n",
            "===> Epoch[3](658/720): Loss: 0.001250\n",
            "===> Epoch[3](659/720): Loss: 0.000231\n",
            "===> Epoch[3](660/720): Loss: 0.000256\n",
            "===> Epoch[3](661/720): Loss: 0.000129\n",
            "===> Epoch[3](662/720): Loss: 0.002660\n",
            "===> Epoch[3](663/720): Loss: 0.000387\n",
            "===> Epoch[3](664/720): Loss: 0.000204\n",
            "===> Epoch[3](665/720): Loss: 0.000222\n",
            "===> Epoch[3](666/720): Loss: 0.000175\n",
            "===> Epoch[3](667/720): Loss: 0.000607\n",
            "===> Epoch[3](668/720): Loss: 0.000618\n",
            "===> Epoch[3](669/720): Loss: 0.000462\n",
            "===> Epoch[3](670/720): Loss: 0.000591\n",
            "===> Epoch[3](671/720): Loss: 0.000475\n",
            "===> Epoch[3](672/720): Loss: 0.000495\n",
            "===> Epoch[3](673/720): Loss: 0.000198\n",
            "===> Epoch[3](674/720): Loss: 0.001081\n",
            "===> Epoch[3](675/720): Loss: 0.001023\n",
            "===> Epoch[3](676/720): Loss: 0.000299\n",
            "===> Epoch[3](677/720): Loss: 0.000375\n",
            "===> Epoch[3](678/720): Loss: 0.000176\n",
            "===> Epoch[3](679/720): Loss: 0.001076\n",
            "===> Epoch[3](680/720): Loss: 0.000343\n",
            "===> Epoch[3](681/720): Loss: 0.001210\n",
            "===> Epoch[3](682/720): Loss: 0.000836\n",
            "===> Epoch[3](683/720): Loss: 0.000222\n",
            "===> Epoch[3](684/720): Loss: 0.000510\n",
            "===> Epoch[3](685/720): Loss: 0.000497\n",
            "===> Epoch[3](686/720): Loss: 0.000611\n",
            "===> Epoch[3](687/720): Loss: 0.000584\n",
            "===> Epoch[3](688/720): Loss: 0.000642\n",
            "===> Epoch[3](689/720): Loss: 0.000148\n",
            "===> Epoch[3](690/720): Loss: 0.000329\n",
            "===> Epoch[3](691/720): Loss: 0.000332\n",
            "===> Epoch[3](692/720): Loss: 0.000159\n",
            "===> Epoch[3](693/720): Loss: 0.000508\n",
            "===> Epoch[3](694/720): Loss: 0.000807\n",
            "===> Epoch[3](695/720): Loss: 0.000315\n",
            "===> Epoch[3](696/720): Loss: 0.000287\n",
            "===> Epoch[3](697/720): Loss: 0.000387\n",
            "===> Epoch[3](698/720): Loss: 0.000258\n",
            "===> Epoch[3](699/720): Loss: 0.001257\n",
            "===> Epoch[3](700/720): Loss: 0.000346\n",
            "===> Epoch[3](701/720): Loss: 0.000208\n",
            "===> Epoch[3](702/720): Loss: 0.000225\n",
            "===> Epoch[3](703/720): Loss: 0.001953\n",
            "===> Epoch[3](704/720): Loss: 0.000308\n",
            "===> Epoch[3](705/720): Loss: 0.000144\n",
            "===> Epoch[3](706/720): Loss: 0.001174\n",
            "===> Epoch[3](707/720): Loss: 0.000240\n",
            "===> Epoch[3](708/720): Loss: 0.000397\n",
            "===> Epoch[3](709/720): Loss: 0.002375\n",
            "===> Epoch[3](710/720): Loss: 0.000406\n",
            "===> Epoch[3](711/720): Loss: 0.000240\n",
            "===> Epoch[3](712/720): Loss: 0.000181\n",
            "===> Epoch[3](713/720): Loss: 0.000230\n",
            "===> Epoch[3](714/720): Loss: 0.000370\n",
            "===> Epoch[3](715/720): Loss: 0.000911\n",
            "===> Epoch[3](716/720): Loss: 0.000181\n",
            "===> Epoch[3](717/720): Loss: 0.000229\n",
            "===> Epoch[3](718/720): Loss: 0.000339\n",
            "===> Epoch[3](719/720): Loss: 0.000879\n",
            "===> Epoch[3](720/720): Loss: 0.000379\n",
            "===> Epoch 3 Complete: Avg. Loss: 0.000581\n",
            "=====>  Training 3 epochs completed\n",
            "=====>  Testing 3 epochs\n",
            "=====>  lr scheduler activated in 3 epochs completed\n",
            "=====>  Save checkpoint 3 epochs\n",
            "/content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_3.pth\n",
            "Checkpoint saved to /content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_3.pth\n",
            "=====>  Save checkpoint 3 epochs completed\n",
            "=====>  Training 4 epochs\n",
            "===> Training # 4 epoch\n",
            "===> Epoch[4](1/720): Loss: 0.000243\n",
            "===> Epoch[4](2/720): Loss: 0.001075\n",
            "===> Epoch[4](3/720): Loss: 0.000472\n",
            "===> Epoch[4](4/720): Loss: 0.001494\n",
            "===> Epoch[4](5/720): Loss: 0.000837\n",
            "===> Epoch[4](6/720): Loss: 0.000160\n",
            "===> Epoch[4](7/720): Loss: 0.000395\n",
            "===> Epoch[4](8/720): Loss: 0.000196\n",
            "===> Epoch[4](9/720): Loss: 0.000441\n",
            "===> Epoch[4](10/720): Loss: 0.000573\n",
            "===> Epoch[4](11/720): Loss: 0.000473\n",
            "===> Epoch[4](12/720): Loss: 0.000335\n",
            "===> Epoch[4](13/720): Loss: 0.000664\n",
            "===> Epoch[4](14/720): Loss: 0.000261\n",
            "===> Epoch[4](15/720): Loss: 0.000366\n",
            "===> Epoch[4](16/720): Loss: 0.000233\n",
            "===> Epoch[4](17/720): Loss: 0.001150\n",
            "===> Epoch[4](18/720): Loss: 0.000320\n",
            "===> Epoch[4](19/720): Loss: 0.000245\n",
            "===> Epoch[4](20/720): Loss: 0.000443\n",
            "===> Epoch[4](21/720): Loss: 0.001145\n",
            "===> Epoch[4](22/720): Loss: 0.000499\n",
            "===> Epoch[4](23/720): Loss: 0.000734\n",
            "===> Epoch[4](24/720): Loss: 0.000311\n",
            "===> Epoch[4](25/720): Loss: 0.000446\n",
            "===> Epoch[4](26/720): Loss: 0.001192\n",
            "===> Epoch[4](27/720): Loss: 0.000626\n",
            "===> Epoch[4](28/720): Loss: 0.000234\n",
            "===> Epoch[4](29/720): Loss: 0.000546\n",
            "===> Epoch[4](30/720): Loss: 0.001101\n",
            "===> Epoch[4](31/720): Loss: 0.001410\n",
            "===> Epoch[4](32/720): Loss: 0.002300\n",
            "===> Epoch[4](33/720): Loss: 0.000623\n",
            "===> Epoch[4](34/720): Loss: 0.000828\n",
            "===> Epoch[4](35/720): Loss: 0.001145\n",
            "===> Epoch[4](36/720): Loss: 0.000268\n",
            "===> Epoch[4](37/720): Loss: 0.000985\n",
            "===> Epoch[4](38/720): Loss: 0.001909\n",
            "===> Epoch[4](39/720): Loss: 0.000851\n",
            "===> Epoch[4](40/720): Loss: 0.000666\n",
            "===> Epoch[4](41/720): Loss: 0.000705\n",
            "===> Epoch[4](42/720): Loss: 0.001722\n",
            "===> Epoch[4](43/720): Loss: 0.001769\n",
            "===> Epoch[4](44/720): Loss: 0.000731\n",
            "===> Epoch[4](45/720): Loss: 0.001194\n",
            "===> Epoch[4](46/720): Loss: 0.005503\n",
            "===> Epoch[4](47/720): Loss: 0.000470\n",
            "===> Epoch[4](48/720): Loss: 0.002076\n",
            "===> Epoch[4](49/720): Loss: 0.004212\n",
            "===> Epoch[4](50/720): Loss: 0.001654\n",
            "===> Epoch[4](51/720): Loss: 0.001130\n",
            "===> Epoch[4](52/720): Loss: 0.004000\n",
            "===> Epoch[4](53/720): Loss: 0.003957\n",
            "===> Epoch[4](54/720): Loss: 0.000550\n",
            "===> Epoch[4](55/720): Loss: 0.002742\n",
            "===> Epoch[4](56/720): Loss: 0.004396\n",
            "===> Epoch[4](57/720): Loss: 0.002832\n",
            "===> Epoch[4](58/720): Loss: 0.001321\n",
            "===> Epoch[4](59/720): Loss: 0.002972\n",
            "===> Epoch[4](60/720): Loss: 0.000814\n",
            "===> Epoch[4](61/720): Loss: 0.001326\n",
            "===> Epoch[4](62/720): Loss: 0.000557\n",
            "===> Epoch[4](63/720): Loss: 0.001437\n",
            "===> Epoch[4](64/720): Loss: 0.001691\n",
            "===> Epoch[4](65/720): Loss: 0.001237\n",
            "===> Epoch[4](66/720): Loss: 0.000844\n",
            "===> Epoch[4](67/720): Loss: 0.000400\n",
            "===> Epoch[4](68/720): Loss: 0.000842\n",
            "===> Epoch[4](69/720): Loss: 0.000927\n",
            "===> Epoch[4](70/720): Loss: 0.000307\n",
            "===> Epoch[4](71/720): Loss: 0.000391\n",
            "===> Epoch[4](72/720): Loss: 0.000375\n",
            "===> Epoch[4](73/720): Loss: 0.000277\n",
            "===> Epoch[4](74/720): Loss: 0.000401\n",
            "===> Epoch[4](75/720): Loss: 0.000266\n",
            "===> Epoch[4](76/720): Loss: 0.000879\n",
            "===> Epoch[4](77/720): Loss: 0.000231\n",
            "===> Epoch[4](78/720): Loss: 0.000710\n",
            "===> Epoch[4](79/720): Loss: 0.000229\n",
            "===> Epoch[4](80/720): Loss: 0.000737\n",
            "===> Epoch[4](81/720): Loss: 0.000279\n",
            "===> Epoch[4](82/720): Loss: 0.000917\n",
            "===> Epoch[4](83/720): Loss: 0.000867\n",
            "===> Epoch[4](84/720): Loss: 0.000268\n",
            "===> Epoch[4](85/720): Loss: 0.001005\n",
            "===> Epoch[4](86/720): Loss: 0.001064\n",
            "===> Epoch[4](87/720): Loss: 0.000763\n",
            "===> Epoch[4](88/720): Loss: 0.000917\n",
            "===> Epoch[4](89/720): Loss: 0.000258\n",
            "===> Epoch[4](90/720): Loss: 0.000235\n",
            "===> Epoch[4](91/720): Loss: 0.001230\n",
            "===> Epoch[4](92/720): Loss: 0.000159\n",
            "===> Epoch[4](93/720): Loss: 0.000211\n",
            "===> Epoch[4](94/720): Loss: 0.000393\n",
            "===> Epoch[4](95/720): Loss: 0.000464\n",
            "===> Epoch[4](96/720): Loss: 0.001066\n",
            "===> Epoch[4](97/720): Loss: 0.000548\n",
            "===> Epoch[4](98/720): Loss: 0.000664\n",
            "===> Epoch[4](99/720): Loss: 0.000381\n",
            "===> Epoch[4](100/720): Loss: 0.000196\n",
            "===> Epoch[4](101/720): Loss: 0.000256\n",
            "===> Epoch[4](102/720): Loss: 0.000399\n",
            "===> Epoch[4](103/720): Loss: 0.000601\n",
            "===> Epoch[4](104/720): Loss: 0.000970\n",
            "===> Epoch[4](105/720): Loss: 0.000663\n",
            "===> Epoch[4](106/720): Loss: 0.000380\n",
            "===> Epoch[4](107/720): Loss: 0.000312\n",
            "===> Epoch[4](108/720): Loss: 0.000537\n",
            "===> Epoch[4](109/720): Loss: 0.000331\n",
            "===> Epoch[4](110/720): Loss: 0.000536\n",
            "===> Epoch[4](111/720): Loss: 0.001042\n",
            "===> Epoch[4](112/720): Loss: 0.000228\n",
            "===> Epoch[4](113/720): Loss: 0.000941\n",
            "===> Epoch[4](114/720): Loss: 0.000359\n",
            "===> Epoch[4](115/720): Loss: 0.000651\n",
            "===> Epoch[4](116/720): Loss: 0.001223\n",
            "===> Epoch[4](117/720): Loss: 0.000606\n",
            "===> Epoch[4](118/720): Loss: 0.001838\n",
            "===> Epoch[4](119/720): Loss: 0.000355\n",
            "===> Epoch[4](120/720): Loss: 0.000469\n",
            "===> Epoch[4](121/720): Loss: 0.001533\n",
            "===> Epoch[4](122/720): Loss: 0.000394\n",
            "===> Epoch[4](123/720): Loss: 0.000458\n",
            "===> Epoch[4](124/720): Loss: 0.000294\n",
            "===> Epoch[4](125/720): Loss: 0.000566\n",
            "===> Epoch[4](126/720): Loss: 0.000764\n",
            "===> Epoch[4](127/720): Loss: 0.000353\n",
            "===> Epoch[4](128/720): Loss: 0.000420\n",
            "===> Epoch[4](129/720): Loss: 0.000381\n",
            "===> Epoch[4](130/720): Loss: 0.000270\n",
            "===> Epoch[4](131/720): Loss: 0.000296\n",
            "===> Epoch[4](132/720): Loss: 0.001648\n",
            "===> Epoch[4](133/720): Loss: 0.001688\n",
            "===> Epoch[4](134/720): Loss: 0.000290\n",
            "===> Epoch[4](135/720): Loss: 0.000435\n",
            "===> Epoch[4](136/720): Loss: 0.000591\n",
            "===> Epoch[4](137/720): Loss: 0.001654\n",
            "===> Epoch[4](138/720): Loss: 0.001196\n",
            "===> Epoch[4](139/720): Loss: 0.000429\n",
            "===> Epoch[4](140/720): Loss: 0.000158\n",
            "===> Epoch[4](141/720): Loss: 0.000289\n",
            "===> Epoch[4](142/720): Loss: 0.001009\n",
            "===> Epoch[4](143/720): Loss: 0.001432\n",
            "===> Epoch[4](144/720): Loss: 0.000579\n",
            "===> Epoch[4](145/720): Loss: 0.000972\n",
            "===> Epoch[4](146/720): Loss: 0.000184\n",
            "===> Epoch[4](147/720): Loss: 0.000454\n",
            "===> Epoch[4](148/720): Loss: 0.000312\n",
            "===> Epoch[4](149/720): Loss: 0.001347\n",
            "===> Epoch[4](150/720): Loss: 0.000226\n",
            "===> Epoch[4](151/720): Loss: 0.000233\n",
            "===> Epoch[4](152/720): Loss: 0.000335\n",
            "===> Epoch[4](153/720): Loss: 0.000154\n",
            "===> Epoch[4](154/720): Loss: 0.000276\n",
            "===> Epoch[4](155/720): Loss: 0.000400\n",
            "===> Epoch[4](156/720): Loss: 0.000770\n",
            "===> Epoch[4](157/720): Loss: 0.000527\n",
            "===> Epoch[4](158/720): Loss: 0.000138\n",
            "===> Epoch[4](159/720): Loss: 0.000448\n",
            "===> Epoch[4](160/720): Loss: 0.000598\n",
            "===> Epoch[4](161/720): Loss: 0.000640\n",
            "===> Epoch[4](162/720): Loss: 0.000284\n",
            "===> Epoch[4](163/720): Loss: 0.000299\n",
            "===> Epoch[4](164/720): Loss: 0.001033\n",
            "===> Epoch[4](165/720): Loss: 0.000678\n",
            "===> Epoch[4](166/720): Loss: 0.000609\n",
            "===> Epoch[4](167/720): Loss: 0.000151\n",
            "===> Epoch[4](168/720): Loss: 0.000300\n",
            "===> Epoch[4](169/720): Loss: 0.000368\n",
            "===> Epoch[4](170/720): Loss: 0.000550\n",
            "===> Epoch[4](171/720): Loss: 0.001180\n",
            "===> Epoch[4](172/720): Loss: 0.000595\n",
            "===> Epoch[4](173/720): Loss: 0.000296\n",
            "===> Epoch[4](174/720): Loss: 0.000264\n",
            "===> Epoch[4](175/720): Loss: 0.000722\n",
            "===> Epoch[4](176/720): Loss: 0.000984\n",
            "===> Epoch[4](177/720): Loss: 0.000320\n",
            "===> Epoch[4](178/720): Loss: 0.000426\n",
            "===> Epoch[4](179/720): Loss: 0.000246\n",
            "===> Epoch[4](180/720): Loss: 0.000541\n",
            "===> Epoch[4](181/720): Loss: 0.000314\n",
            "===> Epoch[4](182/720): Loss: 0.000290\n",
            "===> Epoch[4](183/720): Loss: 0.000211\n",
            "===> Epoch[4](184/720): Loss: 0.000247\n",
            "===> Epoch[4](185/720): Loss: 0.000319\n",
            "===> Epoch[4](186/720): Loss: 0.000167\n",
            "===> Epoch[4](187/720): Loss: 0.000145\n",
            "===> Epoch[4](188/720): Loss: 0.000829\n",
            "===> Epoch[4](189/720): Loss: 0.000232\n",
            "===> Epoch[4](190/720): Loss: 0.000584\n",
            "===> Epoch[4](191/720): Loss: 0.000263\n",
            "===> Epoch[4](192/720): Loss: 0.000262\n",
            "===> Epoch[4](193/720): Loss: 0.000503\n",
            "===> Epoch[4](194/720): Loss: 0.000541\n",
            "===> Epoch[4](195/720): Loss: 0.000239\n",
            "===> Epoch[4](196/720): Loss: 0.000150\n",
            "===> Epoch[4](197/720): Loss: 0.000562\n",
            "===> Epoch[4](198/720): Loss: 0.000285\n",
            "===> Epoch[4](199/720): Loss: 0.000576\n",
            "===> Epoch[4](200/720): Loss: 0.000947\n",
            "===> Epoch[4](201/720): Loss: 0.000236\n",
            "===> Epoch[4](202/720): Loss: 0.001460\n",
            "===> Epoch[4](203/720): Loss: 0.000346\n",
            "===> Epoch[4](204/720): Loss: 0.000362\n",
            "===> Epoch[4](205/720): Loss: 0.000610\n",
            "===> Epoch[4](206/720): Loss: 0.000233\n",
            "===> Epoch[4](207/720): Loss: 0.001227\n",
            "===> Epoch[4](208/720): Loss: 0.000202\n",
            "===> Epoch[4](209/720): Loss: 0.001243\n",
            "===> Epoch[4](210/720): Loss: 0.000386\n",
            "===> Epoch[4](211/720): Loss: 0.000454\n",
            "===> Epoch[4](212/720): Loss: 0.000774\n",
            "===> Epoch[4](213/720): Loss: 0.000132\n",
            "===> Epoch[4](214/720): Loss: 0.000257\n",
            "===> Epoch[4](215/720): Loss: 0.000140\n",
            "===> Epoch[4](216/720): Loss: 0.000230\n",
            "===> Epoch[4](217/720): Loss: 0.000153\n",
            "===> Epoch[4](218/720): Loss: 0.000166\n",
            "===> Epoch[4](219/720): Loss: 0.000246\n",
            "===> Epoch[4](220/720): Loss: 0.000325\n",
            "===> Epoch[4](221/720): Loss: 0.000490\n",
            "===> Epoch[4](222/720): Loss: 0.000329\n",
            "===> Epoch[4](223/720): Loss: 0.000419\n",
            "===> Epoch[4](224/720): Loss: 0.000953\n",
            "===> Epoch[4](225/720): Loss: 0.000577\n",
            "===> Epoch[4](226/720): Loss: 0.000341\n",
            "===> Epoch[4](227/720): Loss: 0.000286\n",
            "===> Epoch[4](228/720): Loss: 0.000355\n",
            "===> Epoch[4](229/720): Loss: 0.000224\n",
            "===> Epoch[4](230/720): Loss: 0.001099\n",
            "===> Epoch[4](231/720): Loss: 0.000652\n",
            "===> Epoch[4](232/720): Loss: 0.000649\n",
            "===> Epoch[4](233/720): Loss: 0.000557\n",
            "===> Epoch[4](234/720): Loss: 0.002270\n",
            "===> Epoch[4](235/720): Loss: 0.000227\n",
            "===> Epoch[4](236/720): Loss: 0.000356\n",
            "===> Epoch[4](237/720): Loss: 0.000134\n",
            "===> Epoch[4](238/720): Loss: 0.000203\n",
            "===> Epoch[4](239/720): Loss: 0.000342\n",
            "===> Epoch[4](240/720): Loss: 0.000251\n",
            "===> Epoch[4](241/720): Loss: 0.000189\n",
            "===> Epoch[4](242/720): Loss: 0.001774\n",
            "===> Epoch[4](243/720): Loss: 0.000474\n",
            "===> Epoch[4](244/720): Loss: 0.000133\n",
            "===> Epoch[4](245/720): Loss: 0.000994\n",
            "===> Epoch[4](246/720): Loss: 0.000170\n",
            "===> Epoch[4](247/720): Loss: 0.000830\n",
            "===> Epoch[4](248/720): Loss: 0.000179\n",
            "===> Epoch[4](249/720): Loss: 0.000250\n",
            "===> Epoch[4](250/720): Loss: 0.000194\n",
            "===> Epoch[4](251/720): Loss: 0.000394\n",
            "===> Epoch[4](252/720): Loss: 0.000180\n",
            "===> Epoch[4](253/720): Loss: 0.001130\n",
            "===> Epoch[4](254/720): Loss: 0.000625\n",
            "===> Epoch[4](255/720): Loss: 0.000314\n",
            "===> Epoch[4](256/720): Loss: 0.000409\n",
            "===> Epoch[4](257/720): Loss: 0.000470\n",
            "===> Epoch[4](258/720): Loss: 0.000322\n",
            "===> Epoch[4](259/720): Loss: 0.000631\n",
            "===> Epoch[4](260/720): Loss: 0.000554\n",
            "===> Epoch[4](261/720): Loss: 0.000947\n",
            "===> Epoch[4](262/720): Loss: 0.000705\n",
            "===> Epoch[4](263/720): Loss: 0.000876\n",
            "===> Epoch[4](264/720): Loss: 0.001160\n",
            "===> Epoch[4](265/720): Loss: 0.000918\n",
            "===> Epoch[4](266/720): Loss: 0.001268\n",
            "===> Epoch[4](267/720): Loss: 0.000976\n",
            "===> Epoch[4](268/720): Loss: 0.000421\n",
            "===> Epoch[4](269/720): Loss: 0.000286\n",
            "===> Epoch[4](270/720): Loss: 0.000963\n",
            "===> Epoch[4](271/720): Loss: 0.000345\n",
            "===> Epoch[4](272/720): Loss: 0.000930\n",
            "===> Epoch[4](273/720): Loss: 0.000223\n",
            "===> Epoch[4](274/720): Loss: 0.000423\n",
            "===> Epoch[4](275/720): Loss: 0.001781\n",
            "===> Epoch[4](276/720): Loss: 0.000456\n",
            "===> Epoch[4](277/720): Loss: 0.000256\n",
            "===> Epoch[4](278/720): Loss: 0.000220\n",
            "===> Epoch[4](279/720): Loss: 0.000232\n",
            "===> Epoch[4](280/720): Loss: 0.000173\n",
            "===> Epoch[4](281/720): Loss: 0.000258\n",
            "===> Epoch[4](282/720): Loss: 0.001015\n",
            "===> Epoch[4](283/720): Loss: 0.000099\n",
            "===> Epoch[4](284/720): Loss: 0.000272\n",
            "===> Epoch[4](285/720): Loss: 0.000337\n",
            "===> Epoch[4](286/720): Loss: 0.000261\n",
            "===> Epoch[4](287/720): Loss: 0.000344\n",
            "===> Epoch[4](288/720): Loss: 0.000287\n",
            "===> Epoch[4](289/720): Loss: 0.000468\n",
            "===> Epoch[4](290/720): Loss: 0.000205\n",
            "===> Epoch[4](291/720): Loss: 0.001650\n",
            "===> Epoch[4](292/720): Loss: 0.001234\n",
            "===> Epoch[4](293/720): Loss: 0.000221\n",
            "===> Epoch[4](294/720): Loss: 0.000154\n",
            "===> Epoch[4](295/720): Loss: 0.000437\n",
            "===> Epoch[4](296/720): Loss: 0.000183\n",
            "===> Epoch[4](297/720): Loss: 0.000685\n",
            "===> Epoch[4](298/720): Loss: 0.000941\n",
            "===> Epoch[4](299/720): Loss: 0.000237\n",
            "===> Epoch[4](300/720): Loss: 0.000173\n",
            "===> Epoch[4](301/720): Loss: 0.000318\n",
            "===> Epoch[4](302/720): Loss: 0.001093\n",
            "===> Epoch[4](303/720): Loss: 0.000147\n",
            "===> Epoch[4](304/720): Loss: 0.000160\n",
            "===> Epoch[4](305/720): Loss: 0.000457\n",
            "===> Epoch[4](306/720): Loss: 0.000178\n",
            "===> Epoch[4](307/720): Loss: 0.000328\n",
            "===> Epoch[4](308/720): Loss: 0.000579\n",
            "===> Epoch[4](309/720): Loss: 0.000390\n",
            "===> Epoch[4](310/720): Loss: 0.000505\n",
            "===> Epoch[4](311/720): Loss: 0.000214\n",
            "===> Epoch[4](312/720): Loss: 0.000670\n",
            "===> Epoch[4](313/720): Loss: 0.000182\n",
            "===> Epoch[4](314/720): Loss: 0.000710\n",
            "===> Epoch[4](315/720): Loss: 0.000593\n",
            "===> Epoch[4](316/720): Loss: 0.001092\n",
            "===> Epoch[4](317/720): Loss: 0.001229\n",
            "===> Epoch[4](318/720): Loss: 0.000498\n",
            "===> Epoch[4](319/720): Loss: 0.000915\n",
            "===> Epoch[4](320/720): Loss: 0.000254\n",
            "===> Epoch[4](321/720): Loss: 0.000331\n",
            "===> Epoch[4](322/720): Loss: 0.000129\n",
            "===> Epoch[4](323/720): Loss: 0.000418\n",
            "===> Epoch[4](324/720): Loss: 0.001896\n",
            "===> Epoch[4](325/720): Loss: 0.000413\n",
            "===> Epoch[4](326/720): Loss: 0.000320\n",
            "===> Epoch[4](327/720): Loss: 0.000223\n",
            "===> Epoch[4](328/720): Loss: 0.000405\n",
            "===> Epoch[4](329/720): Loss: 0.001042\n",
            "===> Epoch[4](330/720): Loss: 0.002496\n",
            "===> Epoch[4](331/720): Loss: 0.000624\n",
            "===> Epoch[4](332/720): Loss: 0.000714\n",
            "===> Epoch[4](333/720): Loss: 0.002184\n",
            "===> Epoch[4](334/720): Loss: 0.000721\n",
            "===> Epoch[4](335/720): Loss: 0.000909\n",
            "===> Epoch[4](336/720): Loss: 0.002702\n",
            "===> Epoch[4](337/720): Loss: 0.003676\n",
            "===> Epoch[4](338/720): Loss: 0.002195\n",
            "===> Epoch[4](339/720): Loss: 0.000776\n",
            "===> Epoch[4](340/720): Loss: 0.001366\n",
            "===> Epoch[4](341/720): Loss: 0.001576\n",
            "===> Epoch[4](342/720): Loss: 0.000628\n",
            "===> Epoch[4](343/720): Loss: 0.000583\n",
            "===> Epoch[4](344/720): Loss: 0.000870\n",
            "===> Epoch[4](345/720): Loss: 0.000286\n",
            "===> Epoch[4](346/720): Loss: 0.001649\n",
            "===> Epoch[4](347/720): Loss: 0.000545\n",
            "===> Epoch[4](348/720): Loss: 0.000895\n",
            "===> Epoch[4](349/720): Loss: 0.000517\n",
            "===> Epoch[4](350/720): Loss: 0.000963\n",
            "===> Epoch[4](351/720): Loss: 0.000804\n",
            "===> Epoch[4](352/720): Loss: 0.000969\n",
            "===> Epoch[4](353/720): Loss: 0.001120\n",
            "===> Epoch[4](354/720): Loss: 0.000638\n",
            "===> Epoch[4](355/720): Loss: 0.000962\n",
            "===> Epoch[4](356/720): Loss: 0.000949\n",
            "===> Epoch[4](357/720): Loss: 0.000818\n",
            "===> Epoch[4](358/720): Loss: 0.001006\n",
            "===> Epoch[4](359/720): Loss: 0.000755\n",
            "===> Epoch[4](360/720): Loss: 0.000476\n",
            "===> Epoch[4](361/720): Loss: 0.000765\n",
            "===> Epoch[4](362/720): Loss: 0.000255\n",
            "===> Epoch[4](363/720): Loss: 0.001505\n",
            "===> Epoch[4](364/720): Loss: 0.000887\n",
            "===> Epoch[4](365/720): Loss: 0.000228\n",
            "===> Epoch[4](366/720): Loss: 0.000666\n",
            "===> Epoch[4](367/720): Loss: 0.000240\n",
            "===> Epoch[4](368/720): Loss: 0.000823\n",
            "===> Epoch[4](369/720): Loss: 0.001142\n",
            "===> Epoch[4](370/720): Loss: 0.001950\n",
            "===> Epoch[4](371/720): Loss: 0.000263\n",
            "===> Epoch[4](372/720): Loss: 0.001077\n",
            "===> Epoch[4](373/720): Loss: 0.000457\n",
            "===> Epoch[4](374/720): Loss: 0.000675\n",
            "===> Epoch[4](375/720): Loss: 0.001317\n",
            "===> Epoch[4](376/720): Loss: 0.000894\n",
            "===> Epoch[4](377/720): Loss: 0.000245\n",
            "===> Epoch[4](378/720): Loss: 0.000594\n",
            "===> Epoch[4](379/720): Loss: 0.000886\n",
            "===> Epoch[4](380/720): Loss: 0.000205\n",
            "===> Epoch[4](381/720): Loss: 0.000552\n",
            "===> Epoch[4](382/720): Loss: 0.001899\n",
            "===> Epoch[4](383/720): Loss: 0.000964\n",
            "===> Epoch[4](384/720): Loss: 0.001513\n",
            "===> Epoch[4](385/720): Loss: 0.000340\n",
            "===> Epoch[4](386/720): Loss: 0.001022\n",
            "===> Epoch[4](387/720): Loss: 0.001242\n",
            "===> Epoch[4](388/720): Loss: 0.001158\n",
            "===> Epoch[4](389/720): Loss: 0.001208\n",
            "===> Epoch[4](390/720): Loss: 0.000354\n",
            "===> Epoch[4](391/720): Loss: 0.001797\n",
            "===> Epoch[4](392/720): Loss: 0.002904\n",
            "===> Epoch[4](393/720): Loss: 0.001077\n",
            "===> Epoch[4](394/720): Loss: 0.001777\n",
            "===> Epoch[4](395/720): Loss: 0.000812\n",
            "===> Epoch[4](396/720): Loss: 0.001499\n",
            "===> Epoch[4](397/720): Loss: 0.000761\n",
            "===> Epoch[4](398/720): Loss: 0.000967\n",
            "===> Epoch[4](399/720): Loss: 0.000578\n",
            "===> Epoch[4](400/720): Loss: 0.001561\n",
            "===> Epoch[4](401/720): Loss: 0.000636\n",
            "===> Epoch[4](402/720): Loss: 0.000371\n",
            "===> Epoch[4](403/720): Loss: 0.000679\n",
            "===> Epoch[4](404/720): Loss: 0.000341\n",
            "===> Epoch[4](405/720): Loss: 0.000521\n",
            "===> Epoch[4](406/720): Loss: 0.000767\n",
            "===> Epoch[4](407/720): Loss: 0.001054\n",
            "===> Epoch[4](408/720): Loss: 0.000709\n",
            "===> Epoch[4](409/720): Loss: 0.000301\n",
            "===> Epoch[4](410/720): Loss: 0.000863\n",
            "===> Epoch[4](411/720): Loss: 0.000213\n",
            "===> Epoch[4](412/720): Loss: 0.000304\n",
            "===> Epoch[4](413/720): Loss: 0.000756\n",
            "===> Epoch[4](414/720): Loss: 0.002046\n",
            "===> Epoch[4](415/720): Loss: 0.001288\n",
            "===> Epoch[4](416/720): Loss: 0.000235\n",
            "===> Epoch[4](417/720): Loss: 0.000910\n",
            "===> Epoch[4](418/720): Loss: 0.000410\n",
            "===> Epoch[4](419/720): Loss: 0.000189\n",
            "===> Epoch[4](420/720): Loss: 0.000696\n",
            "===> Epoch[4](421/720): Loss: 0.000379\n",
            "===> Epoch[4](422/720): Loss: 0.000825\n",
            "===> Epoch[4](423/720): Loss: 0.000735\n",
            "===> Epoch[4](424/720): Loss: 0.000965\n",
            "===> Epoch[4](425/720): Loss: 0.001110\n",
            "===> Epoch[4](426/720): Loss: 0.001426\n",
            "===> Epoch[4](427/720): Loss: 0.001046\n",
            "===> Epoch[4](428/720): Loss: 0.001825\n",
            "===> Epoch[4](429/720): Loss: 0.000767\n",
            "===> Epoch[4](430/720): Loss: 0.001131\n",
            "===> Epoch[4](431/720): Loss: 0.001403\n",
            "===> Epoch[4](432/720): Loss: 0.001683\n",
            "===> Epoch[4](433/720): Loss: 0.000321\n",
            "===> Epoch[4](434/720): Loss: 0.000293\n",
            "===> Epoch[4](435/720): Loss: 0.000400\n",
            "===> Epoch[4](436/720): Loss: 0.000253\n",
            "===> Epoch[4](437/720): Loss: 0.002095\n",
            "===> Epoch[4](438/720): Loss: 0.000432\n",
            "===> Epoch[4](439/720): Loss: 0.000448\n",
            "===> Epoch[4](440/720): Loss: 0.000477\n",
            "===> Epoch[4](441/720): Loss: 0.000214\n",
            "===> Epoch[4](442/720): Loss: 0.001651\n",
            "===> Epoch[4](443/720): Loss: 0.000708\n",
            "===> Epoch[4](444/720): Loss: 0.000199\n",
            "===> Epoch[4](445/720): Loss: 0.001394\n",
            "===> Epoch[4](446/720): Loss: 0.000255\n",
            "===> Epoch[4](447/720): Loss: 0.000434\n",
            "===> Epoch[4](448/720): Loss: 0.000413\n",
            "===> Epoch[4](449/720): Loss: 0.000728\n",
            "===> Epoch[4](450/720): Loss: 0.000248\n",
            "===> Epoch[4](451/720): Loss: 0.000715\n",
            "===> Epoch[4](452/720): Loss: 0.000909\n",
            "===> Epoch[4](453/720): Loss: 0.000426\n",
            "===> Epoch[4](454/720): Loss: 0.001243\n",
            "===> Epoch[4](455/720): Loss: 0.000451\n",
            "===> Epoch[4](456/720): Loss: 0.000144\n",
            "===> Epoch[4](457/720): Loss: 0.000428\n",
            "===> Epoch[4](458/720): Loss: 0.000585\n",
            "===> Epoch[4](459/720): Loss: 0.000523\n",
            "===> Epoch[4](460/720): Loss: 0.000411\n",
            "===> Epoch[4](461/720): Loss: 0.001143\n",
            "===> Epoch[4](462/720): Loss: 0.000400\n",
            "===> Epoch[4](463/720): Loss: 0.000125\n",
            "===> Epoch[4](464/720): Loss: 0.000309\n",
            "===> Epoch[4](465/720): Loss: 0.000174\n",
            "===> Epoch[4](466/720): Loss: 0.000266\n",
            "===> Epoch[4](467/720): Loss: 0.000473\n",
            "===> Epoch[4](468/720): Loss: 0.000202\n",
            "===> Epoch[4](469/720): Loss: 0.000145\n",
            "===> Epoch[4](470/720): Loss: 0.000766\n",
            "===> Epoch[4](471/720): Loss: 0.000347\n",
            "===> Epoch[4](472/720): Loss: 0.000185\n",
            "===> Epoch[4](473/720): Loss: 0.000167\n",
            "===> Epoch[4](474/720): Loss: 0.000319\n",
            "===> Epoch[4](475/720): Loss: 0.000460\n",
            "===> Epoch[4](476/720): Loss: 0.000507\n",
            "===> Epoch[4](477/720): Loss: 0.000209\n",
            "===> Epoch[4](478/720): Loss: 0.000548\n",
            "===> Epoch[4](479/720): Loss: 0.000141\n",
            "===> Epoch[4](480/720): Loss: 0.000924\n",
            "===> Epoch[4](481/720): Loss: 0.000637\n",
            "===> Epoch[4](482/720): Loss: 0.000180\n",
            "===> Epoch[4](483/720): Loss: 0.000395\n",
            "===> Epoch[4](484/720): Loss: 0.000318\n",
            "===> Epoch[4](485/720): Loss: 0.000365\n",
            "===> Epoch[4](486/720): Loss: 0.000668\n",
            "===> Epoch[4](487/720): Loss: 0.000910\n",
            "===> Epoch[4](488/720): Loss: 0.000375\n",
            "===> Epoch[4](489/720): Loss: 0.000501\n",
            "===> Epoch[4](490/720): Loss: 0.000296\n",
            "===> Epoch[4](491/720): Loss: 0.000105\n",
            "===> Epoch[4](492/720): Loss: 0.000250\n",
            "===> Epoch[4](493/720): Loss: 0.000405\n",
            "===> Epoch[4](494/720): Loss: 0.000238\n",
            "===> Epoch[4](495/720): Loss: 0.000841\n",
            "===> Epoch[4](496/720): Loss: 0.000480\n",
            "===> Epoch[4](497/720): Loss: 0.000360\n",
            "===> Epoch[4](498/720): Loss: 0.000219\n",
            "===> Epoch[4](499/720): Loss: 0.000249\n",
            "===> Epoch[4](500/720): Loss: 0.000362\n",
            "===> Epoch[4](501/720): Loss: 0.000228\n",
            "===> Epoch[4](502/720): Loss: 0.000097\n",
            "===> Epoch[4](503/720): Loss: 0.000398\n",
            "===> Epoch[4](504/720): Loss: 0.000325\n",
            "===> Epoch[4](505/720): Loss: 0.000240\n",
            "===> Epoch[4](506/720): Loss: 0.000439\n",
            "===> Epoch[4](507/720): Loss: 0.001015\n",
            "===> Epoch[4](508/720): Loss: 0.000369\n",
            "===> Epoch[4](509/720): Loss: 0.000388\n",
            "===> Epoch[4](510/720): Loss: 0.000228\n",
            "===> Epoch[4](511/720): Loss: 0.000157\n",
            "===> Epoch[4](512/720): Loss: 0.001195\n",
            "===> Epoch[4](513/720): Loss: 0.000601\n",
            "===> Epoch[4](514/720): Loss: 0.000992\n",
            "===> Epoch[4](515/720): Loss: 0.000405\n",
            "===> Epoch[4](516/720): Loss: 0.001204\n",
            "===> Epoch[4](517/720): Loss: 0.000860\n",
            "===> Epoch[4](518/720): Loss: 0.000182\n",
            "===> Epoch[4](519/720): Loss: 0.000373\n",
            "===> Epoch[4](520/720): Loss: 0.000198\n",
            "===> Epoch[4](521/720): Loss: 0.000235\n",
            "===> Epoch[4](522/720): Loss: 0.000478\n",
            "===> Epoch[4](523/720): Loss: 0.000233\n",
            "===> Epoch[4](524/720): Loss: 0.000570\n",
            "===> Epoch[4](525/720): Loss: 0.000232\n",
            "===> Epoch[4](526/720): Loss: 0.000667\n",
            "===> Epoch[4](527/720): Loss: 0.000344\n",
            "===> Epoch[4](528/720): Loss: 0.000329\n",
            "===> Epoch[4](529/720): Loss: 0.001210\n",
            "===> Epoch[4](530/720): Loss: 0.000610\n",
            "===> Epoch[4](531/720): Loss: 0.000199\n",
            "===> Epoch[4](532/720): Loss: 0.000429\n",
            "===> Epoch[4](533/720): Loss: 0.000404\n",
            "===> Epoch[4](534/720): Loss: 0.001878\n",
            "===> Epoch[4](535/720): Loss: 0.000701\n",
            "===> Epoch[4](536/720): Loss: 0.000585\n",
            "===> Epoch[4](537/720): Loss: 0.001095\n",
            "===> Epoch[4](538/720): Loss: 0.000430\n",
            "===> Epoch[4](539/720): Loss: 0.000253\n",
            "===> Epoch[4](540/720): Loss: 0.000719\n",
            "===> Epoch[4](541/720): Loss: 0.001465\n",
            "===> Epoch[4](542/720): Loss: 0.002078\n",
            "===> Epoch[4](543/720): Loss: 0.000165\n",
            "===> Epoch[4](544/720): Loss: 0.000603\n",
            "===> Epoch[4](545/720): Loss: 0.000238\n",
            "===> Epoch[4](546/720): Loss: 0.000318\n",
            "===> Epoch[4](547/720): Loss: 0.000250\n",
            "===> Epoch[4](548/720): Loss: 0.000299\n",
            "===> Epoch[4](549/720): Loss: 0.000128\n",
            "===> Epoch[4](550/720): Loss: 0.000278\n",
            "===> Epoch[4](551/720): Loss: 0.000192\n",
            "===> Epoch[4](552/720): Loss: 0.000318\n",
            "===> Epoch[4](553/720): Loss: 0.000364\n",
            "===> Epoch[4](554/720): Loss: 0.000643\n",
            "===> Epoch[4](555/720): Loss: 0.000278\n",
            "===> Epoch[4](556/720): Loss: 0.000688\n",
            "===> Epoch[4](557/720): Loss: 0.000865\n",
            "===> Epoch[4](558/720): Loss: 0.001001\n",
            "===> Epoch[4](559/720): Loss: 0.000413\n",
            "===> Epoch[4](560/720): Loss: 0.000307\n",
            "===> Epoch[4](561/720): Loss: 0.000267\n",
            "===> Epoch[4](562/720): Loss: 0.000197\n",
            "===> Epoch[4](563/720): Loss: 0.000361\n",
            "===> Epoch[4](564/720): Loss: 0.000441\n",
            "===> Epoch[4](565/720): Loss: 0.000565\n",
            "===> Epoch[4](566/720): Loss: 0.000342\n",
            "===> Epoch[4](567/720): Loss: 0.000998\n",
            "===> Epoch[4](568/720): Loss: 0.002456\n",
            "===> Epoch[4](569/720): Loss: 0.000222\n",
            "===> Epoch[4](570/720): Loss: 0.000696\n",
            "===> Epoch[4](571/720): Loss: 0.000499\n",
            "===> Epoch[4](572/720): Loss: 0.000466\n",
            "===> Epoch[4](573/720): Loss: 0.000663\n",
            "===> Epoch[4](574/720): Loss: 0.000089\n",
            "===> Epoch[4](575/720): Loss: 0.000360\n",
            "===> Epoch[4](576/720): Loss: 0.000247\n",
            "===> Epoch[4](577/720): Loss: 0.000847\n",
            "===> Epoch[4](578/720): Loss: 0.000570\n",
            "===> Epoch[4](579/720): Loss: 0.000373\n",
            "===> Epoch[4](580/720): Loss: 0.000228\n",
            "===> Epoch[4](581/720): Loss: 0.000917\n",
            "===> Epoch[4](582/720): Loss: 0.000303\n",
            "===> Epoch[4](583/720): Loss: 0.000259\n",
            "===> Epoch[4](584/720): Loss: 0.000226\n",
            "===> Epoch[4](585/720): Loss: 0.000234\n",
            "===> Epoch[4](586/720): Loss: 0.000219\n",
            "===> Epoch[4](587/720): Loss: 0.000394\n",
            "===> Epoch[4](588/720): Loss: 0.000129\n",
            "===> Epoch[4](589/720): Loss: 0.000678\n",
            "===> Epoch[4](590/720): Loss: 0.000277\n",
            "===> Epoch[4](591/720): Loss: 0.000872\n",
            "===> Epoch[4](592/720): Loss: 0.000913\n",
            "===> Epoch[4](593/720): Loss: 0.001217\n",
            "===> Epoch[4](594/720): Loss: 0.000436\n",
            "===> Epoch[4](595/720): Loss: 0.000471\n",
            "===> Epoch[4](596/720): Loss: 0.000277\n",
            "===> Epoch[4](597/720): Loss: 0.000185\n",
            "===> Epoch[4](598/720): Loss: 0.000141\n",
            "===> Epoch[4](599/720): Loss: 0.000176\n",
            "===> Epoch[4](600/720): Loss: 0.000151\n",
            "===> Epoch[4](601/720): Loss: 0.003150\n",
            "===> Epoch[4](602/720): Loss: 0.000238\n",
            "===> Epoch[4](603/720): Loss: 0.000655\n",
            "===> Epoch[4](604/720): Loss: 0.000830\n",
            "===> Epoch[4](605/720): Loss: 0.000450\n",
            "===> Epoch[4](606/720): Loss: 0.000504\n",
            "===> Epoch[4](607/720): Loss: 0.001015\n",
            "===> Epoch[4](608/720): Loss: 0.000355\n",
            "===> Epoch[4](609/720): Loss: 0.000702\n",
            "===> Epoch[4](610/720): Loss: 0.000960\n",
            "===> Epoch[4](611/720): Loss: 0.001727\n",
            "===> Epoch[4](612/720): Loss: 0.000136\n",
            "===> Epoch[4](613/720): Loss: 0.000700\n",
            "===> Epoch[4](614/720): Loss: 0.000443\n",
            "===> Epoch[4](615/720): Loss: 0.000737\n",
            "===> Epoch[4](616/720): Loss: 0.000307\n",
            "===> Epoch[4](617/720): Loss: 0.000134\n",
            "===> Epoch[4](618/720): Loss: 0.000212\n",
            "===> Epoch[4](619/720): Loss: 0.000222\n",
            "===> Epoch[4](620/720): Loss: 0.000826\n",
            "===> Epoch[4](621/720): Loss: 0.000251\n",
            "===> Epoch[4](622/720): Loss: 0.000811\n",
            "===> Epoch[4](623/720): Loss: 0.000300\n",
            "===> Epoch[4](624/720): Loss: 0.000254\n",
            "===> Epoch[4](625/720): Loss: 0.000108\n",
            "===> Epoch[4](626/720): Loss: 0.000632\n",
            "===> Epoch[4](627/720): Loss: 0.000998\n",
            "===> Epoch[4](628/720): Loss: 0.001013\n",
            "===> Epoch[4](629/720): Loss: 0.000291\n",
            "===> Epoch[4](630/720): Loss: 0.000978\n",
            "===> Epoch[4](631/720): Loss: 0.000224\n",
            "===> Epoch[4](632/720): Loss: 0.000556\n",
            "===> Epoch[4](633/720): Loss: 0.000501\n",
            "===> Epoch[4](634/720): Loss: 0.000158\n",
            "===> Epoch[4](635/720): Loss: 0.000144\n",
            "===> Epoch[4](636/720): Loss: 0.000892\n",
            "===> Epoch[4](637/720): Loss: 0.000520\n",
            "===> Epoch[4](638/720): Loss: 0.000164\n",
            "===> Epoch[4](639/720): Loss: 0.000614\n",
            "===> Epoch[4](640/720): Loss: 0.000396\n",
            "===> Epoch[4](641/720): Loss: 0.000603\n",
            "===> Epoch[4](642/720): Loss: 0.001197\n",
            "===> Epoch[4](643/720): Loss: 0.000199\n",
            "===> Epoch[4](644/720): Loss: 0.000109\n",
            "===> Epoch[4](645/720): Loss: 0.000870\n",
            "===> Epoch[4](646/720): Loss: 0.000242\n",
            "===> Epoch[4](647/720): Loss: 0.000314\n",
            "===> Epoch[4](648/720): Loss: 0.000182\n",
            "===> Epoch[4](649/720): Loss: 0.000269\n",
            "===> Epoch[4](650/720): Loss: 0.000338\n",
            "===> Epoch[4](651/720): Loss: 0.001189\n",
            "===> Epoch[4](652/720): Loss: 0.000156\n",
            "===> Epoch[4](653/720): Loss: 0.000232\n",
            "===> Epoch[4](654/720): Loss: 0.000170\n",
            "===> Epoch[4](655/720): Loss: 0.000267\n",
            "===> Epoch[4](656/720): Loss: 0.000260\n",
            "===> Epoch[4](657/720): Loss: 0.000322\n",
            "===> Epoch[4](658/720): Loss: 0.000218\n",
            "===> Epoch[4](659/720): Loss: 0.000154\n",
            "===> Epoch[4](660/720): Loss: 0.000880\n",
            "===> Epoch[4](661/720): Loss: 0.000486\n",
            "===> Epoch[4](662/720): Loss: 0.000173\n",
            "===> Epoch[4](663/720): Loss: 0.000310\n",
            "===> Epoch[4](664/720): Loss: 0.000233\n",
            "===> Epoch[4](665/720): Loss: 0.000588\n",
            "===> Epoch[4](666/720): Loss: 0.000889\n",
            "===> Epoch[4](667/720): Loss: 0.000760\n",
            "===> Epoch[4](668/720): Loss: 0.000946\n",
            "===> Epoch[4](669/720): Loss: 0.000212\n",
            "===> Epoch[4](670/720): Loss: 0.000151\n",
            "===> Epoch[4](671/720): Loss: 0.001106\n",
            "===> Epoch[4](672/720): Loss: 0.000361\n",
            "===> Epoch[4](673/720): Loss: 0.003237\n",
            "===> Epoch[4](674/720): Loss: 0.000389\n",
            "===> Epoch[4](675/720): Loss: 0.000373\n",
            "===> Epoch[4](676/720): Loss: 0.000381\n",
            "===> Epoch[4](677/720): Loss: 0.000752\n",
            "===> Epoch[4](678/720): Loss: 0.000347\n",
            "===> Epoch[4](679/720): Loss: 0.000310\n",
            "===> Epoch[4](680/720): Loss: 0.001352\n",
            "===> Epoch[4](681/720): Loss: 0.000665\n",
            "===> Epoch[4](682/720): Loss: 0.000502\n",
            "===> Epoch[4](683/720): Loss: 0.001614\n",
            "===> Epoch[4](684/720): Loss: 0.001320\n",
            "===> Epoch[4](685/720): Loss: 0.000524\n",
            "===> Epoch[4](686/720): Loss: 0.000737\n",
            "===> Epoch[4](687/720): Loss: 0.000124\n",
            "===> Epoch[4](688/720): Loss: 0.001902\n",
            "===> Epoch[4](689/720): Loss: 0.001020\n",
            "===> Epoch[4](690/720): Loss: 0.000422\n",
            "===> Epoch[4](691/720): Loss: 0.001368\n",
            "===> Epoch[4](692/720): Loss: 0.003389\n",
            "===> Epoch[4](693/720): Loss: 0.001277\n",
            "===> Epoch[4](694/720): Loss: 0.001944\n",
            "===> Epoch[4](695/720): Loss: 0.002621\n",
            "===> Epoch[4](696/720): Loss: 0.002716\n",
            "===> Epoch[4](697/720): Loss: 0.002309\n",
            "===> Epoch[4](698/720): Loss: 0.001139\n",
            "===> Epoch[4](699/720): Loss: 0.003904\n",
            "===> Epoch[4](700/720): Loss: 0.003432\n",
            "===> Epoch[4](701/720): Loss: 0.003671\n",
            "===> Epoch[4](702/720): Loss: 0.002323\n",
            "===> Epoch[4](703/720): Loss: 0.001938\n",
            "===> Epoch[4](704/720): Loss: 0.000817\n",
            "===> Epoch[4](705/720): Loss: 0.002007\n",
            "===> Epoch[4](706/720): Loss: 0.003677\n",
            "===> Epoch[4](707/720): Loss: 0.015429\n",
            "===> Epoch[4](708/720): Loss: 0.006260\n",
            "===> Epoch[4](709/720): Loss: 0.005388\n",
            "===> Epoch[4](710/720): Loss: 0.007094\n",
            "===> Epoch[4](711/720): Loss: 0.008938\n",
            "===> Epoch[4](712/720): Loss: 0.006638\n",
            "===> Epoch[4](713/720): Loss: 0.007497\n",
            "===> Epoch[4](714/720): Loss: 0.008281\n",
            "===> Epoch[4](715/720): Loss: 0.015697\n",
            "===> Epoch[4](716/720): Loss: 0.007599\n",
            "===> Epoch[4](717/720): Loss: 0.005013\n",
            "===> Epoch[4](718/720): Loss: 0.007977\n",
            "===> Epoch[4](719/720): Loss: 0.005978\n",
            "===> Epoch[4](720/720): Loss: 0.004111\n",
            "===> Epoch 4 Complete: Avg. Loss: 0.000852\n",
            "=====>  Training 4 epochs completed\n",
            "=====>  Testing 4 epochs\n",
            "=====>  lr scheduler activated in 4 epochs completed\n",
            "=====>  Save checkpoint 4 epochs\n",
            "/content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_4.pth\n",
            "Checkpoint saved to /content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_faces/model_epoch_4.pth\n",
            "=====>  Save checkpoint 4 epochs completed\n",
            "=====>  Training 5 epochs\n",
            "===> Training # 5 epoch\n",
            "===> Epoch[5](1/720): Loss: 0.009890\n",
            "===> Epoch[5](2/720): Loss: 0.017129\n",
            "===> Epoch[5](3/720): Loss: 0.015318\n",
            "===> Epoch[5](4/720): Loss: 0.004058\n",
            "===> Epoch[5](5/720): Loss: 0.016041\n",
            "===> Epoch[5](6/720): Loss: 0.013116\n",
            "===> Epoch[5](7/720): Loss: 0.009007\n",
            "===> Epoch[5](8/720): Loss: 0.012116\n",
            "===> Epoch[5](9/720): Loss: 0.004511\n",
            "===> Epoch[5](10/720): Loss: 0.006540\n",
            "===> Epoch[5](11/720): Loss: 0.006300\n",
            "===> Epoch[5](12/720): Loss: 0.006200\n",
            "===> Epoch[5](13/720): Loss: 0.006117\n",
            "===> Epoch[5](14/720): Loss: 0.002610\n",
            "===> Epoch[5](15/720): Loss: 0.002375\n",
            "===> Epoch[5](16/720): Loss: 0.002841\n",
            "===> Epoch[5](17/720): Loss: 0.001590\n",
            "===> Epoch[5](18/720): Loss: 0.002301\n",
            "===> Epoch[5](19/720): Loss: 0.001585\n",
            "===> Epoch[5](20/720): Loss: 0.001425\n",
            "===> Epoch[5](21/720): Loss: 0.001628\n",
            "===> Epoch[5](22/720): Loss: 0.002007\n",
            "===> Epoch[5](23/720): Loss: 0.001339\n",
            "===> Epoch[5](24/720): Loss: 0.001797\n",
            "===> Epoch[5](25/720): Loss: 0.000816\n",
            "===> Epoch[5](26/720): Loss: 0.000882\n",
            "===> Epoch[5](27/720): Loss: 0.001513\n",
            "===> Epoch[5](28/720): Loss: 0.001971\n",
            "===> Epoch[5](29/720): Loss: 0.001964\n",
            "===> Epoch[5](30/720): Loss: 0.002059\n",
            "===> Epoch[5](31/720): Loss: 0.001182\n",
            "===> Epoch[5](32/720): Loss: 0.000820\n",
            "===> Epoch[5](33/720): Loss: 0.000984\n",
            "===> Epoch[5](34/720): Loss: 0.001748\n",
            "===> Epoch[5](35/720): Loss: 0.000987\n",
            "===> Epoch[5](36/720): Loss: 0.001209\n",
            "===> Epoch[5](37/720): Loss: 0.002560\n",
            "===> Epoch[5](38/720): Loss: 0.000568\n",
            "===> Epoch[5](39/720): Loss: 0.000851\n",
            "===> Epoch[5](40/720): Loss: 0.001065\n",
            "===> Epoch[5](41/720): Loss: 0.000783\n",
            "===> Epoch[5](42/720): Loss: 0.001150\n",
            "===> Epoch[5](43/720): Loss: 0.000427\n",
            "===> Epoch[5](44/720): Loss: 0.000331\n",
            "===> Epoch[5](45/720): Loss: 0.000846\n",
            "===> Epoch[5](46/720): Loss: 0.000657\n",
            "===> Epoch[5](47/720): Loss: 0.001156\n",
            "===> Epoch[5](48/720): Loss: 0.000375\n",
            "===> Epoch[5](49/720): Loss: 0.001191\n",
            "===> Epoch[5](50/720): Loss: 0.001085\n",
            "===> Epoch[5](51/720): Loss: 0.000501\n",
            "===> Epoch[5](52/720): Loss: 0.000580\n",
            "===> Epoch[5](53/720): Loss: 0.000408\n",
            "===> Epoch[5](54/720): Loss: 0.000464\n",
            "===> Epoch[5](55/720): Loss: 0.000565\n",
            "===> Epoch[5](56/720): Loss: 0.000996\n",
            "===> Epoch[5](57/720): Loss: 0.000815\n",
            "===> Epoch[5](58/720): Loss: 0.000798\n",
            "===> Epoch[5](59/720): Loss: 0.000421\n",
            "===> Epoch[5](60/720): Loss: 0.001120\n",
            "===> Epoch[5](61/720): Loss: 0.000485\n",
            "===> Epoch[5](62/720): Loss: 0.000530\n",
            "===> Epoch[5](63/720): Loss: 0.001356\n",
            "===> Epoch[5](64/720): Loss: 0.001070\n",
            "===> Epoch[5](65/720): Loss: 0.000396\n",
            "===> Epoch[5](66/720): Loss: 0.000572\n",
            "===> Epoch[5](67/720): Loss: 0.000687\n",
            "===> Epoch[5](68/720): Loss: 0.000374\n",
            "===> Epoch[5](69/720): Loss: 0.000519\n",
            "===> Epoch[5](70/720): Loss: 0.002300\n",
            "===> Epoch[5](71/720): Loss: 0.000383\n",
            "===> Epoch[5](72/720): Loss: 0.001613\n",
            "===> Epoch[5](73/720): Loss: 0.000262\n",
            "===> Epoch[5](74/720): Loss: 0.000473\n",
            "===> Epoch[5](75/720): Loss: 0.000832\n",
            "===> Epoch[5](76/720): Loss: 0.003744\n",
            "===> Epoch[5](77/720): Loss: 0.000335\n",
            "===> Epoch[5](78/720): Loss: 0.000388\n",
            "===> Epoch[5](79/720): Loss: 0.000516\n",
            "===> Epoch[5](80/720): Loss: 0.000446\n",
            "===> Epoch[5](81/720): Loss: 0.001174\n",
            "===> Epoch[5](82/720): Loss: 0.001089\n",
            "===> Epoch[5](83/720): Loss: 0.001072\n",
            "===> Epoch[5](84/720): Loss: 0.000981\n",
            "===> Epoch[5](85/720): Loss: 0.000244\n",
            "===> Epoch[5](86/720): Loss: 0.001046\n",
            "===> Epoch[5](87/720): Loss: 0.000343\n",
            "===> Epoch[5](88/720): Loss: 0.000980\n",
            "===> Epoch[5](89/720): Loss: 0.000277\n",
            "===> Epoch[5](90/720): Loss: 0.000319\n",
            "===> Epoch[5](91/720): Loss: 0.000292\n",
            "===> Epoch[5](92/720): Loss: 0.000358\n",
            "===> Epoch[5](93/720): Loss: 0.000225\n",
            "===> Epoch[5](94/720): Loss: 0.000508\n",
            "===> Epoch[5](95/720): Loss: 0.000212\n",
            "===> Epoch[5](96/720): Loss: 0.000605\n",
            "===> Epoch[5](97/720): Loss: 0.000393\n",
            "===> Epoch[5](98/720): Loss: 0.000247\n",
            "===> Epoch[5](99/720): Loss: 0.000270\n",
            "===> Epoch[5](100/720): Loss: 0.001089\n",
            "===> Epoch[5](101/720): Loss: 0.000172\n",
            "===> Epoch[5](102/720): Loss: 0.000281\n",
            "===> Epoch[5](103/720): Loss: 0.000333\n",
            "===> Epoch[5](104/720): Loss: 0.000313\n",
            "===> Epoch[5](105/720): Loss: 0.000760\n",
            "===> Epoch[5](106/720): Loss: 0.000284\n",
            "===> Epoch[5](107/720): Loss: 0.000265\n",
            "===> Epoch[5](108/720): Loss: 0.000285\n",
            "===> Epoch[5](109/720): Loss: 0.000436\n",
            "===> Epoch[5](110/720): Loss: 0.000892\n",
            "===> Epoch[5](111/720): Loss: 0.000231\n",
            "===> Epoch[5](112/720): Loss: 0.001034\n",
            "===> Epoch[5](113/720): Loss: 0.000338\n",
            "===> Epoch[5](114/720): Loss: 0.000331\n",
            "===> Epoch[5](115/720): Loss: 0.000570\n",
            "===> Epoch[5](116/720): Loss: 0.001091\n",
            "===> Epoch[5](117/720): Loss: 0.002477\n",
            "===> Epoch[5](118/720): Loss: 0.000362\n",
            "===> Epoch[5](119/720): Loss: 0.000295\n",
            "===> Epoch[5](120/720): Loss: 0.000279\n",
            "===> Epoch[5](121/720): Loss: 0.000564\n",
            "===> Epoch[5](122/720): Loss: 0.001032\n",
            "===> Epoch[5](123/720): Loss: 0.000676\n",
            "===> Epoch[5](124/720): Loss: 0.000252\n",
            "===> Epoch[5](125/720): Loss: 0.001406\n",
            "===> Epoch[5](126/720): Loss: 0.000858\n",
            "===> Epoch[5](127/720): Loss: 0.001580\n",
            "===> Epoch[5](128/720): Loss: 0.000578\n",
            "===> Epoch[5](129/720): Loss: 0.000940\n",
            "===> Epoch[5](130/720): Loss: 0.000272\n",
            "===> Epoch[5](131/720): Loss: 0.000272\n",
            "===> Epoch[5](132/720): Loss: 0.000621\n",
            "===> Epoch[5](133/720): Loss: 0.001216\n",
            "===> Epoch[5](134/720): Loss: 0.000755\n",
            "===> Epoch[5](135/720): Loss: 0.000321\n",
            "===> Epoch[5](136/720): Loss: 0.000484\n",
            "===> Epoch[5](137/720): Loss: 0.000494\n",
            "===> Epoch[5](138/720): Loss: 0.000439\n",
            "===> Epoch[5](139/720): Loss: 0.000407\n",
            "===> Epoch[5](140/720): Loss: 0.000631\n",
            "===> Epoch[5](141/720): Loss: 0.001149\n",
            "===> Epoch[5](142/720): Loss: 0.000333\n",
            "===> Epoch[5](143/720): Loss: 0.000843\n",
            "===> Epoch[5](144/720): Loss: 0.000207\n",
            "===> Epoch[5](145/720): Loss: 0.000770\n",
            "===> Epoch[5](146/720): Loss: 0.000489\n",
            "===> Epoch[5](147/720): Loss: 0.000300\n",
            "===> Epoch[5](148/720): Loss: 0.000326\n",
            "===> Epoch[5](149/720): Loss: 0.000328\n",
            "===> Epoch[5](150/720): Loss: 0.000408\n",
            "===> Epoch[5](151/720): Loss: 0.000441\n",
            "===> Epoch[5](152/720): Loss: 0.000794\n",
            "===> Epoch[5](153/720): Loss: 0.000357\n",
            "===> Epoch[5](154/720): Loss: 0.000803\n",
            "===> Epoch[5](155/720): Loss: 0.001014\n",
            "===> Epoch[5](156/720): Loss: 0.001299\n",
            "===> Epoch[5](157/720): Loss: 0.000332\n",
            "===> Epoch[5](158/720): Loss: 0.000242\n",
            "===> Epoch[5](159/720): Loss: 0.000364\n",
            "===> Epoch[5](160/720): Loss: 0.000265\n",
            "===> Epoch[5](161/720): Loss: 0.000455\n",
            "===> Epoch[5](162/720): Loss: 0.000676\n",
            "===> Epoch[5](163/720): Loss: 0.000296\n",
            "===> Epoch[5](164/720): Loss: 0.000352\n",
            "===> Epoch[5](165/720): Loss: 0.000334\n",
            "===> Epoch[5](166/720): Loss: 0.000815\n",
            "===> Epoch[5](167/720): Loss: 0.001319\n",
            "===> Epoch[5](168/720): Loss: 0.000186\n",
            "===> Epoch[5](169/720): Loss: 0.001385\n",
            "===> Epoch[5](170/720): Loss: 0.002025\n",
            "===> Epoch[5](171/720): Loss: 0.000447\n",
            "===> Epoch[5](172/720): Loss: 0.000576\n",
            "===> Epoch[5](173/720): Loss: 0.001258\n",
            "===> Epoch[5](174/720): Loss: 0.000510\n",
            "===> Epoch[5](175/720): Loss: 0.000290\n",
            "===> Epoch[5](176/720): Loss: 0.000694\n",
            "===> Epoch[5](177/720): Loss: 0.000287\n",
            "===> Epoch[5](178/720): Loss: 0.000528\n",
            "===> Epoch[5](179/720): Loss: 0.000275\n",
            "===> Epoch[5](180/720): Loss: 0.001126\n",
            "===> Epoch[5](181/720): Loss: 0.000487\n",
            "===> Epoch[5](182/720): Loss: 0.000304\n",
            "===> Epoch[5](183/720): Loss: 0.000732\n",
            "===> Epoch[5](184/720): Loss: 0.000111\n",
            "===> Epoch[5](185/720): Loss: 0.000433\n",
            "===> Epoch[5](186/720): Loss: 0.000435\n",
            "===> Epoch[5](187/720): Loss: 0.000228\n",
            "===> Epoch[5](188/720): Loss: 0.000189\n",
            "===> Epoch[5](189/720): Loss: 0.001068\n",
            "===> Epoch[5](190/720): Loss: 0.000371\n",
            "===> Epoch[5](191/720): Loss: 0.000549\n",
            "===> Epoch[5](192/720): Loss: 0.000383\n",
            "===> Epoch[5](193/720): Loss: 0.000788\n",
            "===> Epoch[5](194/720): Loss: 0.000461\n",
            "===> Epoch[5](195/720): Loss: 0.000447\n",
            "===> Epoch[5](196/720): Loss: 0.000302\n",
            "===> Epoch[5](197/720): Loss: 0.000554\n",
            "===> Epoch[5](198/720): Loss: 0.000536\n",
            "===> Epoch[5](199/720): Loss: 0.000521\n",
            "===> Epoch[5](200/720): Loss: 0.000310\n",
            "===> Epoch[5](201/720): Loss: 0.000582\n",
            "===> Epoch[5](202/720): Loss: 0.000547\n",
            "===> Epoch[5](203/720): Loss: 0.000260\n",
            "===> Epoch[5](204/720): Loss: 0.000718\n",
            "===> Epoch[5](205/720): Loss: 0.000966\n",
            "===> Epoch[5](206/720): Loss: 0.000264\n",
            "===> Epoch[5](207/720): Loss: 0.000419\n",
            "===> Epoch[5](208/720): Loss: 0.000483\n",
            "===> Epoch[5](209/720): Loss: 0.000257\n",
            "===> Epoch[5](210/720): Loss: 0.000533\n",
            "===> Epoch[5](211/720): Loss: 0.000206\n",
            "===> Epoch[5](212/720): Loss: 0.000542\n",
            "===> Epoch[5](213/720): Loss: 0.000637\n",
            "===> Epoch[5](214/720): Loss: 0.000232\n",
            "===> Epoch[5](215/720): Loss: 0.000250\n",
            "===> Epoch[5](216/720): Loss: 0.000274\n",
            "===> Epoch[5](217/720): Loss: 0.000607\n",
            "===> Epoch[5](218/720): Loss: 0.000393\n",
            "===> Epoch[5](219/720): Loss: 0.000373\n",
            "===> Epoch[5](220/720): Loss: 0.000418\n",
            "===> Epoch[5](221/720): Loss: 0.000398\n",
            "===> Epoch[5](222/720): Loss: 0.000185\n",
            "===> Epoch[5](223/720): Loss: 0.000167\n",
            "===> Epoch[5](224/720): Loss: 0.000196\n",
            "===> Epoch[5](225/720): Loss: 0.000836\n",
            "===> Epoch[5](226/720): Loss: 0.000323\n",
            "===> Epoch[5](227/720): Loss: 0.000171\n",
            "===> Epoch[5](228/720): Loss: 0.000387\n",
            "===> Epoch[5](229/720): Loss: 0.000663\n",
            "===> Epoch[5](230/720): Loss: 0.000208\n",
            "===> Epoch[5](231/720): Loss: 0.002437\n",
            "===> Epoch[5](232/720): Loss: 0.000339\n",
            "===> Epoch[5](233/720): Loss: 0.000404\n",
            "===> Epoch[5](234/720): Loss: 0.000448\n",
            "===> Epoch[5](235/720): Loss: 0.000518\n",
            "===> Epoch[5](236/720): Loss: 0.000974\n",
            "===> Epoch[5](237/720): Loss: 0.000198\n",
            "===> Epoch[5](238/720): Loss: 0.000847\n",
            "===> Epoch[5](239/720): Loss: 0.000438\n",
            "===> Epoch[5](240/720): Loss: 0.000957\n",
            "===> Epoch[5](241/720): Loss: 0.002654\n",
            "===> Epoch[5](242/720): Loss: 0.000621\n",
            "===> Epoch[5](243/720): Loss: 0.000507\n",
            "===> Epoch[5](244/720): Loss: 0.000217\n",
            "===> Epoch[5](245/720): Loss: 0.000348\n",
            "===> Epoch[5](246/720): Loss: 0.000234\n",
            "===> Epoch[5](247/720): Loss: 0.001532\n",
            "===> Epoch[5](248/720): Loss: 0.000537\n",
            "===> Epoch[5](249/720): Loss: 0.000181\n",
            "===> Epoch[5](250/720): Loss: 0.000259\n",
            "===> Epoch[5](251/720): Loss: 0.000232\n",
            "===> Epoch[5](252/720): Loss: 0.001037\n",
            "===> Epoch[5](253/720): Loss: 0.000151\n",
            "===> Epoch[5](254/720): Loss: 0.000339\n",
            "===> Epoch[5](255/720): Loss: 0.000231\n",
            "===> Epoch[5](256/720): Loss: 0.000741\n",
            "===> Epoch[5](257/720): Loss: 0.000122\n",
            "===> Epoch[5](258/720): Loss: 0.000376\n",
            "===> Epoch[5](259/720): Loss: 0.000417\n",
            "===> Epoch[5](260/720): Loss: 0.000547\n",
            "===> Epoch[5](261/720): Loss: 0.001592\n",
            "===> Epoch[5](262/720): Loss: 0.001753\n",
            "===> Epoch[5](263/720): Loss: 0.001218\n",
            "===> Epoch[5](264/720): Loss: 0.000568\n",
            "===> Epoch[5](265/720): Loss: 0.000815\n",
            "===> Epoch[5](266/720): Loss: 0.001253\n",
            "===> Epoch[5](267/720): Loss: 0.000231\n",
            "===> Epoch[5](268/720): Loss: 0.001022\n",
            "===> Epoch[5](269/720): Loss: 0.000208\n",
            "===> Epoch[5](270/720): Loss: 0.000982\n",
            "===> Epoch[5](271/720): Loss: 0.000817\n",
            "===> Epoch[5](272/720): Loss: 0.000430\n",
            "===> Epoch[5](273/720): Loss: 0.001286\n",
            "===> Epoch[5](274/720): Loss: 0.001515\n",
            "===> Epoch[5](275/720): Loss: 0.001106\n",
            "===> Epoch[5](276/720): Loss: 0.000788\n",
            "===> Epoch[5](277/720): Loss: 0.000554\n",
            "===> Epoch[5](278/720): Loss: 0.000739\n",
            "===> Epoch[5](279/720): Loss: 0.000619\n",
            "===> Epoch[5](280/720): Loss: 0.000765\n",
            "===> Epoch[5](281/720): Loss: 0.000263\n",
            "===> Epoch[5](282/720): Loss: 0.000376\n",
            "===> Epoch[5](283/720): Loss: 0.000440\n",
            "===> Epoch[5](284/720): Loss: 0.000282\n",
            "===> Epoch[5](285/720): Loss: 0.000389\n",
            "===> Epoch[5](286/720): Loss: 0.000976\n",
            "===> Epoch[5](287/720): Loss: 0.000616\n",
            "===> Epoch[5](288/720): Loss: 0.000486\n",
            "===> Epoch[5](289/720): Loss: 0.002051\n",
            "===> Epoch[5](290/720): Loss: 0.000261\n",
            "===> Epoch[5](291/720): Loss: 0.001809\n",
            "===> Epoch[5](292/720): Loss: 0.000292\n",
            "===> Epoch[5](293/720): Loss: 0.000301\n",
            "===> Epoch[5](294/720): Loss: 0.000295\n",
            "===> Epoch[5](295/720): Loss: 0.000672\n",
            "===> Epoch[5](296/720): Loss: 0.000650\n",
            "===> Epoch[5](297/720): Loss: 0.000210\n",
            "===> Epoch[5](298/720): Loss: 0.000365\n",
            "===> Epoch[5](299/720): Loss: 0.000264\n",
            "===> Epoch[5](300/720): Loss: 0.000300\n",
            "===> Epoch[5](301/720): Loss: 0.000466\n",
            "===> Epoch[5](302/720): Loss: 0.000887\n",
            "===> Epoch[5](303/720): Loss: 0.000796\n",
            "===> Epoch[5](304/720): Loss: 0.000289\n",
            "===> Epoch[5](305/720): Loss: 0.000274\n",
            "===> Epoch[5](306/720): Loss: 0.000355\n",
            "===> Epoch[5](307/720): Loss: 0.001046\n",
            "===> Epoch[5](308/720): Loss: 0.000533\n",
            "===> Epoch[5](309/720): Loss: 0.000883\n",
            "===> Epoch[5](310/720): Loss: 0.002591\n",
            "===> Epoch[5](311/720): Loss: 0.000213\n",
            "===> Epoch[5](312/720): Loss: 0.000184\n",
            "===> Epoch[5](313/720): Loss: 0.000741\n",
            "===> Epoch[5](314/720): Loss: 0.000398\n",
            "===> Epoch[5](315/720): Loss: 0.000176\n",
            "===> Epoch[5](316/720): Loss: 0.000245\n",
            "===> Epoch[5](317/720): Loss: 0.000135\n",
            "===> Epoch[5](318/720): Loss: 0.001442\n",
            "===> Epoch[5](319/720): Loss: 0.002029\n",
            "===> Epoch[5](320/720): Loss: 0.000160\n",
            "===> Epoch[5](321/720): Loss: 0.000081\n",
            "===> Epoch[5](322/720): Loss: 0.000382\n",
            "===> Epoch[5](323/720): Loss: 0.001250\n",
            "===> Epoch[5](324/720): Loss: 0.001640\n",
            "===> Epoch[5](325/720): Loss: 0.000461\n",
            "===> Epoch[5](326/720): Loss: 0.000200\n",
            "===> Epoch[5](327/720): Loss: 0.002180\n",
            "===> Epoch[5](328/720): Loss: 0.000463\n",
            "===> Epoch[5](329/720): Loss: 0.000854\n",
            "===> Epoch[5](330/720): Loss: 0.000252\n",
            "===> Epoch[5](331/720): Loss: 0.000284\n",
            "===> Epoch[5](332/720): Loss: 0.000523\n",
            "===> Epoch[5](333/720): Loss: 0.000240\n",
            "===> Epoch[5](334/720): Loss: 0.000223\n",
            "===> Epoch[5](335/720): Loss: 0.000442\n",
            "===> Epoch[5](336/720): Loss: 0.000176\n",
            "===> Epoch[5](337/720): Loss: 0.000329\n",
            "===> Epoch[5](338/720): Loss: 0.000651\n",
            "===> Epoch[5](339/720): Loss: 0.001084\n",
            "===> Epoch[5](340/720): Loss: 0.001031\n",
            "===> Epoch[5](341/720): Loss: 0.000525\n",
            "===> Epoch[5](342/720): Loss: 0.000205\n",
            "===> Epoch[5](343/720): Loss: 0.000590\n",
            "===> Epoch[5](344/720): Loss: 0.000375\n",
            "===> Epoch[5](345/720): Loss: 0.000602\n",
            "===> Epoch[5](346/720): Loss: 0.000219\n",
            "===> Epoch[5](347/720): Loss: 0.000286\n",
            "===> Epoch[5](348/720): Loss: 0.001022\n",
            "===> Epoch[5](349/720): Loss: 0.000977\n",
            "===> Epoch[5](350/720): Loss: 0.000238\n",
            "===> Epoch[5](351/720): Loss: 0.000498\n",
            "===> Epoch[5](352/720): Loss: 0.000148\n",
            "===> Epoch[5](353/720): Loss: 0.000762\n",
            "===> Epoch[5](354/720): Loss: 0.000708\n",
            "===> Epoch[5](355/720): Loss: 0.000203\n",
            "===> Epoch[5](356/720): Loss: 0.001008\n",
            "===> Epoch[5](357/720): Loss: 0.000864\n",
            "===> Epoch[5](358/720): Loss: 0.000930\n",
            "===> Epoch[5](359/720): Loss: 0.000271\n",
            "===> Epoch[5](360/720): Loss: 0.000146\n",
            "===> Epoch[5](361/720): Loss: 0.000133\n",
            "===> Epoch[5](362/720): Loss: 0.000172\n",
            "===> Epoch[5](363/720): Loss: 0.000498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_recent_checkpoint(checkpoint_dir):\n",
        "    checkpoint_paths = [path for path in glob(\"{}/model_epoch_*.pth\".format(checkpoint_dir))]\n",
        "    idxes = [int(os.path.basename(path).split('_')[2].split('.')[0]) for path in checkpoint_paths]\n",
        "\n",
        "    max_idx = max(idxes)\n",
        "    latest_checkpoint = os.path.join(checkpoint_dir, \"model_epoch_{}.pth\".format(max_idx))\n",
        "    print(\" [*] Found latest checkpoint: {}\".format(latest_checkpoint))\n",
        "    return latest_checkpoint, max_idx"
      ],
      "metadata": {
        "id": "ARz7e-L73r34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs_path =  \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test/downsized\"\n",
        "results_path=  \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_Upconv_endo/\"\n",
        "# results_path=  \"/content/temp\"\n"
      ],
      "metadata": {
        "id": "iB4_IMnI3r0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import os\n",
        "from glob import glob\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kkXaab70MQsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_ckpt , _ = get_most_recent_checkpoint(\"/content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_endo\")\n",
        "too_big_imgs = []\n",
        "model = torch.load(last_ckpt)\n",
        "already_saved = sorted(os.listdir(results_path))\n",
        "for i in sorted(os.listdir(test_imgs_path)):\n",
        "  if i in already_saved:\n",
        "    continue \n",
        "  img = Image.open(os.path.join(test_imgs_path,i)).convert('YCbCr')\n",
        "  # img = img.resize((img.size[0]//2, img.size[1]//2))\n",
        "  if img.size[0]>=800 or img.size[1]>=800:\n",
        "    too_big_imgs.append(i)\n",
        "    continue\n",
        "  print(img.size)\n",
        "  y, cb, cr = img.split()\n",
        "  img_to_tensor = ToTensor()\n",
        "  input = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])\n",
        "\n",
        "  out = model(input)\n",
        "  out = out.cpu()\n",
        "\n",
        "  out_img_y = out[0].detach().numpy()\n",
        "  out_img_y *= 255.0\n",
        "  out_img_y = out_img_y.clip(0, 255)\n",
        "  out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n",
        "\n",
        "  out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)\n",
        "  out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)\n",
        "  out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n",
        "\n",
        "  out_img.save(os.path.join(results_path,i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNlH9T823rwo",
        "outputId": "12921548-a4fc-4eb9-8cd7-b621ada3a58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Found latest checkpoint: /content/gdrive/MyDrive/MLSP_project_data/project_ckpts/Upconv_endo/model_epoch_7.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "8"
      ],
      "metadata": {
        "id": "FsXJdt3M3rs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doRfIIXQ3rpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ItbgWM883rmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tCgMSFP3rjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXNsXw_C3rau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGEHo0VjpY5"
      },
      "source": [
        "# Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022 -- Oral) [![paper](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2111.09881) \n",
        "\n",
        "<hr />\n",
        "\n",
        "This is a demo to run Restormer on you own images for the following tasks\n",
        "- Real Image Denoising\n",
        "- Single-Image Defocus Deblurring\n",
        "- Single-Image Motion Deblurring \n",
        "- Image Deraining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRd46QaXlklQ"
      },
      "source": [
        "# 1. Setup\n",
        "- First, in the **Runtime** menu -> **Change runtime type**, make sure to have ```Hardware Accelerator = GPU```\n",
        "- Clone repo and install dependencies. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLDZ9t1pm9JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef7f8ba-0576-4518-f551-4e83c52468bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.5.0\n",
            "Cloning into 'Restormer'...\n",
            "remote: Enumerating objects: 300, done.\u001b[K\n",
            "remote: Total 300 (delta 0), reused 0 (delta 0), pack-reused 300\u001b[K\n",
            "Receiving objects: 100% (300/300), 1.56 MiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "/content/Restormer\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install einops\n",
        "\n",
        "if os.path.isdir('Restormer'):\n",
        "  !rm -r Restormer\n",
        "\n",
        "# Clone Restormer\n",
        "!git clone https://github.com/swz30/Restormer.git\n",
        "%cd Restormer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxtBPA1tGxL"
      },
      "source": [
        "# 2. Define Task and Download Pre-trained Models\n",
        "Uncomment the task you would like to perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM4ksCkZtqUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebb85ef-8ec1-4b63-b23e-7c2be6c8a66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-28 22:37:28--  https://github.com/swz30/Restormer/releases/download/v1.0/single_image_defocus_deblurring.pth\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/29507e7d-b992-4c77-a4f9-ec3fb3b555bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221028%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221028T223728Z&X-Amz-Expires=300&X-Amz-Signature=a932a88b504a31747e2000708f1ce26580c8a02161cfde460e5a21cf247f302a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=418793252&response-content-disposition=attachment%3B%20filename%3Dsingle_image_defocus_deblurring.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-28 22:37:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/29507e7d-b992-4c77-a4f9-ec3fb3b555bf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221028%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221028T223728Z&X-Amz-Expires=300&X-Amz-Signature=a932a88b504a31747e2000708f1ce26580c8a02161cfde460e5a21cf247f302a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=418793252&response-content-disposition=attachment%3B%20filename%3Dsingle_image_defocus_deblurring.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104700429 (100M) [application/octet-stream]\n",
            "Saving to: ‘Defocus_Deblurring/pretrained_models/single_image_defocus_deblurring.pth’\n",
            "\n",
            "single_image_defocu 100%[===================>]  99.85M  27.3MB/s    in 4.3s    \n",
            "\n",
            "2022-10-28 22:37:33 (23.1 MB/s) - ‘Defocus_Deblurring/pretrained_models/single_image_defocus_deblurring.pth’ saved [104700429/104700429]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# task = 'Real_Denoising'\n",
        "task = 'Single_Image_Defocus_Deblurring'\n",
        "# task = 'Motion_Deblurring'\n",
        "# task = 'Deraining'\n",
        "\n",
        "# Download the pre-trained models\n",
        "if task is 'Real_Denoising':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/real_denoising.pth -P Denoising/pretrained_models\n",
        "if task is 'Single_Image_Defocus_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/single_image_defocus_deblurring.pth -P Defocus_Deblurring/pretrained_models\n",
        "if task is 'Motion_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth -P Motion_Deblurring/pretrained_models\n",
        "if task is 'Deraining':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth -P Deraining/pretrained_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9nwA_Prt7PI"
      },
      "source": [
        "# 3. Upload Images\n",
        "Either download the sample images or upload your own images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC_q1NshvQHz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Download sample images\n",
        "# !rm -r demo/*\n",
        "# !wget https://github.com/swz30/Restormer/releases/download/v1.0/sample_images.zip -P demo\n",
        "# shutil.unpack_archive('demo/sample_images.zip', 'demo/')\n",
        "# os.remove('demo/sample_images.zip')\n",
        "\n",
        "# OR Uncomment the following block if you would like to upload your own images. \n",
        "\"\"\"\n",
        "!rm -r demo/*\n",
        "input_dir = 'demo/sample_images/'+task+'/degraded'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  input_path = os.path.join(input_dir, filename)\n",
        "  shutil.move(filename, input_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ArqQfvBbRf"
      },
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOJN6gHGCKGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdae1b7b-1920-489b-f795-27268787a2ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Restormer(\n",
              "  (patch_embed): OverlapPatchEmbed(\n",
              "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (encoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down1_2): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2_3): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3_4): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (latent): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4_3): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3_2): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2_1): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (decoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (refinement): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "def get_weights_and_parameters(task, parameters):\n",
        "    if task == 'Motion_Deblurring':\n",
        "        weights = os.path.join('Motion_Deblurring', 'pretrained_models', 'motion_deblurring.pth')\n",
        "    elif task == 'Single_Image_Defocus_Deblurring':\n",
        "        weights = os.path.join('Defocus_Deblurring', 'pretrained_models', 'single_image_defocus_deblurring.pth')\n",
        "    elif task == 'Deraining':\n",
        "        weights = os.path.join('Deraining', 'pretrained_models', 'deraining.pth')\n",
        "    elif task == 'Real_Denoising':\n",
        "        weights = os.path.join('Denoising', 'pretrained_models', 'real_denoising.pth')\n",
        "        parameters['LayerNorm_type'] =  'BiasFree'\n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {'inp_channels':3, 'out_channels':3, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'WithBias', 'dual_pixel_task':False}\n",
        "weights, parameters = get_weights_and_parameters(task, parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join('basicsr', 'models', 'archs', 'restormer_arch.py'))\n",
        "model = load_arch['Restormer'](**parameters)\n",
        "model.cuda()\n",
        "\n",
        "checkpoint = torch.load(weights)\n",
        "model.load_state_dict(checkpoint['params'])\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDvxkztWDsYd"
      },
      "source": [
        "# 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqZR6kktv1Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2Wwk1-p3peg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odPtmz_lD2Rd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "27832685-e302-4d58-edeb-3e47d87fc649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ==> Running Single_Image_Defocus_Deblurring with weights Defocus_Deblurring/pretrained_models/single_image_defocus_deblurring.pth\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/1444 [00:00<07:23,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c995f794d2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mrestored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mrestored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_img)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0minp_enc_level1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mout_enc_level1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_level1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_enc_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0minp_enc_level2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_enc_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 412.00 MiB (GPU 0; 14.76 GiB total capacity; 12.64 GiB already allocated; 335.75 MiB free; 13.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "input_dir = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test/downsized_upsized\"\n",
        "out_dir = \"/content/gdrive/MyDrive/MLSP_project_data/Humans_split/Test_results_Defocus_Deblurring\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "extensions = ['jpg', 'JPG', 'png', 'PNG', 'jpeg', 'JPEG', 'bmp', 'BMP']\n",
        "files = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "\n",
        "img_multiple_of = 8\n",
        "\n",
        "print(f\"\\n ==> Running {task} with weights {weights}\\n \")\n",
        "with torch.no_grad():\n",
        "  for filepath in tqdm(files):\n",
        "      # print(file_)\n",
        "      torch.cuda.ipc_collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
        "      original_h, original_w = img.shape[0], img.shape[1]\n",
        "      img.resize((img.shape[1]//4,img.shape[0]//4,3))\n",
        "      input_ = torch.from_numpy(img).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "      # Pad the input if not_multiple_of 8\n",
        "      h,w = input_.shape[2], input_.shape[3]\n",
        "      H,W = ((h+img_multiple_of)//img_multiple_of)*img_multiple_of, ((w+img_multiple_of)//img_multiple_of)*img_multiple_of\n",
        "      padh = H-h if h%img_multiple_of!=0 else 0\n",
        "      padw = W-w if w%img_multiple_of!=0 else 0\n",
        "      input_ = F.pad(input_, (0,padw,0,padh), 'reflect')\n",
        "\n",
        "      restored = model(input_)\n",
        "      restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "      # Unpad the output\n",
        "      restored = restored[:,:,:h,:w]\n",
        "\n",
        "      restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "      restored = img_as_ubyte(restored[0])\n",
        "\n",
        "      filename = os.path.split(filepath)[-1]\n",
        "      out_img = cv2.cvtColor(restored, cv2.COLOR_RGB2BGR)\n",
        "      out_img.resize((original_w,original_h,3))\n",
        "      cv2.imwrite(os.path.join(out_dir, filename),(out_img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bwDss7ui1y2"
      },
      "source": [
        "# 6. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jm5gyBgzlONb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "inp_filenames = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "out_filenames = natsorted(glob(os.path.join(out_dir, '*')))\n",
        "\n",
        "## Will display only first 5 images\n",
        "num_display_images = 5\n",
        "if len(inp_filenames)>num_display_images:\n",
        "  inp_filenames = inp_filenames[:num_display_images]\n",
        "  out_filenames = out_filenames[:num_display_images]\n",
        "\n",
        "print(f\"Results: {task}\")\n",
        "for inp_file, out_file in zip(inp_filenames, out_filenames):\n",
        "  degraded = cv2.cvtColor(cv2.imread(inp_file), cv2.COLOR_BGR2RGB)\n",
        "  restored = cv2.cvtColor(cv2.imread(out_file), cv2.COLOR_BGR2RGB)\n",
        "  ## Display Images\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "  dpi = fig.get_dpi()\n",
        "  fig.set_size_inches(900/ dpi, 448 / dpi)\n",
        "  plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "  axes[0].axis('off')\n",
        "  axes[0].imshow(degraded)\n",
        "  axes[1].axis('off')\n",
        "  axes[1].imshow(restored)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9TuiD7OtX9V"
      },
      "source": [
        "# 7. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yVqiRjflYll"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "zip_filename = f\"Restormer_{task}.zip\"\n",
        "os.system(f\"zip -r {zip_filename} demo/sample_images/{task}\")\n",
        "files.download(zip_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYG9bFUSvEb8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}